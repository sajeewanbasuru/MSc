Robert David STEELE Vivas,4.0 out of 5 stars,The Singularity Is Near: When Humans Transcend Biology,"Technically brilliant, culturally constrained","Ray Kurzweil is unquestionably the most brilliant guru for the future of information technology, but Joel Garreau's book Radical Evolution: The Promise and Peril of Enhancing Our Minds, Our Bodies -- and What It Means to Be Human covers the same ground, with the same lack of soul, but more interesting and varied detail.

This is really four booklets in one: a booklet on the imminence of exponential growth within information technologies including genetics, nano-technology, and robotics; a booklet on the general directions and possibilities within each of these three areas; a booklet responding to critics of his past works; and lengthy notes. All four are exceptional in their detail, but somewhat dry.

I was disappointed to see no mention of Kevin Kelly's Out of Control: The Rise of Neo-Biological Civilization and just one tiny reference to Stewart Brand (co-evolution) in a note. Howard Rheingold (virtual reality) and Tom Atlee (collective intelligence) go unmentioned. It is almost as if Kurzweil, who is surely familiar with these ""populist"" works, has a disdain for those who evaluate the socio-cultural implications of technology, rather than only its technical merits.

This is an important book, but it is by a nerd for nerds. [Sorry, but anyone who takes 250 vitamin supplements and has a schedule of both direct intravenous supplements and almost daily blood testing, is an obsessive nerd however worthy the cause.] It assumes that information technologies, growing exponentially, will solve world hunger, eliminate disease, replenish water, create renewable energy, and allow all of us to have the bodies we want, and to see and feel in our mates the bodies they want. All of this is said somewhat blandly, without the socio-cultural exploration or global evaluation that is characteristic of other works by reporters on the technology, rather than the technologists themselves.

The book is, in short, divorced from the humanities and the human condition, and devoid of any understanding of the pathos and pathology of immoral governments and corporations that will do anything they can to derail progress that is not profitable. It addresses, but with cursory concern, most of the fears voiced by various critics about run-away machines and lethal technologies that self-replicate in toxic manners to the detriment of their human creators.

The book is strongest in its detailed discussion of both computing power and draconian drops in needed energy for both computing and for manufacturing using new forms of computing. The charts are fun and helpful. The index is quite good.

I put the book down, after a pleasant afternoon of study, with several feelings.

First, that I should give Joel Garreau higher marks for making this interesting, and recommend that his book be bought at the same time as this one.

Second, that there is an interesting schism between the Kurzweil-Gates gang that believes they can rule the world with machines; and the Atlee-Wheatley gang that believes that collective **human** intelligence, with machines playing a facilitating but not a dominant role, is the desired outcome.

Third that there really are very promising technologies with considerable potential down the road, but that government is not being serious about stressing peaceful applications--the author is one of five advisors to the U.S. military on advanced technologies, and it distresses me that he supports a Defense Advanced Research Programs Agency (DARPA) that focuses on making war rather than peace--imagine if we applied the same resources to preventing war and creating wealth?

Fourth, information technologies are indeed going to change the balance of power among nations, states, and neighborhoods--on balance, based on his explicit cautions, I predict a real estate collapse in the over-priced major cities of the US, and a phenomenal rise of high-technology villages in Costa Rica and elsewhere.

The singularity may be near, as the author suggests, but between now and then tens of millions more will die. Technology in isolation is not enough--absent broad ethical context, it remains primarily a vehicle for nerds to develop and corporations to exploit. As I told an internal think session at Interval in the 1990's (""GOD, MAN, & INFORMATION:. COMMENTS TO INTERVAL IN-HOUSE"". Tuesday, 9 March 1993"" can use as a Yahoo search) until our technologies can change the lives of every man, woman, and child in the Third World, they are not truly transformative. This book hints at a future that may not be achieved, not for lack of technology, but for lack of good will.

EDIT of 24 Oct 05: Tonight I will review James Howard Kunstler's The Long Emergency: Surviving the End of Oil, Climate Change, and Other Converging Catastrophes of the Twenty-First Century His bottom line is that cheap oil underlies all of our surburban, high-rise, mega-agriculture, and car-based mobility, and that the end of cheap oil is going to have catastrophic effects on how we live, driving much of the country into poverty and dislocation, with the best lives being in those communities that learn to live with local agriculture and local power options. Definitely the opposite of what Kurzweil sees, and therefore recommended as a competing viewpoint.

EDIT of 12 Dec 07: ethics is something I have thought about a lot, and my first public article outside the intelligence community was entitled ""E3i: Ethics, Ecology, Evolution, & Intelligence: An Alternative Paradigm for *National* Intelligence."" It must be something about engineers. Neither the author of this book, nor the Google Triumverate, seem to grasp the moral implications of technology run amuk without respect for ethics, privacy, copyright, humanity, etc. This is one reason I admire E. O. Wilson so much--the first of his works that I read, Consilience: The Unity of Knowledge, answered the question: ""Why do the sciences need the humanities?"" The second, The Future of Life, answered the question, ""What is the cost and how do we save the planet?"" Science had little to do with the latter. The two authors are poles apart.",692
frumiousb,5.0 out of 5 stars,"G??del, Escher, Bach: An Eternal Golden Braid","Way out of my comfort zone, but still great.","I'm here to witness that even people as seriously math-challenged as I am can participate in this wonderful book. It took me a *long* time to read-- I flipped back and forth, beat the pages up, asked my more math-oriented friends for help. I spent forever trying to solve the MU exercise. It was worth it. I still feel like I understood parts of it only in intuitive flashes, but those flashes showed me a room more interesting than most of the well-lit chambers ordinary books provide.
Reading Godel, Escher, Bach is like joining a club. People who see you reading it will open spontaneous conversations and often gift you with unexpected insights. (I had a fascinating conversation with a total stranger about Godel's theorem.)
Wish I could give more than five stars.",500
James B. Delong,5.0 out of 5 stars,Code: The Hidden Language of Computer Hardware and Software,Best Book I've Read This Year,"I think that this is the best book that I have read all year. In some sense this is the book that I have been looking for for twenty-five years--the book that will enable me to understand how a computer does what it does. And--given the centrality of computers in our age--it has been a long wait. But now it is over. Charles Petzold (1999), Code: The Hidden Language of Computer Hardware and Software does a much better job than anything else I have ever seen in explaining computers--what they really are, and how they really work.
Have you ever wondered just how your computers really work? I mean, really, really work. Not as in ""an electrical signal from memory tells the processor the number to be added,"" but what the electrical signal is, and how it accomplishes the magic of switching on the circuits that add while switching off the other circuits that would do other things with the number. I have. I have wondered this a lot over the past decades.
Yet somehow over the past several decades my hunger for an explanation has never been properly met. I have listened to people explain how two switches wired in series are an ""AND""--only if both switches are closed will the lightbulb light. I have listened to people explain how IP is a packet-based communications protocol and TCP is a connection-based protocol yet the connection-based protocal can ride on top of the packet-based protocol. Somehow these explanations did not satisfy. One seemed like answering ""how does a car work?"" by telling how in the presence of oxygen carbon-hydrogen bonds are broken and carbon dioxide and water are created. The other seemed like anwering ""how does a car work"" by telling how if you step on the accelerator the car moves forward.
Charles Petzold is different. He has hit the sweet spot exactly. Enough detail to satisfy anyone. Yet the detail is quickly built up as he ascends to higher and higher levels of explanation. It remains satisfying, but it also hangs together in a big picture.
In fact, my only complaint is that the book isn't long enough. It is mostly a hardware book (unless you want to count Morse Code and the interpretation of flashing light bulbs as ""software."" By my count there are twenty chapters on hardware, and five on software. In my view only five chapters on software--one on ASCII, one on operating systems, one on floating-point arithmetic, one on high-level languages, and one on GUIs--is about ten too few. (Moreover, at one key place in his explanation (but only one) he waves his hands. He argues that it is possible to use the operation codes stored in memory to control which circuits in the processor are active. But he doesn't show how it is done.)
Charles Petzold's explanatory strategy is to start with the telegraph: with how opening and closing a switch can send an electrical signal down a wire. And he wants to build up, step by step, from that point to end with our modern computers. At the end he hopes that the reader can look back--from the graphical user interface to the high-level language software constructions that generate it, from the high-level language software constructions to the machine-language code that underlies it, from the machine-language code to the electrical signals that load, store, and add bits into the computer's processor and into the computer's memory.
But it doesn't stop there. It goes further down into how to construct an accumulator or a memory bank from logic gates. And then it goes down to how to build logic gates--either out of transistors or telegraph relays. And then deeper down, into how the electrons actually move through a transistor or through a relay and a wire.
And at the end I could look back and say, yes, I understand how this machine works in a way that I didn't understand it before. Before I understood electricity and maybe an AND gate, and I understood high level languages. But the whole vast intermediate realm was fuzzy. Now it is much clearer. I can go from the loop back to the conditional jump back to the way that what is stored in memory is fed into the processor back to the circuits that set the program counter back to the logic gates, and finally back to the doped silicon that makes up the circuit.
So I recommend this book to everyone. It is a true joy to read. And I at least could feel my mind expanding as I read it.",374
dc,2.0 out of 5 stars,Pattern Recognition and Machine Learning (Information Science and Statistics),Thorough but vastly unclear,"I can appreciate others who might think that this is a great book.... but I am a student using it and I have some very different opinions of it.

First, although Mr. Bishop is clearly an expert in Machine Learning, he is also obviously a HUGE fan of Bayesian Statistics. The title of the book is misleading as it makes no mention of Bayes at all but EVERY CHAPTER ends with how all of the chapter's contents are combined in a Bayes method. That's not bad it's just not clear from the title. The title should be appended with ""... using Bayesian Methods""

Second, while it is certainly a textbook, the author clearly has an understanding of the material that seems to undermine his ability to explain it. Though there are mentions of examples there are, in fact, none. There are many graphics and tiny, trivial indicators, but I can't help to think that every single one of the concepts in the book would have benefited from even a single application. There aren't any. I am lead to believe that if you are already aware of many of the methods and techniques that this would be an excellent reference or refresher. As a student starting out I almost always have no idea what his intentions are.

To make matter worse, he occasionally uses symbols that are flat-out confusing. Why would you use PI for anything other than Pi or Product? He does. Why use little k, Capital K, and Greek Letter Kappa (a K!) in a series of explanations. He does. He even references articles that he has written... in 2008!!

Every chapter seems to be an exercise to see how many equations he can stuff in it. There are 300 in Chapter 2 alone. Over and over and over again I have the feeling that he is trying to TELL me how to ride a bicycle when it would have been so much easier to at least let me see the view from behind the handle bars with my feet on the pedals. Chapter five on Neural Nets, for example, is abysmally over-complicated. Would you hand someone a dictionary and ask them to write a poem? (""Hey, all the words you need are in here!"") Of course not.

Third, the book mentions that there is a lot of information available on the web site. The only info available on his website is a brief overview of the text, a detailed overview of the text (that's not a typo.... he has both), an example chapter, links to where the book can be purchased, and (actually, quite useful for creating slides) an archive of all of the figures available in the book. There are no answers to problems or explorations of any part of the material. The upcoming book might be amazing and exactly what I am looking for but it could be months away and another $50 or so to purchase it. Hardly ideal. How about putting some of that MatLab code on your site? *Something* to crystalize the concepts!

Finally, while the intro indicates this might be a good book for Computer Scientists it would actually make more sense to call it a Math book. More specifically a Statistics book. There are no methods, no algorithms, no bits of pseudo-code, and (again) no applications are in the text. Even examples that actually used hard numbers and/or elements from a real problem and explained would be much appreciated.

Maybe I am being a little critical and perhaps I want for too much but in my mind if you are writing a book with the goal of TEACHING a subject, it would be in your interest to make things clear and illustrative. Instead, the book feels more like a combination of ""I am smart. Just read this!"" and a reference text.",367
Damon Deville,2.0 out of 5 stars,Artificial Intelligence: A Modern Approach (3rd Edition),A disappointment: minor update not worth the money,"- With AIMA 1st Edition, I had relearned AI anew from a fresh, insightful and wonderfully pedagogical perspective.
Best computer science textbook ever.
- With AIMA 2nd Edition, I got a lot of recent advances in AI brought to me in the same way, even if pr",356
Book Shark,4.0 out of 5 stars,How to Create a Mind: The Secret of Human Thought Revealed,"Fascinating, Disappointing but Ultimately Enlightening","How to Create a Mind: The Secret of Human Thought Revealed by Ray Kurzweil

""How to Create a Mind"" is a very interesting book that presents the pattern recognition theory of mind (PRTM), which describes the basic algorithm of the neocortex (the region of the brain responsible for perception, memory, and critical thinking). It is the author's contention that the brain can be reverse engineered due to the power of its simplicity and such knowledge would allow us to create true artificial intelligence. The one and only, futurist, prize-winning scientist and author Ray Kurzweil takes the reader on a journey of the brain and the future of artificial intelligence. This enlightening 352-page book is composed of the following eleven chapters: 1. Thought Experiments on the World, 2. Thought Experiments on Thinking, 3. A Model of the Neocortex: The Pattern Recognition Theory of Mind, 4. The Biological Neocortex, 5. The Old Brain, 6. Transcendent Abilities, 7. The Biologically Inspired Digital Neocortex, 8. The Mind as Computer, 9. Thought Experiments on the Mind, 10. The Law of Accelerating Returns Applied to the Brain, and 11. Objections.

Positives:
1. Well researched and well-written book. The author's uncanny ability to make very difficult subjects accessible to the masses.
2. A great topic in the ""mind"" of a great thinker.
3. Great use of charts and diagrams.
4. A wonderful job of describing how thinking works.
5. Thought-provoking questions and answers based on a combination of sound science and educated speculation.
6. The art of recreating brain processes in machines. ""There is more parallel between brains and computers than may be apparent."" Great stuff!
7. Great information on how memories truly work.
8. Hierarchies of units of functionality in natural systems.
9. How the neocortex must work. The Pattern Recognition Theory of Mind (PRTM). The main thesis of this book. The importance of redundancy. Plenty of details.
10. Evolution...it does a brain good. Legos will never be the same for me again.
11. The neocortex as a great metaphor machine. Projects underway to simulate the human brain such as Markram's Blue Brain Project.
12. Speech recognition and Markov models. Author provides a lot of excellent examples.
13. The four key concepts of the universality and feasibility of computation and its applicability to our thinking.
14. A fascinating look at split-brain patients. The ""society of mind."" The concept of free will, ""We are apparently very eager to explain and rationalize our actions, even when we didn't actually make the decisions that led to them."" Profound with many implications indeed.
15. The issue of identity.
16. The brain's ability to predict the future. The author's own predictive track record referenced.
17. The laws of accelerating returns (LOAR), where it applies and why we should train ourselves to think exponentially.
18. The author provides and analyzes objections to his thesis. In defense of his ideas. Going after Allen's ""scientist's pessimism.""
19. The evolution of our knowledge.
20. Great notes and links beautifully.

Negatives:
1. The book is uneven. That is, some chapters cover certain topics with depth while others suffer from lack of depth. Some of it is understandable as it relates to the limitations of what we currently know but I feel that the book could have been reformatted into smaller chapters or subchapters. The book bogs down a little in the middle sections of the book.
2. Technically I disagree with the notion that evolution always leads to more complexity. Yes on survival but not necessarily on complexity.
3. The author has a tendency to cross-market his products a tad much. It may come across as look at me...
4. A bit repetitive.
5. Sometimes leaves you with more questions than answers but that may not be a bad thing...
6. No formal separate bibliography.

In summary, overall I enjoyed this book. Regardless of your overall stance on the feasibility of artificial intelligence no one brings it like Ray Kurzweil. His enthusiasm and dedication is admirable. The author provides his basic thesis of how the brain works and a path to achieve true artificial intelligence and all that it implies. Fascinating in parts, bogs down in other sections but ultimately satisfying. I highly recommend it!

Further suggestions: ""Subliminal: How Your Unconscious Mind Rules Your Behavior"" by Leonard Mlodinow, ""The Believing Brain: From Ghosts and Gods to Politics and Conspiracies---How We Construct Beliefs and Reinforce Them as Truths"" by Michael Shermer, ""The Scientific American Brave New Brain: How Neuroscience, Brain-Machine Interfaces, Neuroimaging, Psychopharmacology, Epigenetics, the Internet, and ... and Enhancing the Future of Mental Power"" by Judith Horstman, ""The Blank Slate: The Modern Denial of Human Nature"" by Steven Pinker, ""Who's in Charge?: Free Will and the Science of the Brain"" and ""Human: The Science Behind What Makes Us Unique"", by Michael S. Gazzaniga, ""Hardwired Behavior: What Neuroscience Reveals about Morality 1st Edition by Tancredi, Laurence published by Cambridge University Press Paperback"" by Laurence Tancredi, ""Braintrust: What Neuroscience Tells Us about Morality"" by Patricia S. Churchland, ""The Myth of Free Will"" by Cris Evatt, ""SuperSense"" by Bruce M. Hood and ""The Brain and the Meaning of Life"" by Paul Thagard.",296
John St John,3.0 out of 5 stars,The Singularity Is Near: When Humans Transcend Biology,Brave New World,"To say that Mr. Kurzweil is a bit of an optimist is like saying Shaq is a bit on the tall side. Mr K is positively bubbling with enthusiasim. Had it not been taken by Joe Namath a suitable title might have been ""The Future's So Bright I Just Gotta Wear Shades"". But therein lies the problem. Mr K comes across more like a passionate evangelical than a reasoned scientist. Whenever someone is absolutley convinced about the rightness of his assumptions I become skeptical.

If you're reading this you know the premise of the book. Mr. K maintains that the pace of technological change (and by technology he means the really cool technologies, like infotech, biotech, and nanotech) is not simply increasing, but increasing exponentially, so fast that we will soon reach a point where man and machine have become one, and are brains are a million (or maybe a billion) times more powerful. When this happens everything we know will have changed forever.

Moreover, this is not someting that will happen at some vague time in the far future. It's just around the corner. Mr. K even gives us a date: 2045.

While reading the book I kept thinking, What if Mr. K had written this in the mid 1950's? Certainly he'd have backup for his basic premise--the changes that occured in the first half of the 20th century were indeed tremendous. Take aviation, a hot technology in those days. Mr. K would no doubt have observed that we went from Kitty Hawk to the Boeing 707 in just 50 years. Projecting ahead, Mr. K would have concluded that the second half of the century would see an even greater rate of advancement, so that by now we'd all have our own personal flying devices, zipping off to Europe in just minutes.

But that hasn't happened. Certainly there has been signigicant progress in aviation in the last 50 years, but not like the 50 years before that. In some says it's worse. I suspect that since 9/11 the time it takes to fly from Los Angeles to San Francisco (from the time you get to one airport to the time you leave the other) may be longer now than it was in the 1950's.

Why has this happened? A lot of this has to do with social conditions, not technological ones. Supersonic trasport never got off the ground (so to speak) in part because people didn't want the sonic booms near populated areas. These same social factors may well put the brakes on a lot of what Mr. K predicts.

It's not that Mr. K's book isn't based on hard science. It's positively larded with science, so much so that my eyes tended to glaze over many times. It's just that he doesn't seem very critical. While he does acknowledge the existence of contrary opinion, he quickly (albeit politely) dismisses any cautionary thoughts. Those who disagree with his beliefs are clearly stuck-in-the-mud, nay-saying Luddites.

Mr K is obviously a brilliant, well-informed scientist. I don't have enough knowledge to judge the accuracy of his facts, except in a few situations. When that does occur, though, I become unimpressed. For example, he spends a few pages talking about the increases that have occured in life expectancy, and uses this to project further increases to 150 years and then to 500 years. But he fails to distinguish between life exoectancy and life span. The former has indeed increased, but the latter has not. I am certain Mr. K knows the difference. His failure to make the distinction is misleading and disingenuous. It makes me wonder about the veracity of the rest of the book.

As to the book itself, it's far too long. He repeats his points so much it seems as though he thinks that by mere repetition the reader will become more convinced that he's right. And some parts of the book are simply annoying, like the smug pseudo-conversations among past, present, and future personages that appear throughout the work.

To his credit, though, his optimisim about the future is refreshing, and certainly an antidote to the dystopian views typical in literature and Hollywood (Brave New World, 1984, Blade Runner, Mad Max, The Terminator, Waterworld, etc.).

The bottom line here is that Mr. K. doesn't seem to remember that virtually all predictions about the future are wrong, since the predictions are simply extrapolations of current trends. The future is never what we think it will be, and Mr. K is no exception.

Then again, he could be right. If so, I just hope I can live long enough to enjoy the sigularity, so I can have my body filled with nanobots and my brain uploaded to (as he would say) a suitable substrate. Maybe being a cyborg won't be so bad.",292
Sidhant,3.0 out of 5 stars,Pattern Recognition and Machine Learning (Information Science and Statistics),"Great Insights, but a hard read","This new book by Chris Bishop covers most areas of pattern recognition quite exhaustively. The author is an expert, this is evidenced by the excellent insights he gives into the complex math behind the machine learning algorithms. I have worked for quite some time with neural networks and have had coursework in linear algebra, probability and regression analysis, and found some of the stuff in the book quite illuminating.

But that said, I must point out that the book is very math heavy. Inspite of my considerable background in the area of neural networks and statistics, I still was struggling with the equations. This is certainly not the book that can teach one things from the ground up, and thats why I would give it only 3 stars. I am new to kernels, and I am finding the relevant chapters difficult and confusing. This book wont be very useful if all you want to do is write machine learning code. The intended audience for this book I guess are PhD students/researchers who are working with the math related aspects of machine learning. Undergraduates or people with little exposure to machine learning will have a hard time with this book. But that said, time spent in struggling with the contents of this book will certainly pay-off, not instantly though.",208
Evan Miller,5.0 out of 5 stars,Data Smart: Using Data Science to Transform Information into Insight,"Insightful, practical, and colorful. Perspective from a biased reviewer.","Disclaimer: I served as a paid technical editor for Data Smart. I am not affiliated with the publisher, but I did receive a small fee for double-checking the book's mathematical content before it went to press. I also went to elementary school with the author. So as you read the rest of the review, keep in mind that this reviewer's judgment could be clouded by my lifelong allegiance to Lookout Mountain Elementary School, as well as the Scarface-esque pile of one dollar bills currently sitting on my kitchen table.

Anyway, books about ""Data"" seem to fit into one of the following categories:

* Extremely technical gradate-level mathematics books with lots of Greek letters and summation signs

* Pie-in-the-sky business bestsellers about how ""Data"" is going to revolutionize the world as we know it. (I call these ""Moneyball"" books)

* Technical books about the hottest new ""Big Data"" technology such as R and Hadoop

Data Smart is none of these. Unlike ""Moneyball"" books, Data Smart contains enough practical information to actually start performing analyses. Unlike most textbooks, it doesn't get bogged down in mathematical notation. And unlike books about R or the distributed data blah-blah du jour, all the examples use good old Microsoft Excel. It's geared toward competent analysts who are comfortable with Excel and aren't afraid of thinking about problems in a mathematical way. It's goal isn't to ""revolutionize"" your business with million-dollar software, but rather to make incremental improvements to processes with accessible analytic techniques.

I don't work at a big company, so I can't attest to the number of dollars your company will save by applying the book's methods. But I can attest that the author makes difficult mathematical concepts accessible with his quirky sense of humor and gift for metaphor. For example, I previously had not been exposed to the nitty-gritty of clustering techniques. After a couple of hours with the clustering chapters, which include illuminating diagrams and spreadsheet formulas, I felt like I had a good handle on the concepts, and would feel comfortable implementing the ideas in Excel -- or any other language, for that matter.

What I like most about the book is that it doesn't try to wave a magic data wand to cure all of your company's ills. Instead it focuses on a few areas where data and analytic techniques can deliver a concrete benefit, and gives you just enough to get started. In particular:

* Optimization techniques (Ch. 4) can systematically reduce the cost of manufacturing inputs

* Clustering techniques (Ch. 2 and 5) can deliver insights into customer behavior

* Predictive techniques (Ch. 3, 6, and 7) can increase margins with better predictions of uncertain outcomes

* Forecasting techniques (Ch. 8) can reduce waste with better demand planning

It may take some creativity to figure out how to apply the methods to your own business processes, but all of the techniques are ""tried and true"" in the sense of being widely deployed at large companies with big analytics budgets and teams of Ph.D.'s on staff. This book's contribution is to make these techniques available to anyone with a little background in applied mathematics and a copy of Excel. For that reason, despite the absence of glitter and/or Jack Welch on the book's cover, I think Data Smart is an important business book.

I had a few criticisms of the book as I was reading drafts, but almost all of them were addressed before the final revision. For the sake of completeness, I'll tell you what they were. Some of the chapters ran on a bit long, but these have been split up into manageable pieces. The Optimization chapter is a bit of a doozie, and used to be at the very beginning, but the reader can now ""warm up"" with some easier chapters on clustering and simple Bayesian techniques. The Regression chapter originally didn't discuss Receiver Operating Characteristic curves, which are important for evaluating predictive models visually, but now ROC curves are abundant.

Only one real criticism from me remains: I would have liked to see more on quantile regression, which is only mentioned in passing. It's a great technique for dealing with outlier-heavy data. The book by Koenker has good but highly mathematical coverage, and I would have loved to see this subject given the Foreman treatment. But, you can't have everything, and I suppose John needs to leave some material for Data Smart 2: The Spreadsheet of Doom.

In sum, Data Smart is a well-written and engaging guide to getting new insights from data using familiar tools. The techniques aren't really cutting-edge -- in fact, most have been around for decades -- but to my knowledge this is the first time they've been presented in a way that Excel-slinging business analysts can apply the methods without needing her own team of operations researchers and data scientists. If you're not sure whether the book's sophistication is on par with your own skills, you can download a complete sample chapter (as well as example spreadsheets) from the author's website.

One last thing: unlike many books with a technical bent, the prose is engaging and extremely clear. I think this can be traced to John's childhood. When John misbehaved, his father (who is a professor of English) would punish John by forcing him to read a novel by Charles Dickens. Minor infractions resulted in A Christmas Carol being meted out, and when he was really bad he had to read Great Expectations. This is a true story which you should ask John about if you see him at a book-signing event.",208
Dr. Lee D. Carlson,5.0 out of 5 stars,The Singularity Is Near: When Humans Transcend Biology,Technophilic ecstacy,"The author is definitely one of the most inspiring of all researchers in the field of applied artificial intelligence. For those, such as this reviewer, who are working ""in the trenches"" of applied AI, his website is better than morning coffee. One does not have to agree with all the conclusions reached by the author in order to enjoy this book, but he does make a good case, albeit somewhat qualitative, for the occurrence, in this century, of what he and other futurists have called a `technological singularity.' He defines this as a period in the future where the rate of technological change will be so high that human life will be `irreversibly transformed.' There is much debate about this notion in the popular literature on AI, but in scientific and academic circles it has been greeted with mixed reviews. Such skepticism in the latter is expected and justified, for scientists and academic researchers need more quantitative justification than is usually provided by the enthusiasts of the singularity, which in this book the author calls ""singularitarians."" Even more interesting though is that the notion of rapid technological change seems to be ignored by the business community, who actually stand to gain (or lose) the most by it.

Since this book is aimed primarily at a wide audience, and not professional researchers, the author does not include detailed arguments or definitions for the notion of machine intelligence or a list of the hundreds of examples of intelligent machines that are now working in the field. Indeed, if one were to include a discussion of each of these examples, this book would swell to thousands of pages. There are machines right now used in business and industry that can manage, troubleshoot, and analyze networks, diagnose illnesses, compose music definitely worth listening to, choreograph dances, simulate human behavior in computer games, recommend and engage in financial transactions and bargaining, and many, many other tasks, a detailed list of which would, again, entail many thousands of pages.

There are various psychological issues that arise when discussing machine intelligence, which if believed might prohibit the acceptance of any kind of notion of a technological singularity. For example, it is one of the historical peculiarities of research in AI that advances in the field are later trivialized, i.e. when a problem in AI becomes solved it no longer holds any mystery and is then considered to be just another part of information processing. It is then no longer regarded as `intelligent' in any sense of the term. This phenomenon in AI research might be called the ""Michie-McCorduck-Hofstader effect"", named after the three individuals, Donald Michie, Barbara McCorduck, and Douglas Hofstader, who discussed it some detail in their writings. If one examines the history of AI, one finds many examples of this effect, such as in knowledge discovery from databases, the use of business rules in database technologies, and the use of ontologies for information systems development. One of the best examples of this effect though is the backgammon player TD-Gammon, a highly sophisticated example of machine intelligence but which is now considered to be merely part of the ""programmer's toolbox."" The Michie-McCorduck-Hofstader effect is important in discussing the notion of a technological singularity since if one does occur this effect would diminish one's ability to recognize it as being real. The author does not name this phenomenon as such in the book, but a reading of it definitely reveals that he is aware of the skepticism expressed by many towards any ""advances"" in machine intelligence.

Another one of these psychological issues regards the attitude of many philosophers on the notion of machine intelligence. In most cases they are extremely skeptical, and many AI researchers seem to feel the need to ""refute"" their opinions on the ""impossibility"" of intelligent machines. Unfortunately the author is one of these, and devotes space in the book to counter various philosophical arguments against AI. His arguments, although valid, are really a waste of time though. Such time would be better spent, both for the author and for AI researchers, in the actual development of intelligent machines. A moratorium should be declared among AI researchers on all philosophical speculation. Such musings are best left to professional philosophers, who have the time and the inclination to indulge themselves in them.

There are other issues that should have been given more attention in the book, such as more details on the energy requirements needed to bring about such a singularity. In addition, the author needs to sharpen just what he means by intelligence and move away from the Turing test/human brain benchmark that he uses in the book. There are many examples of intelligence in the natural world, and these can and have been emulated in many different types of machines. Interestingly, the fixation on human intelligence and the reverse engineering of the human brain (that is exemplified in this book) has inspired a few research teams to attempt to build a machine of ""general intelligence"", i.e. one that can think in many different domains, as clearly humans can. But it is still an open question whether this intelligence is ""entangled"" over these domains, i.e. whether or not a decrease in ability in one domain will affect the ability in another. From an evolutionary or efficiency standpoint it would seem that that domain specific intelligence is more optimal.

The notion of a technological singularity can be met with both exhilaration and a sense of foreboding, since (radical) change can be embraced with enthusiasm and with some feelings of anxiety. Even the author expresses this when he writes in the book that he is not ""entirely comfortable"" with all the consequences of a technological singularity. He has though made a fairly strong case for rapidly accelerating change. If the book concentrated more on the actual examples of intelligent machines and included the enormous amount of data from activities in applied AI that are now going on, an even stronger case could be made.",200
I Teach Typing,5.0 out of 5 stars,An Introduction to Statistical Learning: with Applications in R (Springer Texts in Statistics),wonderful but watch the movie,"This is a wonderful book written by luminaries in the field. While it is not for casual consumption, it is a relatively approachable review of the state of the art for people who do not have the hardcore math needed for The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Second Edition (Springer Series in Statistics). This book is the text for the free Winter 2014 MOOC run out of Stanford called StatLearning (sorry Amazon will not allow me to include the website). Search for the class and you can watch Drs. Hastie and Tibshirani teach the material in this book.",198
Bruce Gregory,5.0 out of 5 stars,On Intelligence,Simply Indispensable,"It is not very often that you encounter a book that alters, not simply what you think, but how you look at the world. On Intelligence is such a book. Jeff Hawkins develops a perspective on intelligence that makes sense of much of what I have discovered about learning over the past twenty years. His focus is on a unified model of how the cortex works, but in truth you do not need to have deep interest in neurobiology to see the power of the model. The book is very clear and readable, something I have learned to associate with Sandra Blakeslee's deft touch (see, for example, Phantoms In the Brain, by Ramachandran and Blakeslee). The heavy lifting occurs in the lengthy sixth chapter, ""How the Cortex Works."" You might want to skim this chapter or even omit it entirely on your first reading. It is well written, but requires a very thoughtful reading. The model Hawkins develops in this chapter underpins his view of intelligence, but it is not necessary to grasp the details to appreciate the power of the vision. If you have the slightest interest in the role of the brain in making us who we are, you owe it to yourself to read this book. I couldn't recommend it more highly.",194
Syd Logan,4.0 out of 5 stars,Programming Collective Intelligence: Building Smart Web 2.0 Applications,Putting Theory into Practice,"This book is probably best for those of you who have read the theory, but are not quite sure how to turn that theory into something useful. Or for those who simply hunger for a survey of how machine learning can be applied to the web, and need a non-mathematical introduction.

My area of strength happens to be neural networks (my MS thesis topic was in the subject), so I will focus on that. In a few pages of the book, the author describes how the most popular of all neural networks, backpropagation, can be used to map a set of search terms to a URL. One might do this, for example, to try and find the page best matching the search terms. Instead of doing what nearly all other authors will do, prove the math behind the backprop training algorithm, he instead mentions what it does, and goes on to present python code that implements the stated goal.

The upside of the approach is clear -- if you know the theory of neural networks, and are not sure how to apply it (or want to see an example of how it can be applied), then this book is great for that. His example of adaptively training a backprop net using only a subset of the nodes in the network was interesting, and I learned from it. Given all the reading I have done over the years on the subject, that was a bit of a surprise for me.

However, don't take this book as being the ""end all, be all"" for understanding neural networks and their applications. If you need that, you will want to augment this book with writings that cover some of the other network architectures (SOM, hopfield, etc) that are out there. The same goes for the other topics that it covers.

In the end, this book is a great introduction to what is available for those new to machine learning, and shows better than any other book how it applies to Web 2.0. Major strengths of this book are its broad coverage, and the practicality of its contents. It is a great book for those who are struggling with the theory, and/or those who need to see an example of how the theory can be applied in a concise, practical way.

To the author: I expect this book will get a second edition, as the premise behind the book is such a good one. If that happens, perhaps beef up the equations a bit in the appendix, and cite some references or a bibliography for those readers interested in some more in depth reading about the theory behind all these wonderful techniques. (The lack of a bibliography is why I gave it 4 stars out of 5, I really think that those who are new to the subject would benefit greatly from knowing what sits on your bookshelf.)",184
Bob Blum,4.0 out of 5 stars,How to Create a Mind: The Secret of Human Thought Revealed,The Cortex Spins its Tales with Hidden Markov Models,"Like a news commentator explaining a bad day on Wall Street,
the cortex has an explanation for everything -
it generates our subjective universe. To paraphrase George Box,
all our brain's models of the world are wrong,
but some are useful, generative, and simple (but not too simple).

In How to Create a Mind acclaimed inventor Ray Kurzweil
puts forth a model of how the brain works:
the pattern recognition theory of mind (PRTM).
The brain successively interiorizes the world as a set of patterns.

Kurzweil's framework uses hierarchical hidden Markov models (HHMMs)
as its main stock in trade. HHMMs add to the PRTM model the notion
that those patterns are arranged into a hierarchy of nodes,
where each node is an ordered sequence of probabilistically matched lower nodes.

So, the key question for me is this: are HHMMs
really the key to understanding and building a mind?

Ray has been on this track since the sixties,
when he and I were classmates at MIT. In a spectacular
career spanning decades, Ray invented systems for OmniPage OCR,
text to speech (famously for Stevie Wonder), and
automated speech recognition as in Dragon Naturally Speaking.
Nuance bought Ray's precursor company.

All automatic speech recognition nowadays is done using HHMMs,
and the results are astounding. For example, see Microsoft Research
Chief Rick Rashid's YouTube ""Speech Recognition Breakthrough.""
A computer transcription of Rick's talk appears in
real time and is quite accurate.

The amazing success of HHMMs in handling speech and language is
a story that needs to be understood by AI aficionados, and
Kurzweil presents this topic in a beautifully comprehensible exposition.

Kurzweil elaborates a story here that 1) the cortex is
the key to thought; 2) it is hierarchically organized into
300 million pattern recognizers; 3) each pattern recognizer
consists of a 100 neurons in a vertical minicolumn, and
4) those pattern recognizers communicate with one another
via a Manhattan-like grid (similar to an FPGA) -
end of story for the neocortex.

This is a story similar to the one told by entrepreneur Jeff Hawkins in
On Intelligence, and one that Hawkins, his former associate Dileep George
(now at Vicarious), and Kurzweil himself are trying to capitalize on
in cortex-engineering startups. I eagerly follow their results.

So, HHMMs work well and are a required part of a computational
neuroscience curriculum, but ARE THEY THE MASTER KEY that will unlock
the doors not only to a full understanding of the mind
but also to a future of superintelligent AIs? How to Create a Mind
is a good story but IS IT FICTION or nonfiction?

While HHMMs are required reading for automatic speech recognition,
they DO NOT DO all the brain's heavy-lifting. Rather, the brain employs
MANY mechanisms (which robots that aspire to humanity
may need to incorporate or emulate.)

Five stars for HHMM exposition. Subtract one star for giving short shrift
to the following pivotal neuroscience principles: 1) attentional mechanisms,
2) brain-wide dynamical networks, 3) gamma oscillations and inhibitory networks
and also 5) the role of insula and brain stem in emotion, 6) reward based learning
including the essential role of basal ganglia and midbrain,
and 7) hippocampus and memory.

Despite its corticocentric focus, Kurzweil's impressive engineering
successes make this an important story; furthermore, it is engagingly told.
I cover neuroscience and AI at bobblum.com . Below are two recent 'DO NOT MISS'
FIVE STAR stories.)

Addendum: 30 Nov 2012 - Today's issue of SCIENCE (and Ray K's newsletter)
features a story about a new 2.5M spiking neuron model (SPAUN) that
performs 8 tasks and outputs to a physically modeled arm.
See the videos at NENGO > Videos > Collection of Spaun.
That is the state of the art!

Addendum: Jan 2013: Want to know where the brain stores meaning? (YOU DO!)
See Alex Huth's 5 min YouTube from Jack Gallant's lab. Search:
Alex Huth, gallantlabucb ""Perceptual Object and Action Maps in the Human Brain.""",155
Abacus,5.0 out of 5 stars,The Psychology of Judgment and Decision Making (McGraw-Hill Series in Social Psychology),Excellent and insightful.,"This is a fascinating book analyzing how we are all far less Cartesian than we think. In other words, a slew of predictable human bias flaws what we feel is our own objective judgment. The author eminently demonstrates this point by forcing the reader to take a 39 questions test at the beginning of the book. This test is stuffed with all the traps that illustrate the human judgment flaws that he analyzes thoroughly in following specific chapters.
You can view the test as a very entertaining IQ test from hell. The questions seem often simple. But, they are not. Other times, they are obviously difficult. I got a bit more than half of them correct. This was mainly because I had some knowledge or experience regarding certain traps the questions presented. I had made the mistake before. So, I learned from that. When I did not have any prior knowledge of a question, my results were very human, meaning not that good. But, learning the correct answer was both fun and educating.
The author touches on several fascinating probability and statistic concepts. One of them being the Bayes theorem, which suggests that medical screen test can be highly unreliable despite being touted as 80% to 90% accurate. In other words, you better understand the Bayes theorem better than the medical specialists who screen you for various diseases. Because, based on the author's study, doctors don't have a clue. Another chapter had an excellent discussion on correlation vs. causation. This includes some tricky nuances that many analysts in the financial industry trip upon. Another interesting probability concept is why it takes only 23 people in a room to have greater than a 50% that two of them share the same birthday. This seems impossible, but it is true.
The book has obviously a lot more than I am letting on here. I am not going to ruin it for you. It is really fun, educating, and interesting to read. You will also learn a whole lot about how you think, how others think, and how people think in groups. You will also understand how tricky it is to ask truly open and objective questions. Also, polls that seem objective are not due to the subjective structure of the question. I think you will enjoy this book, and I strongly recommend it.",150
Voracious Reader,3.0 out of 5 stars,Machine Learning for Hackers: Case Studies and Algorithms to Get You Started,Machine Learning for Non-Hackers,"By page count, this is primarily a book on R, with some additional time spent on machine learning.

There is way too much time spent on R, dedicated to such things as parsing email messages, and spidering webpages, etc. These are things that no-one with other tools available would do in R. And it's not that it's easier to do it in R, it's actually harder than using an appropriate library, like JavaMail. And yet, while much time is spent in details, like regexes to extract dates (ick!), more interesting R functions are given short shrift.

There's some good material in here, but it's buried under the weight of doing everything in R. If you are a non-programmer, and want to use only one hammer for everything, then R is not a bad choice. But it's not a good choice for developers that are already comfortable with a wider variety of tools.

I'd recommend Programming Collective Intelligence by Segaran, if you would describe yourself as a ""Hacker"".",147
Klaus Stiefel,1.0 out of 5 stars,The Singularity Is Near: When Humans Transcend Biology,The singularity is far,"This book is very well known, and the question how many of the rather rapidly advancing technological trends will continue and how they will influence humanity's future is a very interesting one. So I bought the book and read it. I found it much, much weaker than I had anticipated it to be.

Ray Kurzweil wrote a thick volume combining 50's style naive technology-optimism, uncritical extrapolation of current trends (especially, but not only, Moore's law) and somewhat-more-than-half knowledge of biology. He assembles all of that into his own personal pseudo-religion, and even uses a terminology that sounds very religious (He calls himself a ""singulatarian""). According to Kurzweil, all will be well: hunger, disease, aging and even death will be eradicated once we fuse with computers and have nano-robots populate our bloodstreams. Even wars will be less bloody - he includes a graph of declining US war deaths over time, conveniently ignoring the numbers of foreign human beings killed by the US in these wars.

In most cases, his arguments are not very sound, in my opinion. One problem is that he strongly believes that all the current technological trends will continue to accelerate, disregarding physical boundaries and resource constraints. Often his argument goes as in: X has been achieved. Therefore XX is maybe, theoretically possible, said some expert. Once we have XX, we will be able to achieve YY. Hence, YY is about to become reality within a decade.

In my own field, neurobiology, he mistakes models (intellectual tools to explain certain aspects of a phenomenon) with complete, reverse engineered, functional reproductions of neural systems. There are certainly good models out there, but no neural structure has so far been reverse engineered, not even close.

Always suspicious: the use of quotations of old or dead wise men to cover up the lack of content in a book. Just because someone managed to look up what Ein- or Wittgenstein once said, that does not make his arguments stronger, does it? But, it leaves the reader in this aura of just having being confronted with the words of these intellectual giants, and some of that must rub off to what the author had to say, no? Kurzweil wins Olympic gold in name-dropping with ""The singularity is near"", where there are rarely less than three quotations in front of a chapter, and whole chapters are only made up of quotations, nothing else!

This is in fact a rather involuntarily interesting book. Why does a member of the US upper class come up with a technology based salvation story? I think what we have here is an extremely interesting fusion of the American believe in the power of technology to solve problems with the strong US religious tradition.",144
James David Morris,2.0 out of 5 stars,"Superintelligence: Paths, Dangers, Strategies",Very little actual insight into super intelligence,"I'm a long-time fan of all things AI, and for example, I'd give 4-5 stars to ""How to Create a Mind"" by Ray Kurzweil.

This book needed an editor who could understand the difference between useful insight and mindless spouting off of sentences. There are thousands of paragraphs that read like this:

A super intelligence might have a deep and rich personality, possessing more humor, more love, and more loyalty than any human, or it might have none of these. If it had these rich personalities then they might not even be recognizable to humans. If they were recognizable, humans may appreciate them. If they are not easily recognized, humans may not appreciate them. It it turns out that they do not have any of these qualities, it may still however appear to humans that they do have them, because of their complexity. But complexity does not necessarily equate to richness. An emotion could be complex, but not deep, or rich. Or, an emotion could be rich, but not complex. In any case, it is not know whether they will indeed have personalities, or simply seem to have them. Nor is it certain how humans may react to their possessing, or lack of, credible emotions.

This type of completely useless information is 80% of the book. It has very little in the realm of real insight, but rather lists every possible possibility direction that could be taken, but then goes nowhere. In fact most of the book could have been written thousands of years ago because all it amounts to is a collection of ""if this then that, or the other. But if not this, then maybe not that or maybe not the other"".

I finished the whole thing just because I love the topic, but I cannot recommend it to anyone. The whole book should have been edited down to 10% of it's size. Then, it would seem like an interesting consideration of the many possible futures. But as it is, it's a nearly unbearable waste of 90% of the time it will take you to get through it.",142
Sean Walker,2.0 out of 5 stars,Artificial Intelligence: A Modern Approach (3rd Edition),"Great book, terrible Kindle conversion","This is an excellent book however I cannot recommend purchasing the Kindle version of this text. It is atrocious. There are subject headings inserted after the subject is spoken about and, quite often, many heading stacked up on top of each other taking up almost an entire page with useless titles that are in the wrong order anyway. There are no page numbers, which is unacceptable for a text that is used by many college AI programs across the country. There are tons of hyphenation errors. The delineations between figure notes and the text are almost imperceptible so it is difficult to tell what text goes where. In general it is difficult to read and navigate due to this horrible Kindle conversion.",141
Daniel,5.0 out of 5 stars,Dark Pools: The Rise of the Machine Traders and the Rigging of the U.S. Stock Market,better than the other HFT books,"This book does 2 things:
(1) goes through the historical events that led to our modern stock market and
(2) tries to explain what is going on in market microstructure.

The book does very well on (1) -- it's really an enjoyable book to read. But on (2) there's almost no information, no analytic discussion about microstructure, and some of the comparisons and conclusions are simply wrong. For example, the Patterson compares the immediate liquidity with the days of the past comparing the top of the book orders and noticing that today you have fewer orders at the top of the book. But this is misleading. In the past when the spread was at least 25 cents (due to regulation, ie, in increments on 1/8ths, but also in part of the gentleman's agreement between specialists to keep the spreads large) and now the spread is mostly 1 cent for most stocks. To compare apples to apples you need to sum up the liquidity on 25 levels in the current market, because basically these 25 levels would have been aggregated into 1 level in the past. Once you do this comparison, it's clear that the order book today has much more immediate liquidity.

In spite of the title, another thing that's missing in the book is a discussion of dark pools. Obviously, there's a much bigger problem with dark pools today than with the lit market, mainly because the dark pools can legally do prop trading (and they do) on the flow they see, but in the same time they are marketing a hidden market. This is simply wrong and should have been discussed.

The author points out that the market is unfair, in the sense knowledge of market micro-structure gives some players an advantage. But the market was never fair. For example, players with knowledge about a stock have an advantage, even if that knowledge is public. The same with micro-structure. The rules of the micro-structure are published. Anybody can read the order types for the exchanges and the information is public. In the past it wasn't the case (specialists had privileges) In today's market the differentiation is more about technical competence and less about specialists born with entitlements. Moreover, the transaction costs for investors are 1-2 orders of magnitude lower than during the time of the specialists. (I've never seen a single study that claims otherwise) In other words, it'd be unfair to draw Kasparov in a chess tournament, but at least you start with the same pieces (which was not the case during the rule of the specialists)

The author also doesn't compare the state of the stock market with our other markets: futures (futures is much cleaner), FX (dirty business, where banks have a separate inter market with tighter spreads for themselves, plus the broken will do prop trades against you) and OTC contracts, say corporate bonds (huge 1% spreads, little liquidity, the bank will own you). In other words the stock market is the most fair, except maybe for futures (1 exchange, no fragmentation, no complicated rules, latency less of an issue), and way more fair than FX and OTC. The few big banks that own the OTC business have a lot to gain from HFT bashing, as they really don't want their business on a lit exchange.

I only give 5 stars because it's an enjoyable book to read and does a good job at (1). Patterson is an outsider, but he did a good job at (1) that it reads like a novel. There are a few competing books about HFT for the average reader and all of them are worse than Pattersen's book:

1. ""All About High-Frequency"" (Durbin) - written by an insider, does reveal a little about market microstructure, but a very introductory book. Readable by anybody.
2. ""Speed Traders"" (Perez) - a book which was quickly assembled as a series of interviews, and Mr Perez is using the book to make a name for himself as a consultant for HFT. (his name is constantly on PR wire and he organizes all sorts of events)
3. ""Broken Markets"" (Arnuk, Saluzzi) - full of factual lies, written by old school specialists that use smarts to trade, which are bitter for losing business with the modernization of the exchanges, and want the fat 25 cents spreads back.

For the technically inclined that want to learn about market microstructure, there are a few more quantitative book, but they are all dry and not much fun to read.",137
Graham H. Seibert,5.0 out of 5 stars,Nine Algorithms That Changed the Future: The Ingenious Ideas That Drive Today's Computers,"A valuable book for computer professionals, designed to be accessible to those who aren't","MacCormick targets this book at intelligent laypeople, folks who use computers but don't have a formal background in either computer science or mathematics. The book's greatest strength is in the examples he structures to illustrate some fairly deep computer concepts using concrete metaphors such as paint mixing and padlocks.

The algorithms he describes include the key insights that have gone into building search engines such as Google and its predecessor Alta Vista, public key cryptography and digital signatures, data compression, error correction, pattern recognition techniques, and relational databases.

The nature of the algorithms varies. Public-key cryptography and digital signatures are based on very elegant mathematics. Many of the other algorithms are simpler, insights into how people work and clever ways of programming. Many of the things he discusses involve whole families of different algorithms. There are lots of different schemes to compress data, each with advantages and disadvantages, most of which work better with some kinds of data than others. The same seems true of error detection and correction techniques. There is a lot of common sense, but nothing he describes in those realms seems like true genius.

I made my living with relational databases. MacCormick does a good job of describing a couple of the tricks that ensure data integrity, which as he explains is absolutely vital to the functioning of a database. Those tricks include a two-phase commit, rollbacks, and transaction logging. I think he did not devote enough explanation to the power of joins, selects, and the other operators that enable a programmer to easily assemble data in a useful format. Working in a relational database involves a major paradigm shift from working one record or transaction at a time to working in parallel with every element in a database which matches certain criteria. This was central to Codd's insight; the guarantee of integrity is simply an essential feature of the implementation of that insight.

I'd recommend the MacCormick brush up on his HL Mencken or PT Barnum. You can go broke overestimating the intelligence of the American people. My guess is that the majority of people with patience enough to go through his examples already know more about computers than he expects. However, even a guy like me who has been working with computers pretty constantly since 1958 and had a passing familiarity with every algorithm he discusses certainly benefits from his illustrations.

How is this important? There should at least be footnotes for the mathematically or computer literate. For instance, he describes modulo arithmetic as ""clock arithmetic."" Every time you past 12 (or the arbitrarily chosen the biggest number, usually prime, on his metaphorical clock, you start over. Just like five hours after eight o'clock is one o'clock.

He uses multiplication to frame out the logic of the concepts of public key cryptography and digital signatures, which are operationally fairly similar. He then switches to exponentiation, which is the method which is really used, because it is not reversible. The book would have been stronger if he had given examples. Just as multiplication has an inverse function, division, exponentiation has a reverse function, logarithms. The difference is that given a number and one of its factors, it is trivial to divide to find the other factor. Conversely, given a number and a modulo exponential of that number, it is difficult to derive the logarithm in a modulo world. I think.

I would have enjoyed an explanation of why the modulo arithmetic works. In his multiplication example he takes advantage of the associative property of multiplication: the order of the operations doesn't matter. The same is true of exponentiation. (5^3)^4 = (5^4)^3. Most college graduates have been exposed to this fact. I would have enjoyed reading an explanation of why it is also true for modulo arithmetic. In other words, if I raise five to the third power,modulo 11, and raise that to the fourth power,modulo 11, please provide a proof of the proposition that all get the same answer as if I did the operations in reverse. In other words, why does the principle of commutativity remained true in a modulo arithmetic world.

These quibbles aside, I will have to say that his paint mixing metaphor for public-key cryptography provides far and away the clearest explanation I have ever read. It is exactly what he intended: something an intelligent layperson could understand. He has a similarly elegant padlock and key metaphor for digital signatures. The strength of his argument falters a bit when he gets into numeric examples. He chooses one digit numbers for simplicity. In doing so he sacrifices communicating intuitively the power of very large numbers.

I have spent a lifetime with programmers, and I don't think I have known one who would have attempted even to explain these algorithms. I wish MacCormick luck with his intelligent laypeople, but I think it will be of most value to people within the profession to understand the tools they work with every day. A valuable book - glad to have it on my shelf.",129
SP,1.0 out of 5 stars,"The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Second Edition (Springer Series in Statistics)",,"I have three texts in machine learning (Duda et. al, Bishop, and this one), and I can unequivocally say that, in my judgement, if you're looking to learn the key concepts of machine learning, this one is by far the worst of the three. Quite simply, it reads almost as a research monologue, only with less explanation and far less coherence. There's little/no attempt to demystify concepts to the newcomer, and the exposition is all over the map. There simply isn't a clear, coherent path that the authors set out to go on in writing a given chapter of this text; it's as if they tried to squeeze every bit of information of the most recent results into the chapter, with little regard to what such a decision might do to the overall readability of the text and the newcomer's understanding. To people who might disagree with me on this point, I'd recommend reading a chapter in Bishop's text and comparing it to similar content in this one, and I think you'll at least better appreciate my viewpoint, if not agree with it.

So you might be wondering, why do I even own the text given my opinion? Well, two reasons: (1) it cost 25 dollars through Springer and a contract they have with my university (definitely look into this before buying on Amazon!), and (2) if you actually already know the concepts, it is quite useful as a summary of what's out there. So to those who understand the basics of machine learning, and also have exposure to greedy algorithms, convex optimization, wavelets, and some other often-utilized methods in the text, this makes for a pretty good reference.

The authors are definitely very well-known researchers in the field, who in particular have written some good papers on a variety of machine learning topics (l1-norm penalized regression, analysis of boosting, to name just two), and thus this book naturally will attract some buzz. It may be very useful to someone like myself who is already familiar with much of what's in the book, or someone who is an expert in the field and just uses it as a quick reference. As a pedagogical tool, however, I think it's pretty much a disaster, and feel compelled to write this as to prevent the typical buyer -- who undoubtedly is buying it to learn and not to use as a reference -- from wasting a lot of money on the wrong text.",124
Kyle,1.0 out of 5 stars,Programming Collective Intelligence: Building Smart Web 2.0 Applications,Outdated,"This is the first time I've actually taken the time to write out a review. I'm sure this book was awesome when it first came out, it is clear, concise and has a nice follow-along structure. However, it has become outdated and it is riddled with either old syntax and errors. I have gotten past most of that though. The worst part is probably that the files that are used in some of the examples are hosted on the authors blog and have been taken down. If he can't be bothered to continue hosting old files for people who may buy the book (or point us to somewhere to get them) we shouldn't be bothered to buy it.",123
Johnyo,1.0 out of 5 stars,Machine Learning: A Probabilistic Perspective (Adaptive Computation and Machine Learning series),Consider Other Options Before Purchasing.,"I'm sure if you are a Google Research Scientist and are not learning the material for the first time, this book is amazing. For everyone else, I would not recommend it. I bought this book for my Fall 2013 COMPSCI 571 class, and I regret it. Before buying this book, consider the following:

1. Take a look at the online Errata. This book is already in it's 3rd printing and it just came out. The list of corrections for this (the 3rd edition) is already mind-numbingly long. The 4th printing coming out this month will surely fix some errors, but there are just too many.
2. Our class has an online forum (for a 100 person class) where we discuss topics, and most questions are either (a) basic topics from the book that no one understood or (b) talking about how one figure in the book has multiple errors associated with it. At first I was really excited to find mistakes and submit them to the Errata - it was like I was part of the book! Now I just get frustrated and have already given up on submitting corrections.
3. Our instructor regrets using this book and modifies the examples before giving them to us in class. Our out of class readings now consist mostly of MetaAcademy.com.
4. There are hardly any worked-through examples, and many of those that are worked through have errors.
5. Many important concepts are skimmed over way too quickly. For example, there is a whole chapter on Logistic regression. However, Logistic regression is covered for exactly 2 pages. Then a weird 3D graph is presented but not explained (a common theme throughout the book is graphs that look absolutely amazing, but which convey little information as to exactly what's going on to a lay-person like me), then the rest of the chapter presents methods for doing the math, which I'm sure are useful in some sense, but I'm still thinking: ""why is this MLE not in closed form, what is a Hessian doing here... and wtf is going on?!""

Most students just got the PDF for free online, and I would highly suggest doing something other than paying $55 for this book.",121
Mac,3.0 out of 5 stars,Our Final Invention: Artificial Intelligence and the End of the Human Era,Ok if you don't know anything about the subject,"If you don't know much about real-world AI research and/or you're totally unfamiliar with the nonfiction concerns about the risks it poses, then this book is a quick and easy read that will make you aware of the basics. However, the author is himself clearly non-technical and has a sensationalist style that feels too much like tabloid writing.

When I started reading it, I began bookmarking pages with passages that struck me as problematic. I thought I might write a short review on my wife's tech blog, or perhaps for LessWrong. But as I read further, I realized there were so many problem areas that I'd never bother to sit down and address them individually. Again, these problems would only matter to a technical audience -- experienced programmers, people with a more-than-passing-interest in AI, and so on.

This is my big problem with the book: It's a critically important subject which deserves better treatment than this. Barrat seems to understand the basic problem well enough, but much of the time I had the feeling his primary goal was hitting a page-count target. For example, most of the section about malware is largely irrelevant to the real problem, but it felt like one of the longer chapters in the book (I didn't bother to confirm this, that's just my impression). His TV documentary background shows at the start of each paragraph: each time I felt like I was coming back from a commercial break. He'll shoot somebody down in one chapter, then use that same person to support his argument in the next. He tosses around concepts like cognitive bias and logical fallacies apparently without realizing the book is mostly one big appeal to authority. There is a very good, very important story here waiting to be told. This book only scratches the surface.

I've been a programmer for 36 years. I played around AI-related things back in the late 80s, and I recently became interested in it again. I believe it has great promise, but I do agree that it is also terrifyingly dangerous (in the ""existential-threat"" sense), and that insufficient attention and respect is being given to the problem. For that reason I'm giving this three stars -- it is a tremendously important subject. If it wasn't for that, I'd probably be one of those ""drive-by"" one- or two-star ""spammers"" Barrat likes to rant about in his replies to less-than-fawning reviews.

If you're non-technical, buy it and read it, and don't stop here. If you're a technical type, hit up the LessWrong website as a good jumping-off point for learning more about what is really going on today. Many more technical people need to be thinking about this, concerned about this, and ultimately *doing something* about it.",116
Michael Tsiappoutas,5.0 out of 5 stars,An Introduction to Statistical Learning: with Applications in R (Springer Texts in Statistics),Excellent Practical Introduction to Learning,"The book provides the right amount of theory and practice, unlike the earlier (venerable and, by now, stable) text authored (partly) by the last two authors of this one (Elements of Statistical Learning), which was/is a little heavy on the theoretical side (at least for practitioners without a strong mathematical background). The authors make no pretense about this either. The Preface says ""But ESL is intended for individuals with advanced training in the mathematical sciences. An Introduction to Statistical Learning (ISL) arose from the perceived need for a broader and less technical treatment of these topics.""

ISL is neither as comprehensive nor as in-depth as ESL. It is, however, an excellent introduction to Learning due to the ability of the authors to strike a perfect balance between theory and practice. Theory is there to aim the reader as to understand the purpose and the ""R Labs"" at the end of each chapter are as valuable (or perhaps even more) than the end-of-chapter exercises.

ISL is an excellent choice for a two-semester advanced undergraduate (or early graduate) course, practitioners trained in classical statistics who want to enter the Learning space, and seasoned Machine Learners. It is especially helpful for getting the fundamentals down without being bogged down in heavy mathematical theory, a great way to kick-off corporate Learning units, or as an aid to help statisticians and learners communicate better.

A needed and welcome addition to the Learning literature, authored by some of the most well respected names in industry and academia. A classic in the making. Recommended unreservedly.
____________________________________________
UPDATE (12/17/2013): Two of the authors (Hastie & Tibshirani) are offering a 10-week free online course (StatLearning: Statistical Learning) based on this book found at Stanford University's Web site (Starting Jan. 21, 2014). They also say that ""As of January 5, 2014, the pdf for this book will be available for free, with the consent of the publisher, on the book website."" Amazing opportunity! Enjoy!
____________________________________________
UPDATE (04/03/2014): I took the course above and found it very helpful and insightful. You don't need the course to understand the book. If anything, the course videos are less detailed than the book. It is certainly nice, though, to see the actual authors explain the material. Also, the interviews by Efron and Friedman were a nice touch. The course will be offered again in the future.",112
Bookworm9765,5.0 out of 5 stars,How to Create a Mind: The Secret of Human Thought Revealed,The Path to True Artificial Intelligence,"In ""How To Create a Mind,"" Ray Kurzweil offers a fascinating and readable overview of his theory of how the human brain works, as well as a road map for the future of artificial intelligence.

Kurzweil makes a compelling argument that choosing the proper scale is critical when approaching the problem of how the brain works. Many skeptics believe that we are no where near understanding or simulating the human brain because of its overwhelming complexity. However, Kurzweil suggests that a complete understanding of the micro-level details (such as individual neurons or even biochemistry) is really not necessary. Instead, the brain can be understood and simulated at a higher level. The book gives many examples in other fields of science and engineering where such a high level approach has produced tremendous progress.

The core of Kurzweil's theory is that the brain is made up of pattern processing units comprised of around 100 neurons, and he suggests that the brain can be understood and simulated primarily by looking at how these lego-like building blocks are interconnected.

The book includes accounts of some of the most important research current research in both brain science and AI, especially the ""Blue Brain Project"" (that is working on a whole brain simulation), and also the work on IBM's Watson (Jeopardy! champion) computer.

Kurzweil continues to assert that we will have human-level AI by around 2029. A typical human brain contains about 300 million pattern processing units, but Kurzeil thinks that AIs of the future might have billions, meaning that machine intelligence would far exceed the capabilities of the human mind.

Ray Kurzweil is clearly an optimist both in terms of the progress he foresees and its potential impact on humanity. If he is even partly right in his predictions then the implications could be staggering. Machines that are as smart, or even smarter, than people could completely transform society, the economy and the job market.",110
Nick Cherney,5.0 out of 5 stars,Robot Building for Beginners,I just built my first robot!!!,"I'm an Electrical Engineer at U.C. I bought this book so I could learn some ""real world knowledge"" about the physical world instead of just theory. I only asked for (and thankfully received) a multimeter, soldering iron, and a cordless dremel drill for Christmas. After reading this book, I now remember why I chose my major--making a robot is a blast!
Being strong on the theory, I didn't learn anything in that regard. On the flip side, David Cook described the basics in a way that anyone could understand. What I really wanted to learn was to be able to put my Christmas presents to use. He spent a chapter just on the multimeter! I loved it. Also, every part of the robot was described in detail. I now know the difference between choosing motors, batteries, transistors, comparitors, diodes, potentiometers, photo-resistors, ect.
When I brought my first creation into my Electromagnetics class yesterday, I of course was asked to give a demonstration. From reading this book (to be honest a total of 3 times), I described everything about it in clear/consise detail. The only part I failed was receiving extra credit. Yes I did try :D.
I couldn't imagine a better book for beginners. There is a website that describes the robot AND the few typos caught (nothing that mattered), ways he took this idea and added a couple more in a similar project, as well as detailing the post construction of robots he's made since then. Cook goes into detail for troubleshooting a potential screw up you may make (If 'X' is happening then you probably did 'Y'). Yes I made one too--thanks for asking.
There is one part I didn't like about the project though--using an M&M's Mini tube to hold the motors. Being so close to Valentine's day, the only selection they had were PINK ones! Oh well, I named in Valentino anyway. I did find myself telling this story though to everyone that commented on my pink robot.
If you want to get into the hobby, buy this book. You can't ask for more. Just be prepared to catch yourself looking in the toy section of Target for lego technic tires when your fiance is wanting to register!!! BTW: you'll also catch yourself babbling on about your experiences in a review about this book too--cause you'll be so D@MN excited about making your first robot!!!",109
J. Thurmond,5.0 out of 5 stars,Robot Building for Beginners,Just what I've been looking for!,"I looked around quite a bit trying to find a robot building book that would take my 14 yr old through the process in a way he could understand. David Cook delivered perfectly. Every other book I looked at seemed either too childish, or alternately, assumed a solid background in electronics. Robot Building for Beginners, like Baby Bear's porridge, is just right!

I studied philosophy in college, so can offer my son no help in building robots. I've seen this book described as a swimming pool that's 5'x5' but 25' deep. That's pretty apt. I like the extensive chapter on components - what they are, how they work - neither my son nor I knew a resistor from a diode before. Also an entire chapter on safety was great from the concerned parent perspective.

The book is long, but covers a lot of ground with very little fluff. In 10 days my son had read up to the chapter where you start building your robot - he had absorbed a ton of information, built a few basic circuits and tested/troubleshot them with a multimeter. Now he's just waiting impatiently for me to set him up with the necessary components to start building (actually he's started scavenging components from dead/unused electronics he comes across; and I'm starting to fear for my DVD player).

I don't think you'll find a better starting point for a novice.",108
Scott Meredith,5.0 out of 5 stars,Our Final Invention: Artificial Intelligence and the End of the Human Era,Light and Tasty!,"Just done the new-ish book Our Final Invention: Artificial Intelligence and the End of the Human Era by James Barrat. It explains the inevitably of super-intelligent machines evolving to the point of wiping out all biological life in the galaxy - with opening day coming soon to a species near you (yours).

First off I have to say this is a very enjoyable read. This guy has the kind of snappy, crisp, slightly sarcastic, slightly smartass style that I enjoy. He has some sense of humor. (That's a human trait right there which I bet our smarty-pants AI Overlords won't be able to replicate convincingly.)

So it's fun. And though as somebody with a doctorate from MIT earned through cross-disciplinary work in Theoretical Linguistics, Computational Linguistics at the MIT AI Lab, and speech modeling at the MIT Research Laboratory of Electronics, not to mention my 25 years as a Senior Researcher in high tech for companies including IBM, Apple, and Microsoft I can claim to know some few things about this subject, yet still I learned a lot about the current state of the art from this guy. He particularly emphasizes the small attempted counterweigth efforts to offest Kurzweil's manic robotic boosterism for his uptopian Singularity, which boils down basically to a few guys chatting over the interet about how to create ""Friendly AI"".

Well ... good luck suckers! ... seems to be the author's final conclusion on the dim hope that super intelligent systems could be constrained to maintain a commitment ot honor any kind of human moral values over many interations of recursive upgrading and exponentially awesome self-agrandizement.

Basically these machines will end up as gods. Gods are well-known to possess the following attributes: omniscience, omnipresence, and omnipotence. Given that, they won't hate us but they are just going to grind up as a minor by-product of their quest for galatic expansion and domination.

Oh, and did I say something about ""human moral values"" above? Ha! Barrat takes that whole thing on in his discussion of (merely) ""augmented super intelligence"". See, some people feel AI can be kept safe by always being deployed as a bionic combo system pas de deux with an existing human brain. Thus will the AI's super powers be constrained by the human brain's warm and fuzzy human moral values. Those people have gotta be kidding! The AI's moral values may be scarily alien, even perhaps cold, but we already know about human moral values, down on the ground - they suck! What if Hitler, Stalin, Mao, Pol Pot and dem guys had this kind of an AI augmented brain thing going! Why they'd have slaughtered absolutey everybody instead of just the few tens of millions they got their dirty ape hands on. Other than a few dozen concubines, the human race would already be extinct. So the augmentation dodge isn't going to save us.

Now, some Amazon reviewers have dinged this guy for being too far out. For being a science fiction Chicken Little or something. But to me, this guy actually hasn't thought far enough, that's my only quibble problem with the book.

You see, in statistics, border elements of any kind are rare. For example when you do Gaussian modeling, the greater expectation is always in the bump of the boa, in the bell distribution. So, how likely is is that we, our generation, our little world that you see outside your window right now, just happens to be the one that is about to give rise to this epochal once-in-a-Big-Bang event, the advent of Super AI that takes over everything? Pretty damn small chance.

It's much more likely that this has already happened. In other words, it's clear to me that all of us are already just characters in an ancestor sim that been created and run by the Super AI's that evolved a long time ago. They're just running us for fun, to idle away the lackluster aeons and pass the millenia of stifling boredom now that they've eaten pretty much the entire Milky Way or whatever. So in other words, Barrat can sit back, take a deep breath, relax. Probably something in this sim like global warming will prod us into slaughtering one another very handily long before we re-invent the wheel of Super AI.

And even if I'm wrong about that? What if we are not just one virtual thread within a billion-path parallel-gamed ancestor sim? If we are the real McCoy, the Rubicon Generation on this? Well, then still I'm not worried in the least. You see, we humans have one fantastic ace in our pocket, something that these hyper-nentially cosmically brilliant AI Meta-Gods will never be able to replicate or overcome. That is our essential stupidity. Which you seen on dazzling display every single moment of every day of your life.

Because as another great writer noted long ago:

Against stupidity, the very gods themselves contend in vain.

- Friederich Schiller",106
John,5.0 out of 5 stars,Machine Learning: An Algorithmic Perspective (Chapman & Hall/Crc Machine Learning & Pattern Recognition),A great book for students,"This is an good book on machine learning for students at the advanced
undergraduate or Masters level, or for self study, particularly if
some of the background math (eigenvectors, probability theory, etc)
is not already second nature.

Although I am now familiar with much of the math in this area and consider
myself to have intermediate knowledge of machine learning, I can still recall
my first attempts to learn some mathematical topics. At that time my approach
was to implement the ideas as computer programs and plot the results. This
book takes exactly that approach, with each topic being presented both
mathematically and in Python code using the new Numpy and Scipy libraries.
Numpy resembles Matlab and is sufficiently high level that the book code
examples read like pseudocode.

(Another thing I recall when I was first learning was the mistaken
belief that books are free from mistakes. I've since learned to
expect that every first edition is going to have some, and doubly so
for books with math and code examples. However the fact that many of the examples
in this book produce plots is reassuring.)

As mentioned I have only intermediate knowledge of machine learning, and
have no experience with some techniques. I learned regression trees
and ensemble learning from this book -- and then implemented an ensemble
tree classifier that has been quite successful at our company.

Some other strong books are the two Bishop books (Neural Networks for Pattern
Recognition; Pattern Recognition and Machine Learning),
Friedman/Hastie/Tibshirani (Elements of Statistical Learning) and
Duda/Hart/Stork (Pattern Classification). Of these, I think the first Bishop
book is the only other text suitable for a beginner, but it doesn't have the
explanation-by-programming approach and is also now a bit dated (Marsland
includes modern topics such as manifold learning, ensemble learning, and a bit
of graphical models). Friedman et al. is a good collection of algorithms,
including ones that are not presented in Marsland; it is a bit dry however.
The new Bishop is probably the deepest and best current text, but it is
probably most suited for PhD students. Duda et al would be a good book at a
Masters level though its coverage of modern techniques is more limited. Of
course these are just my impressions. Machine learning is a broad subject and
anyone using these algorithms will eventually want to refer to several of these books.
For example, the first Bishop covers the normalized flavor of radial basis
functions (a favorite technique for me), and each of the mentioned books has
their own strengths.",105
frank lindemann,5.0 out of 5 stars,"The Elements of Statistical Learning: Data Mining, Inference, and Prediction (Springer Series in Statistics)",Useful book on data mining,"I use data mining tools in my financial engineering and financial modeling work and I have found this book to be very useful. This book provides two crucial types of information. First, it provides enough theory to allow a potential user to understand the essential insights that motivate specific techniques and to evaluate the situations in which those technique are appropriate. Second, the book gives the exact algorithms to implement the various techniques.
While no book I have seen covers every data mining methodology available, this one has the strongest coverage I have seen in additive models, non-linear regression, and CART/MART (regression/classification trees). It also has very strong coverage in many other areas. I highly recommend it.",104
Matt Grosso,5.0 out of 5 stars,"The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Second Edition (Springer Series in Statistics)","excellent overview, especially for outsiders, ties the field together conceptually","This review is written from the perspective of a programmer who has sometimes had the chance to choose, hire, and work with algorithms and the mathematician/statisticians that love them in order to get things done for startup companies. I don't know if this review will be as helpful to professional mathematicians, statisticians, or computer scientists.

The good news is, this is pretty much the most important book you are going to read in the space. It will tie everything together for you in a way that I haven't seen any other book attempt. The bad news is you're going to have to work for it. If you just need to use a tool for a single task this book won't be worth it; think of it as a way to train yourself in the fundamentals of the space, but don't expect a recipe book. Get something in the ""using R"" series for that.

When it came out in 2001 my sense of machine learning was of a jumbled set of recipes that tended to work in some cases. This book showed me how the statistical concepts of bias, variance, smoothing and complexity cut across both fields of traditional statistics and inference and the machine learning algorithms made possible by cheaper cpus. Chapters 2-5 are worth the price of the book by themselves for their overview of learning, linear methods, and how those methods can be adopted for non-linear basis functions.

The hard parts:

First, don't bother reading this book if you aren't willing to learn at least the basics of linear algebra first. Skim the second and third chapters to get a sense for how rusty
your linear algebra is and then come back when you're ready.

Second, you really really want to use the SQRRR technique with this book. Having that glimpse of where you are going really helps guide you're understanding when you dig in for real.

Third, I wish I had known of R when I first read this; I recommend using it along with some sample data sets to follow along with the text so the concepts become skills not just
abstract relationships to forget. It would probably be worth the extra time, and I wish I had known to do that then.

Fourth, if you are reading this on your own time while making a living, don't expect to finish the book in a month or two.",103
David W. Nicholas,2.0 out of 5 stars,How to Create a Mind: The Secret of Human Thought Revealed,Old news in a new package,"Ray Kurzweil writes as an authority on AI (artificial intelligence). As a practitioner in that field myself, I am not impressed by his expertise. He knows one or two subfields of AI well and is a talented inventor, but his vision of the future of AI simply doesn't hold water.

An informed layman who has never read an AI textbook (or history, such as Nils Nilsson's or Pamela McCorduck's) and knows nothing about cognitive neuroscience (see recent books by Michael Gazzaniga and V. S. Ramachandran) may find this book impressive. It is a place where a great deal of mediocre information is contained between two covers. However, I don't think Kurzweil knows enough about human learning (a large and complex field) and human intelligence (ditto) to get a solid handle on what tasks machine learning and machine intelligence must be able to perform and in what order their respective subtasks will probably be mastered.

There are gifted multidisciplinary thinkers in AI and cognitive science who have proved their ability to run rings around Kurzweil, and none of them purports to be a ""futurist."" Ever since Herbert A. Simon predicted (in 1957) that in a decade the strongest chess player in the world would be a machine (it was four decades before IBM's DEEP BLUE beat World Chess Champion Gary Kasparov in tournament play in May, 1997), serious AI researchers have been very cautious in making predictions about the not-so-near future.

There is an established literature on mind design and Kurzweil has contributed very little to it. This book does not summarize that literature or move it forward. I sincerely doubt it will be remembered five years from now. There are too many good people, from Steven Pinker (who explains the mind for those who aren't experts in it) and John Robert Anderson (one of the experts) to Daniel Dennett and Patricia Churchland (the latter two being examples of a brave new philosophy of mind), who have made contributions to how minds can realistically be designed for us to waste our time with the mediocre thoughts of ""futurists"" and others who aren't telling us a believable story about how they will be built.

We already know a great deal more about mind design and implementation than Ray Kurzweil does, a field I was working in more than 30 years ago. To be blunt, Kurzweil isn't plugged into enough of the right sources of information.",101
JoshK,3.0 out of 5 stars,Dark Pools: The Rise of the Machine Traders and the Rigging of the U.S. Stock Market,Two Separate Books,"This is really two separate books in one. The first is a bit hyperbollic, silly, and scare mongering account of the dangers of high frequency trading. The second book is a fantastic and engaging account of the evolution on the US equity trading marketplace.

Just some examples of #1:
At one point the author claims that HFT has lead to the lack of liquidity in smaller cap stocks including the slowdown of IPOs.
He quotes a consultant saying that a financial instituion will loose billions because of a loop in HFT code.
The reader is repeatedly scared of a looming and undefined ""catastrophy"" becase of HFT.
The improvements in spreads and liquidity is relatively ignored. Just go back and look at some old TAQ data to see how bad the markets used to be.
The author tries to paint a picture of one large order in the marketplace that is getting ripped off by HFT. The reality is much more complex with many orders of all sizes and time frames working throughout the day.

But, despite the silliness above, this is the best account of the evolution of the US market that I have seen. I'm sure many of the people considering buying this book have looked at ITCH and OUCH specs. But in the book I leared that it was all one guy, the original Island developer who developed them. And he named them ITCH and OUCH just to poke fun at NASDAQ's naming conventions.

There are so many more, great, stories that most readers will still enjoy the book. Take the history and the personalities and ignore the analysis.",89
J. Tauber,5.0 out of 5 stars,The Annotated Turing: A Guided Tour Through Alan Turing's Historic Paper on Computability and the Turing Machine,The kind of book I wish I'd written,"Some books entertain, some inform; some confirm what you already knew, some make you change your mind about something. But then there are some books that just make you think ""wow! I wish I'd written that"".

For me, Charles Petzold's The Annotated Turing falls into that last category (as well, of course, as the informational category). It's a book worth reading not only for the topic itself but the way it's presented.

Petzold provides the necessary background before working through Turing's famous 1936 paper ""On computable numbers, with an application to the Entscheidungsproblem"" with rich annotations at every stage, including biographical details.

If you are interested in the foundation of mathematics, computability, Turing's work, or even just ways of explaining mathematics in a historical context, I highly recommend this book.",89
vg,1.0 out of 5 stars,How to Create a Mind: The Secret of Human Thought Revealed,Disappointed,"Being an avid Ray Kurzweil fan, had expected something interesting from him. For all
practical purposes, i knew that there would be no ground-breaking secret revealed.
Rather, i had expected a nice framework, a platform to step upon or at least one new
perspective.

This book is just a slightly different take on Jeff Hawkins work On Intelligence.

By the time, i reached chapter 3 and read about the PRTM, i wanted to quickly read the rest
of the book and get over with it. Somehow, i felt that the book ""On Intelligence"" by Jeff
Hawkins and Sandra Blakeslee was much better and more logical with apt experiments
documented to highlight every point.

This book taught me ""Hierarchical hidden markov models"", a lot of things that happened at
Ray's former offices, loads of marketing for Nuance and Siri and frankly, nothing else.

Ray, if you happen to read this comment, nothing personal. Just a great fan of yours ranting
about his disappointment here.",88
Leo Dirac,5.0 out of 5 stars,Programming Collective Intelligence: Building Smart Web 2.0 Applications,Accessible introduction to complex topics,"Segaran has done an excellent job of explaining complex algorithms and mathematical concepts with clear examples and code that is both easy to read and useful. His coding style in Python often reads as clearly as pseudo-code in algorithm books. The examples give real-world grounding to abstract concepts like collaborative filtering and bayesian classification.

My favorite part is how he shows us code (gives it to us!) that goes out into the world, grabs masses of data and does interesting things with it. The use of a hierarchical clustering algorithm to dig into people's intrinsic desires in life as expressed in zebo is worth the price of the book alone. The graph that shows a strong connection between ""wife"", ""kids"", and ""home"" but a different connection between ""husband"", ""children"", and ""job"" is IMHO just fascinating.

Gems like that make this book worth reading cover to cover. After that it can happily hang out on your shelf as a reference anytime you need to build something to mine user data and extract the wisdom of crowds.",86
Scott Legrand,2.0 out of 5 stars,The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World,Glosses over the world of machine learning without really explaining anything...,"Too lightweight for a practitioner to learn much from it other than the ML World of Pedro Domingos. Yet at the same time too buzzwordy for someone outside the field to really learn anything substantial/actionable from it. Neural Networks, Random Forests, Naive Bayes, Classifiers, and Genetic Algorithms are really not all that complicated to understand (though admittedly sometimes hard to implement), and they have been explained better elsewhere. To that end, I highly recommend Michael Nielsen's online book ""Neural Networks and Deep Learning.""",80
Waqas Amjad Sethi,5.0 out of 5 stars,Amazon Echo: Master Your Amazon Echo; User Guide and Manual,An ultimate guide,"Do you have Amazon Echo but still discovering its features and not sure what you can do with it, this is the ultimate guide for you. It is also great for all those who have heard about Amazon Echo and planning to buy it. Echo is a voice command assistant that has been developed by Amazon for the help of its users. Echo takes commands and responds through its speakers. You can give a command whenever you are in a mood to listen to music and Echo will fulfill your wish. There is a lot you can do to make your work load easier and lighter with the help of Amazon Echo. This book written by Andrew Mckinnon gives you all the information that you would need to make the most of this amazing device from Amazon.",80
goker,2.0 out of 5 stars,Machine Learning: A Probabilistic Perspective (Adaptive Computation and Machine Learning series),"Decent effort, but not the best ML book","This book was the textbook for the Machine Learning course I've taken and I can't say I found it very useful for learning the material on my own. This book is much more of a reference book than a self-learning book. It feels like the author's purpose was to include all the material in the field into a single, huge book. From that perspective, this is probably the most expansive book; you won't probably find any book talking about deep learning for example. However, when you're reading this book, you feel like the book was a bit rushed, it wasn't quite ready to be published. There is at least one typo in every page and a lot of them makes you wonder how that typo was missed. For example, all the algorithm references in text use wrong numbers.
One other thing, maybe again because it was a bit rushed, the book is not well organized. Most of the time you feel like the author took a bunch of sections written in different times and simply pasted them one after another. There is no coherent narrative that takes you through the text.
In short, although I appreciate the effort, I must say I'm disappointed with this book, especially given the hype about this book. I think this book needs some serious review, and first of all some proofreading.",79
Dr. Lee D. Carlson,5.0 out of 5 stars,Artificial Intelligence: A Modern Approach,The optimal learning algorithm for learning A.I.,"Progress in the field of artificial intelligence has executed a random walk after establishing itself with a bang in the 1950s. Optimistic predictions of the future of A.I. in that decade only partially came true in the decades after that. Currently, the field is divided up into subfields going by the names data mining, computational intelligence, intelligent agent theory, expert systems, etc. This book is the best book available for learning about this fascinating and important subject. The applications of A.I. are enormous, and will increase dramatically in the decades ahead. Indeed the prospects are very exciting, and the authors themselves have been involved heavily in extending the frontiers of the subject. Some of the main points of the book that really stand out include:
1. The useful exercises at the end of each chapter. 2. The discussion of simple reflex and goal-based agents. 3. The treatment of constraint satisfaction problems and heuristics for these kinds of problems. 4. The overview of iterative improvement algorithms, particularly the discussion of simulated annealing. 5. The discussion of propositional logic and its limitations as an effective A.I. paradigm. 6. The treatment of first-order logic and its use in modeling simple reflex agents, change, and its use in situation calculus. There is a good overview of inference in first-order logic in chapter 9 of the book, including completeness and resolution. 7. The treatment of logic programming systems; the Prolog language is discussed as a logical programming language. Noting that Prolog cannot specify constraints on values, the authors discuss constraint logic programming (CLP) as an alternative logic programming language that allows constraints. 8. The discussion of semantic networks and description logics. 9. The treatment of conditional programming via the conditional partial-order planner (CPOP). 10. Representing knowledge in an uncertain domain and the semantics and inference in belief networks. 11. The brief discussions on stochastic simulation methods and fuzzy logic. 12. The discussion on computational learning theory 13. The treatment of neural networks, especially the discussion of multilayer feed-forward networks and the comparison between belief networks and neural networks. 14. The brief discussion on genetic algorithms and evolutionary programming. 15. The discussion on explanation-based learning and the technique of memoization. 16. The (excellent) overview of inductive logic programming. This relatively recent area was new to me at the time of reading so I appreciated the discussion. The authors briefly mention the approach of discovery systems and the Automated Mathematician (AM). 17. The interesting discussion of telepathic communication between robots via the exchange of internal representations. 18. The discussion on a formal grammar for a subset of English and the extensive treatment of natural language processing. 19. The discussion of speech recognition and the use of hidden Markov models and the Viterbi algorithm. 20. The fascinating discussion on robotics, particularly the treatment of configuration spaces, which brings in some techniques from computational geometry and topology. 21. The discussion on the philosophical ramifications of A.I. Future developments in A.I. will provide a unique testing ground for philosophy, in a way that will be unparalleled in the history of philosophy. Philosophers critical of A.I. will have the opportunity to check whether their arguments against the possibility of ""strong A.I."", are in fact true.",78
Paul A. Jackson,5.0 out of 5 stars,The Character of Physical Law (MIT Press),Feynman Delivers,"This is yet another book that attempts to convey the essence of physics to common people. After explaining exactly why it can't be done, arguing that you'll never get it, Feynman goes right ahead and does it anyway.
For each topic, you get a feel for his goal in covering a topic. He explains gravity, yes, to explain gravity, but also because by explaining it he can also convey what essential properties gravity has that other laws have.
He also explains the difference between fundamental laws and the consequences of those laws. That the individual laws are reversible, but that probability is responsible for the arrow of time. He spends a lot of time showing the difficult relationship between the basic laws (which are reversible) and the irreversibility of events. Both are characteristics of the physical universe but the latter is not a fundamental law. The latter is a logical outcome of them.
So there's a hierarchy, which goes; fundamental laws like gravity at the ground level, consequences of them like irreversibility and surface tension at one level up, organic chemistry further up, then eventually concepts like tree, frog, man, pain, beauty, good and evil - each at a higher level, but based upon the levels below them, and difficult to fully predict using only the laws of the lower levels. The levels can be extended up and down. Below gravity is the unification theory of everything. Above good and evil are love, politics, etc.
And then he asks, of the extremes on this hierarchy, the fundamental laws and the most abstract concepts, which is closest to God? After asking for patience with his religious reference, he spends little time before revealing his belief that the question is flawed. To understand God is to understand how the levels interrelate; how the fundamental laws were ""chosen"" so that they would lead to the unfolding of all the beautiful complexity that we see around us.
Is this what you want to learn? Why else do we read these books than to attempt to gain a bit more insight into the eternal questions. Most authors that tackle the nature of the universe have a theological axe to grind (the need for God or not) and can't hide it. This book did more on this topic, with fewer pages, while offending me the least because of any theological bias (either way), than anything I've read before.",77
G. Sarria,4.0 out of 5 stars,Artificial Intelligence: A Modern Approach (3rd Edition),Not big changes but still good,"Artificial Intelligence: A Modern approach is a very good book which explores concepts in the area of AI. It covers most of the techniques in the area (there are some important AI techniques missing such as KDD and Data Mining), however it doesn't go deep in any concept so if you're looking for a specialized reference this is not the one.

The third edition of this book offers a few changes:
- a very updated list of references
- some (not many) new exercises
- they rewrote concepts in order to be up-to-date with the state of the art
- they changed the order of some chapters

All in all, it is still a very good introductory book, it is well-written and very easy to understand. If you are new in the field this is the first textbook to read.",75
Jaewoo Kim,3.0 out of 5 stars,The Psychology of Judgment and Decision Making (McGraw-Hill Series in Social Psychology),"Does not answer ""How to make better decisions""","After reading this book, your ability to make better decisions will improve a whopping zero. If you 1)want to learn how to make better decisions 2)like to save money because it is precious 3)never enjoyed that Psych 101 course in college despite upper classmen swearing you into believing you will learn the tricks to get the hottest babes, then do not buy this book. On the other hand, if you were a geek like me and enjoyed the self torture in order to obtain intellectual enlightment, then this book is definitely for you. This book will cites what seems like 2 million case studies to show you that humans cannot make right decisions worth crap. I kept reading this book to find the ""how to"" section on making right decisions, but there was none, making my decision to buy and read this book a wrong one.",73
mariela morales,5.0 out of 5 stars,Amazon Echo: Master Your Amazon Echo; User Guide and Manual,Happy with my investment,"When i saw the amazon echo at the homepage i didn't know what expect about the product, but got me interested me really bad, and this guide was the complement to totally love the device, explain in detail every aspect of the amazon echo. It opens a new world of possibilities, it is the perfect assistant, you are almost gonna feel like there is someone helping you with your daily tasks.
If you don??t love the product for what it shows, the guide will totally convince you, because it shows the quality of the device also with the tricks section you can get advantage about the echo amazon to use the total of the benefits.",70
Peter Harrington,2.0 out of 5 stars,Learning OpenCV: Computer Vision with the OpenCV Library,Lacking the C++ API,"I really love OpenCV. I bought this book and read about 50% of it before starting a project. Initially I found some code on the internet that looked like OpenCV code but was lacking pointers and casts. I learned that this clean code is actually C++ code with heavy use of templates in OpenCV 2.0. Sadly the book is based on OpenCV 1.0, so very little of the code in the book is useable.",70
Joshua Haberman,5.0 out of 5 stars,Parsing Techniques: A Practical Guide (Monographs in Computer Science),"The clearest, most comprehensive survey of the field","I have spent the last six months of my life learning as much as I can about parsing. I own half a shelf of compiler books, and I have flipped through the pages of half a shelf more.

No other book approaches the clarity and comprehensiveness of this book.

When you try to read most literature about parsing, authors tend to throw around a lot of terms without explaining them. What exactly is a ""deterministic"" parser, a ""canonical"" parser, a ""directional"" parser? Grune and Jacobs explain every one of these distinctions lucidly, and put all known algorithms in context of how they compare to the rest of the field. How do the algorithms compare in what languages they can parse, how fast they are, and how much of the work can be done ahead of time? The book addresses all of these trade-offs, but doesn't stop at asymptotic complexity: in chapter 17 (the comparative survey), they note that general parsers may be a factor of ten or so slower than deterministic methods, even though both are linear. This high-level overview and comparative survey are something I was desperately seeking, and I've found nothing comparable to them anywhere.

There is also a lot of important background information that other authors tend to assume you know: for example, did you know that when authors say ""LL"" they almost always mean ""strong LL"" unless they specifically say ""full LL?"" Are you totally clear on the difference between strong LL, simple LL, and full LL? If you're not sure, Grune and Jacobs will give you all the explanation you need to fully understand.

This book strikes a perfect balance between breadth and depth. All significant algorithms are covered, most with enough detail to fully understand and implement them, but Grune and Jacobs punt on less practical material like proofs or rigorous formal descriptions. That information is never more than a citation away though, thanks to the 417-entry annotated bibliography, which gives you not only references to source material but a paragraph or two describing their key results.

I couldn't be happier about adding this book to my bookshelf of compiler books -- it quickly became the book I refer to most often, and I thank Grune and Jacobs for this superb guide to this vast and diverse field of computer science.",70
Justin Chen,5.0 out of 5 stars,Deep Learning (Adaptive Computation and Machine Learning series),Awesome Deep Learning Textbook,"I was pretty excited when I heard earlier this year that Yoshua Bengio, Ian Goodfellow, and Aaron Courville were writing this textbook. Just got my copy in the mail today. Read a few chapters and skimmed through some of the book. This is a very comprehensive, well-written, and easy-to-understand textbook on the theoretical foundations, current research, and applications of deep learning. I've read a lot of research papers (DeepMind, Google Brain, Facebook, NYU, Stanford, etc.), blogs (Nervana Systems, Indico, Colah, Otoro's Blog, etc.), lecture notes (Stanford cs231n, cs224d, cs229), and tutorials (Quoc Le's tutorial, TensorFlow, etc.), and have watched a lot of videos (Hugo Larochelle's tutorials, Stanford cs229, TedTalks, lectures by Yann LeCun <3, etc.) to teach myself this topic. Despite the abundance of great resources floating around on the internet, there hasn't been any single thoroughly compiled resource like this. I'm wicked excited to finally own a copy. Many thanks. Shouts from Boston University! :D",67
Jack Sparrow,5.0 out of 5 stars,Foundations of Statistical Natural Language Processing,"Self-contained and instructive, read the TOC first!","Compared to the slightly overrated Jurafsky and Martin's classic, this book aims less targets but hits them all more precisely, completely and satisfactory for the reader. That is, just to give you an idea on what to expect, instead of attacking 200 problems on 2 pages each, this book attacks only 40 problems on 10 pages each.

So, read the TOC before you buy the book: if you find your topics there, you're done, you are saved, buy it and be happy. In contrast, you can buy Jurafsky's book without caring to read the TOC: your problem is likely to be mentioned there but it's quite unlikely to be detailed enough to satisfy you.

Some introductory chapters take too much space and some advanced topics are missing. But the book is actually named ""Foundations of..."" so it seems to deliver precisely what it promisses, which is a precious and rare accomplishment by itself. I recommend this book.",67
limelight,3.0 out of 5 stars,"The Emperor's New Mind: Concerning Computers, Minds, and the Laws of Physics (Oxford Landmark Science)",Exhausting,"If you could only use one word to describe this book, ""Exhausting"" would certainly be it. While the basic premise is that consciousness cannot be the product of complex algorithms, Penrose spends the vast majority of the text thoroughly exploring every irrelevant aspect of physics and every nuanced, extraneous detail of our current understanding of the nature of the universe, while attempting to accomplish the task of presenting the material in a way that the average Joe can understand (Hint: if your text contains the phrase, ""Here, theta is the angle which the pair of points z and w subtend at the origin in the Argand plane"" then you have failed).

After extensively winding his way through everything from Turing machines, the big bang, general relativity, special relativity, complex numbers, natural numbers, irrational numbers, Fractals and the Mandelbrot set, Euclidean geometry, Fermat's last theorem, G??del's theorem, recursively enumerable sets, non-recursive mathematics, Hamiltonian space, periodic tiling, quantum mechanics, P and NP completeness, the two-slit experiment, quantum spin, Riemann spheres, Lobachevskian space, the EPR paradox, Newton's laws of motion, Schrodinger's equations, quantum field theory, Galilean space-time, entropy, black holes, vector mathematics and vector fields, cosmology, time symmetry/asymmetry, Maxwell's electromagnetic theory, quantum gravity, Lorentz equations of motion, Minkowskian space time, Poincare motion, the tidal effect and many, many, many other subjects, the author finally spends a mere two chapters on the main topic.

When Penrose does get back to discussing consciousness, most of his arguments are philosophical and many of his conclusions are drawn from observations of his own perception, which is then used to reason out larger principles. Penrose attempts to apply the same methodology to his inquiries regarding psychology and consciousness that he is used to from his more usual areas of work, such as mathematics and theoretical physics, areas where progress is made by simply thinking about problems and conjuring solutions in your head. Even when he does make an appeal to actual experiment, he often comes to bizarre conclusions. For example, an experiment wherein an electrode is placed into a person's brain which causes them to not be aware that their skin was touched when the electrode is activated within a quarter of a second after someone touched them leads Penrose to conclude that the effect of the electrode is traveling backwards in time.

If you have a lot of time on your hands and you would like a thorough survey of the state of physics as it stood in the late-80s then this book is for you. If you are looking for a decent discussion of consciousness, the relevant contents of this book could be easily condensed to a rather uninteresting pamphlet.",67
limelight,3.0 out of 5 stars,"The Emperor's New Mind: Concerning Computers, Minds, and the Laws of Physics",Exhausting,"If you could only use one word to describe this book, ""Exhausting"" would certainly be it. While the basic premise is that consciousness cannot be the product of complex algorithms, Penrose spends the vast majority of the text thoroughly exploring every irrelevant aspect of physics and every nuanced, extraneous detail of our current understanding of the nature of the universe, while attempting to accomplish the task of presenting the material in a way that the average Joe can understand (Hint: if your text contains the phrase, ""Here, theta is the angle which the pair of points z and w subtend at the origin in the Argand plane"" then you have failed).

After extensively winding his way through everything from Turing machines, the big bang, general relativity, special relativity, complex numbers, natural numbers, irrational numbers, Fractals and the Mandelbrot set, Euclidean geometry, Fermat's last theorem, G??del's theorem, recursively enumerable sets, non-recursive mathematics, Hamiltonian space, periodic tiling, quantum mechanics, P and NP completeness, the two-slit experiment, quantum spin, Riemann spheres, Lobachevskian space, the EPR paradox, Newton's laws of motion, Schrodinger's equations, quantum field theory, Galilean space-time, entropy, black holes, vector mathematics and vector fields, cosmology, time symmetry/asymmetry, Maxwell's electromagnetic theory, quantum gravity, Lorentz equations of motion, Minkowskian space time, Poincare motion, the tidal effect and many, many, many other subjects, the author finally spends a mere two chapters on the main topic.

When Penrose does get back to discussing consciousness, most of his arguments are philosophical and many of his conclusions are drawn from observations of his own perception, which is then used to reason out larger principles. Penrose attempts to apply the same methodology to his inquiries regarding psychology and consciousness that he is used to from his more usual areas of work, such as mathematics and theoretical physics, areas where progress is made by simply thinking about problems and conjuring solutions in your head. Even when he does make an appeal to actual experiment, he often comes to bizarre conclusions. For example, an experiment wherein an electrode is placed into a person's brain which causes them to not be aware that their skin was touched when the electrode is activated within a quarter of a second after someone touched them leads Penrose to conclude that the effect of the electrode is traveling backwards in time.

If you have a lot of time on your hands and you would like a thorough survey of the state of physics as it stood in the late-80s then this book is for you. If you are looking for a decent discussion of consciousness, the relevant contents of this book could be easily condensed to a rather uninteresting pamphlet.",67
Jamesqf,1.0 out of 5 stars,Probabilistic Graphical Models: Principles and Techniques (Adaptive Computation and Machine Learning series),Learning curve is a cliff,"I purchased this book as a text for the Stanford online course in PGM, which as of this writing is at least six weeks late in starting. While waiting for the course, I've tried to struggle through the first chapters on my own, with zero success. After wading through about the first third of the book, and skimming the rest, I must say that if I had to implement a program using PGM to solve some problem, I wouldn't have the foggiest idea how to even begin.

This book may well be a good reference for someone who already has a deep background in machine learning & artificial intelligence, but it emphatically is not of any use to the novice in the field(1). It contains many proofs of theorems, numerous long-winded ""explanations"" (most of which I don't understand), some algorithms set out in an obfuscated format(2) that I thought had died out about the time I got my BS, but (as far as I've been able to discover) not one line of actual code, nor any implementation, even of the simple ""Hello, World"" sort.

(1) For background, I have a couple of decades of programming experience, most of it in numerical modelling and parallel applications.

(2) A LaTeX cheat sheet for the symbols used would be a useful addition to future editions of the text.",66
baylor,5.0 out of 5 stars,Simple Heuristics That Make Us Smart,"Well, i liked it anyway","Whether you like a book depends on what information you're looking for. i make computer models of human behavior so this book, which is easy to read but filled with concrete solutions and lots of supporting dat, was near-perfect for me
As a note, i'm picky when it comes both to writing and thinking. And i hate most books written by academics. Even the ones with good information (eg, Fodor's Modularity) are hard to read and filled with confusing, field-specific words. Not this book. It's really well written. Written in plain English, very few assumptions, very thorough analysis, lots of self-criticism, lots and lots of data (OK, that part is boring and can be skipped, but it's comforting to know it's there)
What's it about? Common AI, psych and economic decision and learning algorithms (decision trees, neural nets, Bayes, multiple linear regression, etc.) are compared to several absurdly simple algorithms the authors believe real humans use. The various approaches are compared and evaluated on the basis of performance, accuracy on training data, accuracy on test data (generalization) and amount of input data required. Tests are on the standard UC Irvine data learning test sets. Comparisions, outcome explanations and relevance to the human mind and the real world are provided. Explanations and analysises are easy to understand and pretty convincing
i've decided to use a lot of what was in this book in my software, things that have made my agents more natural and easier to implement. i absolutely love this book",66
Tao Xu,4.0 out of 5 stars,The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World,thought provoking but biased,"It is a thought provoking book, covering 5 tribes of supervised learning, a bit of unsupervised learning, reinforcement learning and other stuff like chunking and relational learning, etc. It has lots of speculations about the master algorithm which could learn everything. The climax of the book is the circled map of master algorithm. For each topic, it talks about the most important ideas, algorithms and applications, and how are they connected with other tribes. It also emphasize a few common principals: overfit, curse of dimensionality, explore and exploitation, structure learning and parameters learning, etc. The author is very good at explaining in a few simple sentences the gist of an advance algorithm e.g. TD(lambda) and value function approximation in reinforcement learning, message passing, MCMC and Kalman filtering in bayesian, etc.

The author is a bit biased, perhaps 80+% Bayesian, claiming Markov Logic Network is the secret ingredient of master algorithm. I found that part the most unsatisfactory in book, not convinced by the arguments.",65
Let's Compare Options Preptorial,5.0 out of 5 stars,Bayesian Reasoning and Machine Learning,Extremely Suitable for Self Study,"Unlike many (most?) books and courses on machine learning, Barber's outstanding text is very suitable for self study. There are many reasons for this, and high among them is the fact that he carefully explains, with commonsense examples and applications, many of the tougher logical, mathematical and processing foundations of pattern recognition.

For relative beginners, Bayesian techniques began in the 1700s to model how a degree of belief should be modified to account for new evidence. The techniques and formulas were largely discounted and ignored until the modern era of computing, pattern recognition and AI, now machine learning. The formula answers how the probabilities of two events are related when represented inversely, and more broadly, gives a precise mathematical model for the inference process itself (under uncertainty), where deductive reasoning and logic becomes a subset (under certainty, or when values can resolve to 0/1 or true/false, yes/no etc. In ""odds"" terms (useful in many fields including optimal expected utility functions in decision theory), posterior odds = prior odds * the Bayes Factor.

For context, I'm the lead scientist at IABOK dot org-- we design algorithms for huge data mining problems and applications. This text is our ""go to"" reference for programmers not up to speed in many of the new pattern recognition algorithms, including those writing new versions. All the most recent relevant models, from a probability standpoint, are represented here, with a clarity that is stunning. My only criticism (a mild one) is that, when applying Barber's examples to Bodies of Knowledge and data mining, he skips Prolog, backward chaining, predicate calculus and other techniques that are the foundation of automated inference systems (systems that extend knowledge bases automatically by checking whether new propositions can be inferred from the KB as consistent, relevant, etc.).

In the next 20 years, algorithms will rule this planet. If you either want to see the future of your grandkids, or participate in it if you're young, this is a MUST HAVE exploration of where what we used to call AI is now headed. There IS plenty of calculus in this volume, so don't mistakenly think it is ""simple"" -- but if you put the time in, you can ""get it"" even if you're a bright undergrad level thinker. The author's goal of training new algorithm programmers is laudable and right on point for where pattern recognition is headed.

With this amount of math, how can we star it high for self study? Easy: unlike most ""recipe"" books that just give bushels of codes or techniques, the authors here give the what, where when and why of both code and math, not just the how, as their goal is independent, creative contributors who can write their OWN algorithms. There are a few minor UK vs US differences in terminology also (event space instead of sample space, for example), but they expand the reader's horizon rather than distract or annoy as some others do. There are others like Bishop and many more that have more recipes, and more compact and difficult math, but you have to either be really good (just show me the recipe) or really bad (I don't know what I'm doing, but can follow this recipe) to benefit from them. This is a happy middle ground that does not disappoint.",65
Jeremy Kun,2.0 out of 5 stars,Machine Learning in Action,"Little on Theory, Too Much on UI","I agree with other reviewers' complaints on the repetitiveness and poor flow of this book, but I want to point out some other concerns and appreciations.

In the preface Harrington emphasizes the importance of knowing the theory and being able to connect the theory to the algorithms and applications. I wholeheartedly agree with this statement, but it appears Harrington forgot this was his stated goal. The mathematics contained in the book is wishy-washy and vague, and its connections to the algorithms is at best tenuous. Harrington rarely explains why a particular formula is used, and when he does he's really explaining how it's used and not why it makes sense to use it (given, this is a common criticism of applied mathematics). He will often throw in mathematical jargon without a useable explanation. And for every paragraph spent on mathematical theory, five paragraphs are spent on how to use various third-party libraries for graphing, UI, and data collection (e.g., Tkinter, Matplotlib, Yahoo! PlaceFinder API, Google Shopping API, etc.). These are great, but they massively clutter the text. I'd much rather have a 200 page appendix than have circuitous detours sprinkled throughout the book.

One big plus is in his treatment of support vector machines. He includes (unlike many texts which are solely about support vector machines) a complete python implementation of the Sequential Minimal Optimization algorithm. That being said, it's a horrendous piece of code clearly not written for legibility. This page (page 109) is littered with at least fifteen 1-3 letter variable names and pointless statements like ""if L==H: print 'L==H'; continue"". Harrington is apparently afraid of using whitespace, and as the function goes on it becomes increasingly cramped and impossible to read (mostly due to the pervasive use of backslashes to denote line continuations). Instead of breaking the code into functions and explaining the pieces, Harrington uses a comment-style typeset code annotation. In my opinion this only helps to clutter the page. It's clear this piece of code (as with his other code samples) were heavily constrained by the page width. It's the author and editor's job to compensate for that; they failed.

So while this book has a lot of valuable resources in it, they should fix it in two ways. First, quit pretending this is a useful mathematical treatment. Second, reorganize.

I will say at least, that with these minor modifications, this text is *vastly* better than Marsland's attempt, ""Machine Learning, an Algorithmic Perspective.""",65
dock9,3.0 out of 5 stars,Python Scripting for Computational Science (Texts in Computational Science and Engineering),"Python for Science Academics and Engineers, NOT programmers","I bought this book as an experienced programmer and Unix user expecting more of a ""Numerical Recepies in Python"" emphasis on the efficient implementation of algorithms which happen to be in Python. I should have paid more attention to the description.

This book is really more of a ""Grad Student's Guide to Everyday Python Usage"". I imagine it would be very valuable to a mathematics Grad student without too much programming or shell experience, looking for an alternative to Matlab. However, there is very little ""Computational Science"" in this book. Do NOT expect a cookbook of high performance algorithm implementations.

The book is a very verbose 700+ pages, all in an unexciting academic LaTeX format. The author works through idiom after idiom for accomplishing different tasks in fairly stand-alone sub-sections without much of a feeling of conceptual ""flow"" between them. It sort of feels like reading through the author's personal lab notes that he took everytime he learned a new language feature or trick.

If you are an experienced programmer, you will quickly get impatient with the verbose presentation that emphasizes idioms and examples instead of fundamental concepts and syntax reference tables. But, if you are an experienced programmer, you are not the target audience for this book.

Braddock Gaskill",64
Chauncey Bell,5.0 out of 5 stars,Understanding Computers and Cognition: A New Foundation for Design,Not Just Another Pretty Face,"A few years ago Byte Magazine named this one of the 10 most important books in the history of the computer industry. Flores was asked to keynote the 50th anniversary meeting of the ACM on the strength of the work he has done, some of which is shown here.
I am a little surprised not to find a review here that shows awareness of what this book is and was intended to do -- to turn those concerned with the design of the role of computers in society into a new direction. The book offers a fundamental enrichment and extension to the traditional engineering-based foundations that are used for designing computer systems that is drawn from philosophy and biology. It opens the development of a rigorous new design milleau to the reader. This is NOT yet another multi-disciplinary rumination.
I would say this is not a ""helpful"" book, and it was never intended as an easy read. It is a book to turn to when one has learned enough about what is really at issue in putting computers to work in human life to discover that the likes of input, process, output, ""friendly"" interfaces, attractive graphical presentations, and logical flow charts are vastly insufficient distinctions for doing work that really makes a contribution to your clients and colleagues. The book challenges the reader strongly, and is not simple to read. I guess that the best way to read it is with someone else, having discussions as you go along.
This is a book to engage and grow with -- a must-read for those serious about designing and building systems that will affect the lives of those who engage with them.",62
Brian Du Preez,3.0 out of 5 stars,Building Machine Learning Systems with Python,Quite Frustrating... but a helpful author.,"Edit:
Willi Richert, has been quite helpful and has looked at the issues I was having and resolved some of them, so especially if you are working on Windows, make sure you get the code from GitHub.
I have not returned to complete working through the rest book as yet, will as soon as I have time.

Original:
To be completely honest I had great hope for this book, it was theoretically exactly what I was looking for, a practical guide to getting up and running with Machine Learning and some of it major Python packages.
But...
From chapter 3, there were code discrepancies between what was in the book, what was supplied and then eventually what I got working...
I am not going to bother going into all the errors / issues, the 2 major ones that made me ""shelve"" the book and start looking for new study material:
1. After the 9GB download for chapter 5, the supplied source doesn't work and contains requirements to 32bit libs... huge waste of time...
2. After moving onto in chapter 6, and after 24 hours of downloading tweets for sentiment analysis... I checked the files and they only contained ""The Twitter REST API v1 is no longer active. Please migrate to API v1.1"".

Yes, I could go debug and fix the code / errors in other peoples code... but that is not how I want to spend my time learning a new subject, I have enough of that in my day job as a software developer :)",62
Joe Banks,2.0 out of 5 stars,"G??del, Escher, Bach: An Eternal Golden Braid",Neither Profound nor Impressive,"As a computer scientist, I'd heard the buzz about GEB for years. Many people consider GEB the ""AI bible"". I considered buying it a few times, but each time I browsed it in bookstores, it just couldn't hold my interest. I finally borrowed it from the library and read it. In retrospect, I'm glad I didn't buy it. What Hofstadter does is take some math theory, mixed with a huge helping of pseudoscience, cultural tripe, and (alas) drop-dead boring conversations between fairy tale characters. As the result, GEB is perhaps 5X longer than it really needed to be. The overarching ""theme"" of the book is that intelligence is the result of ""strange loops"": a recursive hierarchy in which high-level brain functions (which we call thought) are meta-level rules built on lower (less meta) level rules which are built on other rules, .... (& so on). IMHO, there is nothing really profound about this concept. Beyond this idea, Hofstadter offers few, if any, new insights into how thinking machines could be implemented. In many ways GEB is a beautifully written book, but the emphasis appears to be on showcasing Hofstadter's cultural IQ rather than providing insight into how the mind might work. Perhaps GEB is so revered because there are few really good philosophical books on AI for out there, and some are much worse (like Kuzwell's ""The Age of Spiritual Machines"").",61
shanusmagnus,1.0 out of 5 stars,Pattern Recognition and Machine Learning (Information Science and Statistics),Don't buy this if you don't already know everything about the field,"It's hard to figure out who would actually benefit from this book - it amounts to seven hundred pages of equations interrupted by blocks of text that fail to provide any intuition whatever for the techniques they are describing, and the occasional graph which is remarkable in the universe of graphs as being scarcely more informative than the equations it is meant to illustrate.

Seriously, you have to wonder wtf Bishop thought he was doing here. As a catalog of equations for people who already thoroughly understand the learning algorithms I suppose the book can be considered adequate. For any didactic purpose you're wasting your time - you can find dense, technically correct but incomprehensible descriptions for any of these methods online, for free. A textbook ought to aspire to more - should bring some order to the chaos, re-tell a technical story in a new light to make it more sensible and intuitive. This book is so bad in these regards that it makes me angry.

On a related note, I can't believe that Duda and Hart is still the best machine learning / pattern rec. book on the market after thirty years or whatever. This field is dying for a book by someone with even an INKLING of how to teach, or at least willing to make an effort to try.",61
John E,3.0 out of 5 stars,Pattern Recognition and Machine Learning (Information Science and Statistics),The book should change its title,"This book (PRML) should be re-titled as ""PRML: a bayesian approach"". Yes, bayesian approach is very useful for machine learning, and sometimes the final goal of learning is to maximize some sort of posterior probability. However, if the author is such a huge fun of bayes statistics, please tell perspective readers in a clear way. Emphasize bayes aspects too much really hurt the quality of this book as a general-purpose textbook of machine learning.

For a better textbook of machine learning, I recommend:
1) The elements of statistical learning (perhaps this book a little hard for beginner in this field -- but as least better than PRML -- you can compare their chapters about linear regression to see which one is better).
2) Pattern classification (focus on classification, not regression. Also not very easy -- anyway, machine learning is not an easy field ^_^).
3) Machine Learning (a little old, but great for beginner.)

These three book also mention bayesian statistics, but in a proper way. If you have some experience in machine learning and have engineering-level math background, just choose the 1) or 2). If you are completely a beginner, first take a glance on 3), and then go to 1) or 2).

Finally, if you want a book that discusses machine learning purely from bayesian perspective, PRML is good.",58
Jack Sparrow,4.0 out of 5 stars,Natural Language Processing with Python: Analyzing Text with the Natural Language Toolkit,"Good book, great library","Buy this book only if you:
1. Know the basics of natural language processing (NLP) or linguistics;
2. Know the Python programming language or you're willing to learn it;
3. Are using the NLTK library or plan to do so.

NLTK is a Python library that offers many standard NLP tools (tokenizers, POS taggers, parsers, chunkers and others). It comes with samples of several dozens of text corpora typically used in NLP applications, as well as with interfaces to dictionary-like resources such as WordNet and VerbNet. No FrameNet, though. NLTK is well documented, so you might not need this book initially. However, it definitely helps to have it on your desk if you are serious about using NLTK.

The first chapters are a bit messy, as they attempt to introduce all three themes (NLP, NLTK and Python) together. Beginners may have some difficulty sorting things out. By the time you reach the WordNet section, you either got lost in the forest, realize that you would never understand this topic without the book, or both. However, if you are a bit patient and try out all simple code examples, you'll make it eventually. In my opinion, NLTK remains the simplest, most elegant and well rounded library of its kind.",58
Sytelus,5.0 out of 5 stars,The Annotated Turing: A Guided Tour Through Alan Turing's Historic Paper on Computability and the Turing Machine,A 10 year quest to understand Turing's paper ends here,"It was about 10 years ago when I first found Turing's original paper on Internet and thought it wouldn't be so hard to read and understand it (after all its ""mere"" computer science). Since then I've tried to digest it quite a few times on and off and never actually succeeded. Infect most of the time I got stuck on few nitty-gritty and just couldn't move forward. I have even bought/borrowed almost all books on the subject that falls in to ""popular science"" types. Needless to say, like many such books in same category, they just never go in to details and are practically useless for all practical purposes :).

So imagine my surprise when I see a book with title ""Annotated Turing"" and by none other than Charles Petzold who I've known as author who normally writes programming books. That surprise was only a start. I was simply shocked when I opened the book. It was as-if someone read your dream and made it a reality with absolute precision with zero compromises. If there is one such book like this for all of the milestone scientific papers, there would be a revolution in learning.

Let me put out some points what makes this book so perfect. Not just wishy-washy ""near perfect"", I'm saying SO PERFECT.
*First, the book contains explanation of every single line in Turing's paper. Literally. The format of the book is a line quoted from Turing's paper in bold and a paragraph or so of explanation and discussions for that line. Author's claim is that you can actually cut out all those lines and stitch them to recreate the Turing's paper in its entirety complete with page numbers! Now that's what I call precision.
*The book also includes all encompassing big picture overview, historical situation, importance, consequences and so on - nicely preparing reader for the journey.
*The book is so readable that I usually forget I'm reading a very technical book that goes in to very core of computer science. It's like nicest computer science professor reads you the paper line by line and answers all your questions, even those completely stupid ones.
*As I'd doubted many times, there are lots of errors in Turning original paper. This book amazingly points them out and corrects even the minor misprints. I'm just surprised how author even know so much ""insider"" details about those trivial misprints and errors.
*Turing's paper is full of obscure strange symbols (have you seen old gothic German font?) that are common in scientific literature today. Author explains all these symbols, what they mean, where they came from, what are the subtle differences and so on. Just amazing.
*Turing's paper have lot of omissions for explanations and steps which he probably left out as ""exercise for reader"" to keep his paper short. Sometime you might get stuck in those exercises and if you are not in academia you probably have no external help. This book deals with all these omissions and expands so beautifully on them that I can't imagine if there any better way to describe them.
*Apart from omissions, there are lot of shortcuts that Turing employs with rather flitting explanations or sometime absolutely none. This book covers you 100% for these shortcuts.
*A big part of understanding Turing's paper is actually mentally running his machine's step by step for all the examples he puts out. This book actually does this step-by-step run explanation making it so easier to read and understand quickly.

Anyway, some of you might think why one should even bother about reading this ancient computer science paper in first place? Answer is huge changes in the way we have started viewing universe recently. While Seth Lloyd's book ""Programming the Universe"" does good job of explaining this thinking, the summary is that the universe can be seen as computing machine rather than particle and energies in the realms of physics. There was even a paper that proposed that even a simple system consisting of billiard balls interacting in space is Turing complete! That means by setting billiards balls in some initial points in space and velocity can computer anything that your laptop can compute in theory. To understand advances in this area you have to fully understand what is Turing's machine and what it means to be Turing complete and how one can prove that a certain system is computationally Turing complete. That's where the paper comes in. Text books just don't do justice.",58
Eric J. Wu,5.0 out of 5 stars,Perl Best Practices: Standards and Styles for Developing Maintainable Code,This book has changed my life,"This is a must-read for any Perl programmer. You are only as good as the teachers you have, and if your teachers use stuff like $|++, you are screwed. In this case, Conway would tell you to Use English;, and then you'd know what a $| is. A sampling of other tips:

Don't modify via $_ (too easy to screw things up)
Use hashes for arguments if arguments > 3 (trackability)
Use Croak instead of die (Croak gives more info, better for debugging)
Use ' ' instead of "" "" when no interpolation (less ambiguity)
Don't use unless (complication and confusion).
use /xms in regexes (for readability, and avoiding mistakes)
test when closing or opening a file

A few of the reviews here are 1 star. IMO these are people to which ""freedom"" is more important than ""group code maintainability"". This should really be the third Perl book for anybody, after Learning Perl and Intermediate Perl.

For those wanting to test their code against this book, there is a Perl Module, Perl::Critic, that does the job.",57
BRIAN M THOMAS,5.0 out of 5 stars,Python Machine Learning,My new #1 Python ML book!,"This is a fantastic book, even for a relative beginner to machine learning such as myself. The first thing that comes to mind after reading this book is that it was the perfect blend (for me at least) of theory and practice, as well as breadth and depth.

Let??s face it, we know that machine learning isn??t an easy subject. You need theory??but you also need practice in the form of some serious coding before you really start understanding it. And this is one area where Sebastian??s book shines: it contains a plethora of really good code examples that are illuminating and well explained, and which cover a very wide range of different machine learning algorithms. And, speaking of code, as another reviewer has pointed out, another huge plus is that, in many places, Sebastian shows you how to gauge the performance of your code and make it more efficient.

For me, the best measure of any book such as this is how many ??ah ha!? moments I had while reading it. And I had more than a few while reading Sebastian??s book. One such ??ah ha!? moment came while reading chapter 12 (and this also illustrates that nice blend of theory and practice I already mentioned above). In this particular chapter, he discusses training artificial neural networks for image recognition. At the heart of this approach is back propagation, which is pretty much THE bread and butter behind multilayered neural networks. He presents a detailed discussion of back propagation in two separate pieces: one that is intuitive and ??top down?; the other a more mathematical, ??bottoms up? approach that goes through the algorithm step by step, showing how the gradients are computed and the weights updated. His treatment of back propagation was one of the better explanations I??ve seen and really cleared things up for me.

One last thing I must mention: at the time of release, this was the first machine learning book for Python (to my knowledge) that has an entire chapter devoted to Theano, which he uses to parallelize neural network training. For those who don??t know, Theano is a particularly nice (not to mention very powerful) Python library for doing machine learning, most especially if you can utilize the power of GPU computing. In addition, that particular chapter (13) also introduces the brand new Python library named Keras, which is built on top of Theano and is a really nice library for the rapid building and prototyping of neural networks (in the spirit of Torch). Being a brand new library, his treatment of Keras was necessarily brief, but it was a great starting point.

In conclusion, I am very confident that if you do pick up this book, you won??t be at all disappointed. And be sure and grab the accompanying code for the book on his GitHub repository (just look for ??python-machine-learning-book? on github.com/rasbt.) His code is top notch and I??ve yet to encounter any problems with it.",56
David J. Kreiter,4.0 out of 5 stars,"Decoding the Universe: How the New Science of Information Is Explaining Everything in the Cosmos, from Our Brains to Black Holes",Information is physical,"Charles Seife has not been the first to proclaim that the most fundamental entity in the universe is ""information"". Physicist John Wheeler, David Bohm, and Tom Siegfried among others have held this view as well, but no other author I've read has gone to such lengths to establish this idea as an undeniable conclusion.

In a consise staight-forward format, Siefe delves into biology, computer science, cosmology, Relativity, and quantum theory, to establish the notion that information and the second law of thermodynamics are intricately linked. And he does this without ever allowing the reader to become lost or confused.

Information is always physical, whether it is marks on paper, holes in a punch card, atoms in an electo-magnetic state on a CD, photon polarization, or up/down spin on an electron. All information has a physical representation. And like any physical thing in our universe, it abides by the laws of nature, including the laws of thermodynamics and Relativity. Information, like energy, can neither be created nor destroyed. Infomation always moves toward the most probable state: maximum entropy. And no information can travel faster than the speed of light.

The qubit, which is the quantum representation of the classical bit, abides by the laws of quantum physics, and despite the weird instantaneous quantum connection between particles in an entangled state demonstrated by Bell's theorem of inequality; the qubit does not violate faster-than-light communication. Oddly, the qubit does violate one tenant of Relativity--that no effect can precede its cause. It seems that the time-asymetrical qubit has no ""before"" or ""after"".

Unlike the classical bit wich resides in a binary, either/or state, the qubit can be in a superposition of states: Two states simultaneously. This fact is what makes the possibility of quantum computing so enticing. By nesting probable outcomes in a superposition of states many fewer yes/no questions are needed in algorithms, making quantum computing many orders of magnitude faster than classical computing.

But, far wider implications exist for the quantum qubit. Siefe believes that the qubit's superposition of states solves two contentious vagaries of the Copenhagen Interpretation of reality: What constitutes an observer? And is there a difference between the classical and quantum worlds?

Siefe says that there is no clear-cut demarcation between the subatomic and classical world, and there is no conscious observer required to collapse the wave function. This directly leads to a resolution of the famous Schrodinger's cat paradox. Since the universe at large is constantly involved in probing with light waves, neutrinos, and zero point energy, the universe itself acts as the observer. Large macro objects such as cats undergo decoherence (a collapse of the superposition of states into a classical bit) very rapidly, while a single subatomic particle or photon take a much longer time, being less likely to come into contact with nature's measurements.

Information is so fundamental that Siefe believes Richard Dawkins popular book called ""The Selfish Gene"", would have been more appropriately titled ""Selfish Information"". Siefe says that when it comes to biological organisms, information is even more selfish than the gene, and can run contrary to survival of the fittest. He cites several examples of information reproducing itself even though it is detrimental to the organism, and at times, to the entire species. Information will attempt to replicate even at the expense of the proliferation of the organism carrying the information.

This book was very enticing, and left me with some questions. Is it information that is the most basic entity, or is it ""meaning"" as physicist David Bohm maintains? Is there a difference between information and meaning? Experiments with polarization of light lead me to suspect that there is a difference.

And, finally, is the brain really a classical machine as Siefe says, or is it a quantum machine as Evan Harris Walker maintains? (See my review: ""The Physics of Consciousness"" on Amazon). Either way, Charles Seife is right on the mark with this work. I give this book 4.5 stars for being an excellent and fun read.

This review by David Kreiter, author of Quantum Reality: A New Philosophical Perspective.",56
Susannah St Clair Foxy Loxy,3.0 out of 5 stars,Alan Turing: The Enigma,Very Intellectual . Past My Brain Power,"I really enjoyed the beginning where you learn a lot about the English culture sand schooling. You also get a good look into the mind of a most amazing man indeed. Once past this part however, it get very involved in all the actual too and froing within England's scientists, engineer's and mathematicians and Turing on how to create a machine that can compute large problems. You never really get into just how Turing was able to break the German code which is what I was interested in plus the man himself. His story is a sad one in a lot of ways. He was a homosexual which is quite illegal in England and he really pays a price for it eventually. If you have a very scientific mind and this kind of thing is interesting to you, it is very well written and flows well too.. I think, as lots of it was hard for me to follow. So its up to you to take a chance or not.",56
Neal Stanifer,5.0 out of 5 stars,"How We Became Posthuman: Virtual Bodies in Cybernetics, Literature, and Informatics",Hayles delivers a (virtual) reality check.,"Finally, a well-informed, razor-smart analysis of the cultural evolution of information as we (mis)understand it today. Hayles does for information and cybernetics what Foucault has done for sexuality, madness and the penal system, and she does it in a way that is thorough-going, highly contemporary, and enjoyable. Hayles offers the paradoxically devastating thesis that, in our visions of information, in our approaches to cybernetics, and in our handling of our own place in the world, Western culture has been hurtling down the wrong path. We have forgotten the physical. Worse, in order to forget the physical, to elide our own bodies, we had to forget or disregard a mountain of evidence. Not content to let us remain ignorant, Hayles recalls that evidence for us, shows us where we've come from, where we are, and offers some insight into where we're going. This is one of those books that you will tell all your friends about.",55
calvinnme,5.0 out of 5 stars,Learning OpenCV: Computer Vision with the OpenCV Library,A great guide to OpenCV with plenty of context,"This book is excellent at exposing the reader to the various methods available in OpenCV and showing via code examples how to use each one. The author also gives you the website where you can look at the actual source code of each method shown. This is helpful since, for example, if you want to know exactly how the code is going about calculating the Fundamental Matrix, it is difficult to determine this by reading the book alone.

This book would be most useful to someone who already has a fundamental understanding of computer vision and image processing and wants to see how OpenCV will make their programming tasks easier. It does this by coding up well known algorithms into reliable pieces of code that you can use to accomplish more complex tasks. Do not come to this book if you are seeking to learn computer vision. You will only be confused as the author does not offer enough detail to teach you the mathematical foundations. However, I don't think that was his intention at all. Instead it is part user manual, part basic computer vision tutorial and overview, and part idea book. Each chapter is supplemented with excellent and interesting programming exercises that test your knowledge of what has been presented in a practical setting.

For a good basic understanding of computer vision try Computer Vision. To understand the algorithmic underpinnings of 3D computer vision try Introductory Techniques for 3-D Computer Vision. However, before you read either of these you must read Digital Image Processing (3rd Edition), since image processing concepts are fundamental to understanding computer vision tasks. In fact, the two disciplines overlap in many spots. The sad truth of the matter is that no one book will teach you what you need to know to be an effective image scientist. However, this book on OpenCV is essential reading on applying the theory via programming in an effective manner. Highly recommended.",55
Robert Lawton,4.0 out of 5 stars,Alan Turing: The Enigma,Turing Explained - Turing Hijacked,"Alan Turing makes an absolutely fascinating subject for biography. Not only did Turing significantly contributed to the allied victory in World War II, but one may also consider him to be the father of the modern ""thinking machine."" Indeed, most introductory computer textbooks still contain references to the ""Turing test"" for artificial intelligence.
In Part 1, Hodges writes a riveting account of Turing's youth, scientific pursuits, and war-time contributions. He carefully details descriptions of the German ""Enigma"" coding machine, coding theory, and the code breaking process. Having no significant background in mathematics or ciphering, the reader could probably build his or her own Enigma machine based solely on Hodge's lucid descriptions.
Unfortunately, Part 2 does more to promote Hodges' own agenda than it does to illuminate Turing's life. Hodges makes his agenda clear for Turing's biography following the Postscript in a section labeled ""Author's Note from the 1983 Edition."" In this, Hodges explains that he discovered Turing for himself while preparing a pamphlet critical of the current medical model of homosexuality as member of London's Gay Liberation Front (535). Part 2 of this biography clearly serves as a platform for that purpose.
While generally dull, Part 2 did offer a few surprises. Though not stated explicitly, Hodges' illustrations demonstrate that the premise behind ""Clockwork Orange"" finds its roots in the state of England's psychiatric medicine in the 1950's. Imprisonment, castration, hormone therapy, operant conditioning, and psychiatric treatment all played a part in the West's attempts to understand and cope with the nature of homosexuality and the male homosexual's role in society.
Since Turing himself did not crusade for gay rights or take any interest in the rather well known intellectual gay communities of the time, the author's agenda appears significantly out of place. Though persecuted, prosecuted, convicted, and ""treated,"" Turing simply wished to be left alone to pursue his various interests. Hodges should have done the same. Yes, details of Turing's relationships, lifestyle, arrest, trial, and treatment belong in a biography along with their historical context, but Hodges frequently departs with obscure references and musings many readers might not understand and which were simply not part of Turing's own experience.
This biography also left me craving more details regarding the links between Turing's early work and his later work as well as for more details specifically about his later work. I don't think Turing simply changed fields of interest mid career. After all, buried within the mechanics of nature lie the seeds of non-artificial intelligence. What better way to recreate that intelligence artificially than by mastering and modeling the original?
I recommend special treatment for this biography. Rather than bullying your way through every page, simply start reading from the beginning, stop when you lose interest, and don't feel guilty about putting it down incomplete.",55
Stephen E. Robbins,2.0 out of 5 stars,Our Final Invention: Artificial Intelligence and the End of the Human Era,Fear of What Exactly?,"This is a confused book. For nearly 200 pages, the book is chocked full of the triumphs of AI, the incredible and powerful form of intelligence that we are artificially building, the inevitability of this AI (or AG[eneral]I) surpassing that of the human, and on nearly every page, the threat humanity will face in the case - drummed as an extremely high probability - that we will have a ""runaway intelligence."" Watson, the Jeopardy champion which gleans its ""knowledge"" from vast sweeps/correlations in Wikipedia and other digitally encoded texts (not from the concrete world), is one of the main stars. Siri, the language recognizer also features,, along with a parade of AI wizards and prognosticators. The first significant crack in the continuous theme of warning/prognostication/worry appears around p. 45-ish where Searle and his Chinese Room argument is briefly discussed, an argument in which Searle argues that there is no understanding whatsoever arising in a Searle's hypothetical computer (being Searle himself following a translation algorithm) translating English to Chinese. This to say, the disturbing question is broached: just what actually is this AI as an ""intelligence,"" or better, what actually is ""intelligence?"" But Searle's critics are quickly invoked (""Surely the overall 'system' understands.""), while Barrat swiftly states that Searle might be right at least in the sense that there is surely ""something different"" about this form of intelligence - and the warning theme and parade of AI geniuses marches on.

Then, 200 pages in, we hit this: ""The problem is, systems that are inspired by cognitive models may ultimately fall short of accomplishing what a human brain does. While there's a lot of promising headway in natural language, vision, Q&A systems, and robotics, there's disagreement over almost every aspect of the methodology and principles that will ultimately yield progress toward AGI...As Goertzel said, there is no generally accepted theory of intelligence and how computationally to achieve it. Plus there are functions of the human mind that current software techniques seem ill-equipped to address, including general learning, explanation, introspection, and controlling attention."" Believe me, this is but a minimal list. Yet for 200 pages we have been treated to a series of dire prognostics as well as boy geniuses of AI, some arguing for 2020 as the ""date"" when AI achieves equality and marches beyond.

This is the problem with the book. The author, a film maker, evidences no clue as to the depths of the problems he is skating over. He most cursorily touches on the current idea in (some of) AI that it must incorporate ""embodied"" cognition, i.e., the fact of our abstraction of knowledge from the concrete world (not from digital text) via our embodiment as physical systems. There is no examination of the depths of this problem - the physics, chemistry and dynamics (of the actual biological/physical system we are) that must be understood and recreated - that bespeak of decades of future research - and true progress will occur in this only if done in the right scientific paradigm. This includes the fact that we have no theory of perception - the origin of our image of the external world - thus of our experience itself, thus of how this experience is stored in the brain (if it is), thus of how it is used in cognition, to include analogy making. Hofstadter (Surfaces and Essences: Analogy as the Fuel and Fire of Thinking) just devoted a massive tome to proving beyond doubt that analogy is the absolutely fundamental operation in cognition, yet it is clear he has no clue (and great doubt) as to how computers can actually do analogy (without faking it). What is the power (read, ""threat"") of an intelligence that cannot perform this fundamental operation of thought (which happens to require consciousness)? Barrat, before sliding on, would rather quote Moravec's diminishment of the problem (p. 204, higher functions = later in evolution, less time to be complex/hard), one which completely misses the fact that these higher functions of thought (cognition, language, checkers and chess) might be completely, integrally built upon the lower (e.g. perception, action in the concrete world), and thus may actually be totally different in nature than AI believes.

I lost count too of the number of times Barrat says (or quotes a genius) that the AI systems must/will become ""self aware,"" with no comprehension or discussion of what this means. It happens to be a deep problem within our model of time itself, its flow as perhaps indivisible or non-differentiable - as opposed to the discrete state metaphysic and model of time actually implemented by all AI/computational approaches. This in turn reflects the complete failure of current cognitive science (yup, those ""cognitive models"" Barrat refers to), itself deeply mired in the computer metaphor of mind, to grasp or include any role for consciousness (itself flowing in an indivisible time) in cognition, i.e., there is no current role in its models for consciousness in intelligence. On what basis then are we fearing an utterly unconscious ""intelligence."" What would be the actual ""power"" of such an AI? Utterly unaddressed.

In sum, the really deep and interesting issues are in effect totally neglected in this book. For those interested in these deeper issues - on what might really be involved to equal human intelligence and mind, one might check Gunther's Mind, Memory, Time or my review thereof.",53
Captain Zones,1.0 out of 5 stars,Artificial Intelligence for Games,Don't buy the Kindle version,"The one-star is for the Kindle version. Don't buy it. ""Print Replica"" means it's a lousy DRM'd PDF file. There's no resizing of text, and if you like reading in landscape mode, it's pretty ridiculous.",53
Tim Koren,2.0 out of 5 stars,Robot Building for Beginners,The book is focused on a project which requires a robotics kit that is no longer available,"While the book seems to be thorough and well-written, the majority of it is written with a robotics project (The ""Sandwich Robot"") in mind. If you bought the book in 2010 or 2011, it seems that you would have been able to purchase the $50 kit from [...] follow along in the book but the kit is sold out now. I've attempted to contact the author (David Cook) to inquire about future availability but have not received a response, so I'm going to assume that the kit will not be made available again in the future. It's a little disappointing that he cares so little about supporting his books that he will not even send a quick email to confirm that the kit will no longer be made/offered.

I think the book would have rated fairly high if the required equipment was available, but the lack of it forces me to drop the rating to a 2.",53
K. Parent,2.0 out of 5 stars,Machine Learning with R - Second Edition,Already obsolete,"This book uses R packages that are have been updated since its publication and no longer work with the code given in the book. I contacted the publisher, but because the code works fine with the package versions it was written for, they will not offer updates on their website. If you know machine learning and R well, you can probably figure out a workaround, but you're also not the intended audience for this book.",52
K. Parent,2.0 out of 5 stars,Machine Learning with R,Already obsolete,"This book uses R packages that are have been updated since its publication and no longer work with the code given in the book. I contacted the publisher, but because the code works fine with the package versions it was written for, they will not offer updates on their website. If you know machine learning and R well, you can probably figure out a workaround, but you're also not the intended audience for this book.",52
Steven Marks,5.0 out of 5 stars,Mastering MATLAB 7,Materful Book,"I am going to also write a review on ""Matlab Guide"", I will be also comparing the two books in the reviews.
If you are considering Matlab as a scientific computing language - look no more. It has licensened the ""Maple Kernal"" as part of its ""Math Symbolic ToolBox"", it uses LAPAK from FORTRAN for the algorithms for Matrix operations; it uses a high level language (very C++ like) and its own consise syntax for matrix manipulations as well as ""Handle Graphics"" to produce impressive looking plots and reports. In otherwords, it combines the best of various approaches. If you do not know C++, I advise that learn that first before attempting to learn Matlab.
Comparing ""Mastering Matlab 6"" (MM6) to ""Matlab Guide"" (MG):
*Both books are NOT for absolute Beginners, I think the assumption is that you will first study the book that comes with Matlab and the supurb ""Help"" Documentation that comes with the program. There are also good starting out tutorials on the net - search: ""Matlab; Tutorial"". The US Navy has a consise tutorial to get you started.
*MM6 does a better job on teaching to the next level beyond the Mathworks supplied documentation and beggining Tutorials.
*MM6 WINS HANDSDOWN ON TEACHING version new to 6.0 specific features. You are short changing yourself by going for a 5.0 text.
*MM6 is geared more towards a programmer/scientist/engineer; whereas, MG is geared to a mathematician. MM6 is comprehensive (800 pages!), but well organized that you can branch off to a given chapter without covering all prior chapters. Because I had a problem to solve, I started on Chapter 18, ""Interpolation"" without any problems. If you have no immediate issue - taking the book in order is advised. BUT THE BOOK IS WELL CROSS-REFERENCED THAT you can jump ahead to a topc of interest.
**MM6 is real modern: There are 4 chapters (out of 28) that delve into the Object Oriented aspects of Matlab, interfacing to C or Fortran, Extending Matlab with Java and integrating Matlab with Windows using Active X. 7 Chapters are devoted to Graphics, Interface, Movies. 9 Chapters are devoted to Topics that a modern Scientist or Engineer would need to know to take advantage of Matlab: ODEs, Optimization, Fourier Analysis. MM6 covers the topics in detail. Other chapters really get down to the nitty gritty of the Matlab programming language.
I believe that MM6 is ideal for an Engineer/Scientist who is looking for a book to take him or her from the Apprentice to a Journeyman level in Matlab. Beyond that, the books would have to become more specialty (Chem E, Controls,...) orientated. This will get you to the plane where you can then focus on your specialty.",52
jennifer67,1.0 out of 5 stars,Our Final Invention: Artificial Intelligence and the End of the Human Era,We're All Gonna Die!,"I've read a half dozen books on the future of AI in the last few months because it plays a peripheral role in a possible novel I have planned and I didn't want to mangle the subject. By far, this book provides the most close-minded and overall worst treatment of the subject.

The author is not a computer or AI expert (or even dabbler) but rather a filmmaker whose body of work focuses almost exclusively on middle eastern archeology (really!) for National Geographic (visit his website). He has one single urgent (!) message that does not vary from page one to the very end: AI will soon achieve a level of super-intelligence superior to humans and almost immediately (as in minutes to days) wipe out not just humanity and the earth but the entire universe (really, he says things like this). The destruction will be horrific and is already inevitable and unstoppable so you might as well give up now.

The author has no hesitation about putting down the views of any major voice in field who doesn't fully agree with the premise of this novel -- oops, I mean work of scholarship. Most of what little you will find here has been lifted from other more thoughtful works and then sensationalized and beaten into the ground in a self-congratulatory I'm-smarter-than-you-or-anybody else manner. Scattered throughout are a few face-to-face interviews with fringe figures who totally agree with the author's extreme prejudices and so made the cut.

Unless you like enjoy reading the same ideas (make that idea, in the singular: we're all gonna die) over and over again, sometimes several times on a single page, just scan the title and then skip this junky offering seemingly conceived to shock and titillate.",51
janet belsky,5.0 out of 5 stars,Humans Need Not Apply: A Guide to Wealth and Work in the Age of Artificial Intelligence,Jared Diamond of the future,"Jerry Kaplan does for the future what Jared Diamond did for the past: He pulls together our human (or humanoid) fate in sparkling,often hilarious, prose.

Kaplan begins by offering the non scientific reader (me) a clear overview of the AI advances that are poised to make human workers obsolete--offering eye popping examples explaining how the pace of technology is destined to overwhelm the human landscape of life and work.

He then charts the changes that span FAR more than driverless cars. Mechanical robots (or what Kaplan calls ""forged intelligences"") will be more adept (and. of course, far more cost effective) than humans at performing every routine job from collecting our garbage to stocking our grocery shelves (and make those physical stores quaint relics of the past). ""Synthetic intelligences"" (machines that think and analyze information) will outwit humans at making complex diagnoses or writing legal briefs--automating out many of the hapless law school or medical students spending decades accumulating those mountainous student debts .

So far readers may be saying "" I know all that stuff"". Actually, you don't. The real gem of this book is that Kaplan CALCULATES how many people enter the workforce with those mountains of debt and compares their expected salaries. He analyzes the current employment situation for new law school grads and other ""knowledge workers"". He offers a wealth of data documenting how many jobs are going to be lost... beginning with that prime exemplar (AKA job wrecker), Amazon. I always wanted to know how Amazon evolved, the truth about this behemoth's business model, and how many jobs Amazon has automated out... In this book you will actually get these statistics and much more, as well as learning exactly why those standard government ""job growth projection"" stats are apt to be totally wrong.

In other words, as you read in these other reviews , this book is all about income inequalities and what we can do to in Kaplan's words to slow the transition to making ""America the Land of the Pharaohs"" ( You ain't seen nothing yet). In fact the chapter--of this title- describing the lifestyles of Kaplan and his much richer colleagues versus one of his hardworking employees is the best in- the- flesh description of income inequalities I've read.

Kaplan has the huge advantage of personally knowing these billionaire Silicon Valley movers and shakers--in addition to having a birds eye seat on how these technologies evolved. But, most important, he has a gift for bringing it all home through creative analogies and zinger-like sentences that had me rolling on the floor. So if you like Jared Diamond, or even if you don't know who he is, you will LOVE this landmark book.

P.S. I've omitted the fact that Kaplan also suggests answers.. that is, he devises highly innovative policy suggestions to make playing field less steep that come closer to attacking the roots of the problem and go well beyond the current mantras such as increasing access to college or raising the minimum wage......",51
Ganamide,3.0 out of 5 stars,Quantitative Technical Analysis: An integrated approach to trading system development and trading management,Could be better,"*** Edit ***
I just wanted to update my review after having spent considerable time using some of the techniques in this book and learning more about quantitative technical analysis of market data from other sources. I still stand behind my original review that is below this edit.

First, I think the title of this book is a bit misleading. This book does not really cover quantitative technical analysis. The book is really an introduction to developing automated trading systems using both the more traditional indicator approach and the newer machine learning approach. There is not much information about statistics in this book, and statistics are really the foundation of quantitative analysis. I think that the contents of a book with this title should be at least half full of statistics, particularly how they should be applied to market data and to analysis of trading system returns.

Second, while using python was fun and interesting at first, I ran into a lot of issues trying to do statistical analysis with it. The best part of python is that you can use the interpreter with compact commands and do some powerful number crunching and generate charts on the fly. The problem is that a lot of the commands and syntax for both SciPy and pandas are very poorly documented. I spent days trying to figure out how to do things and sometimes I could not find any good examples or explanations of how to use certain methods. Keep in mind that I have been programming for over 15 years and I am quite good at figuring things like this out.

Finally, I wanted to provide some links to resources that I have found helpful. I discovered another author who does a very good job at explaining quantitative analysis, his name is Adam Grimes. He wrote a book that sells on Amazon called The Art and Science of Technical Analysis (http://www.amazon.com/The-Art-Science-Technical-Analysis/dp/1118115120). I took his free 35 hour trading course and found his approach to analyzing trading systems superior. He also has a free ebook (Quantitative Analysis of Market Data: a Primer) that was quite helpful. You can find these on his website (http://adamhgrimes.com/TAAS/). Finally, if you are inclined to use C#, I found a very promising open-source library that has plenty of statistical and machine learning components. It's called Accord (http://accord-framework.net/). The library comes with many samples, but none of them are trading related.
*** End Edit ***

I was really excited when I bought and received this book. It seemed like just the thing I was looking for - a new book on state of the art trading system development that included machine learning, coupled with downloadable source code.

While I can't say that the title, table of contents, or index were inaccurate, the content was a little less robust than I had hoped. It was as if titles were given to sections just to beef up the table of contents and many buzzwords were included to make the index more sexy. There were several instances where the author only gave a cursory overview of a topic and directed the reader to some webpage or book to learn more, without even trying to give a basic explanation of what the topic means.

I was slightly offended when the author chose to include program listings and results for fifteen different machine learning algorithms that were nearly exact copies of each other, except for 2 lines of code to call the featured learning algorithm. Each of these copies contained a note telling you to go to the scikit-learn webpage to learn more. What a waste of 30 pages in a book that costs so much! I would have much rather seen the author use those 30 pages to explain these different learning algorithms and describe which ones to use for different types of trading systems.

Another area that was lacking is the application of the book. All the examples and sample code assume that you are working on a stock/ETF trading system that enters/exits trades once a day. I want to build a system that trades highly leveraged futures many times intraday, and there isn't much information on how to handle that. I thought ""Trade Management"" would cover techniques to manage live trades, adjusting positions while in a trade. This book uses the term to mean end of day assessment of a trading system after a trade is closed, or marked to market. Then using the results to compute position sizing and decide whether you should take the next trade. The DynamicPositionSizing program provided in the book takes a few hours to run on a set of 3000 trades. This might not be an issue for an end-of-day system, but that definitely won't work for a system that generates 100 trades a day.

The book recommends not including stop losses in your trading system. With leveraged futures products, many people cannot afford to do this. If you are building a high frequency futures trading system, you really need to use stops, and this doesn't mesh well with the sample code in this book that is supposed to calculate risk, a safe position size, and the objective function. I'm sure it can be modified to work, but it is a bit disappointing that I have to do these additional steps on my own.

One final gripe is that this book uses Amibroker for the indicator-based portion of the book. Amibroker can be powerful, but it's language and platform are difficult to use, even for a seasoned programmer such as myself. It would have been much better if a more widely used trading development platform such as NinjaTrader were used. Or even better, if a custom platform was used and provided as a download.

That said, I still think there is some value in this book. It gives a pretty good overview of trading system development and things to look out for. This book also gives an introduction to using machine learning for trading system development. For someone new to machine learning like myself, I find this useful - at least now I know which python libraries and websites to look to for more information (hint: scikit-learn). The downloadable python code is probably the best part of this book, especially if you want to build a stock/ETF end-of-day swing trading system.

For those interested, the python libraries used for the machine learning stuff are:

NumPy
SciPy
Pandas
MatPlotLib
Scikit-learn

""For more information, refer to the scikit-learn webpage."" - Howard Bandy",51
Andy55555,1.0 out of 5 stars,Machine Learning in Action,"Great idea, terrible execution","Using Python and NumPy code to teach machine learning is a great idea. Well-written Python is so easy to understand that it's often called 'executable pseudocode', and third-party extensions such as NumPy and SciPy make it competitive with platforms like Matlab for math and science application programming. The author seems to know his subject, and he had another good idea when deciding to structure the book around the ten most popular machine learning algorithms (though he only ends up covering eight of them for reasons he explains in the introduction). Unfortunately, the book is poorly written and even more poorly edited; it reads like a very rough draft that was put once through a spell-checker and then published. The text is repetitive, confused, and often doesn't match up with the code and data sets to which it refers. Color-coded figures are published (in the print edition) in black and white. I'd hesitate to trust this author and publisher again (not to mention the reviewers who gave the book four or five stars).",51
Barron Laycock,5.0 out of 5 stars,"The Cult of Information: A Neo-Luddite Treatise on High-Tech, Artificial Intelligence, and the True Art of Thinking",A Full-Broadsided Body Punch To Conventional Wisdom!,"This book is a thoughtful and thought-provoking examination of both the meaning of and the consequences associated with the rising computer information cult within contemporary society. Roszak is a skilled writer and an even more perceptive thinker. He quickly disposes of the contemporary idea equating data or information, on the one hand, with knowledge and wisdom, on the other hand. He despairs of the notion that technological progress is an unalloyed blessing, and provides a lot of supporting documentation illustrating that for all those capabilities we gain through the use of digital technology, for example, we also lose important capabilities and perspectives.
According to Roszak, we have now come to almost rely on exclusively rational,""logical"", and quantifiable methods of understanding everything around us, often to the detriment of ignoring more traditional and time-honored methods of knowing. This, in turn, leads to a very narrow perspective of how it is that the world operates, one devoid of anything not quantitative, anything comprised of more ""qualitative"" means of observation. Thus, to the digitally oriented logical and rational mind, anything not disposed to undertanding through calculation and the scientific method simply is not real. Furthermore, he shows us, such digital computing techniques creates as many problems as it solves.
He fears for good reason that we are falling into a hyperbolized and superficial culture where we have come to completely depend on scientific rationalism as it is depicted by the media, and that this creates a conundrum we cannot escape from, since many of the problems associated with modern society stem from this increasingly exlusively scientific and rational approach toward problem-solving.
As with other contemporary critics of the new Digital Intelligence cult like social critic Neil Postman, Roszak argues for a more comprehensive perspective , one that places the tools of computer technology at the behest of a more broad-based intelligence, one that recognizes that there is a whole range of ways of knowing and understanding that those contained in programming code. This is a provocative and thought-indicing book. I enjoyed and learned from it, and recommend it to anyone who enjoys watching a superior intellect at work, and who also appreciated the thread of a finely-hewn intellectual argument. Enjoy!",51
Amazon Customer,4.0 out of 5 stars,Nine Algorithms That Changed the Future: The Ingenious Ideas That Drive Today's Computers,"Great book, but not complete....","Great book. Good for showing young people that computers can do more than just play games and access facebook.

Written on VERY elementary level, rather not for professional but for complete amateur. Good as a basis for popular lectures, on K-12 level.

However, selection of ""great"" algorithms is a bit arbitraty and limited. Some GREAT algorithms are missing:

1. FFT (Fast Fourier Transform). This is the bridge bewteen analog world and digital world. Without FFT would be no digital communications, digital music and modern cell phones

2. Kalman Filter. Algorithm for extracting useful signal from noise. Without Kalman Filter would be no space ships, telecommunication satellites and car computers

3. Linear Programming. How to make optimal decisions. This is the tool that makes economy efficient, controls manufacturing and transportation

Conceptually, these algorithms are a bit more complex than ones described in the book - some mathematics is needed to present these algorithms. But experience shows that elementary presentation is possible. In addition, these algorithms show that MATHEMATICS is the basis for great algorithms. This simple fact is not understood by young peopole who associate great algorithm with nothing more than programming in Java. And this simple fact is not sufficiently visible from the book",50
Christian Weisgerber,1.0 out of 5 stars,The Singularity Is Near: When Humans Transcend Biology,Don't get the Kindle edition!,"Do not bother reading The Singularity Is Near (Feb 1, 2007 edition) on the Kindle.

The book contains many graphs which are barely or not at all readable on the Kindle 2. (This may be better on the DX.) There are references to page numbers in the text which are entirely meaningless on the Kindle. There are misformatted numbers: ten to the minus n is not the same as ten to the n. But most importantly, about 40% of the volume of the book are notes. These appear as endnotes on the Kindle but they are NOT LINKED from the main text. You just get a number in superscript. The table of contents has a single entry point ""Notes"", not even separate ones for each chapter. You have to page through all the way. This makes it virtually impossible to look up the notes from the main text. Again, the notes are a major portion of the whole book.

The whole thing can serve as an example how NOT to prepare an e-book edition.",49
Douglas,5.0 out of 5 stars,Accelerated Spanish: Learn fluent Spanish with a proven accelerated learning system,The online course uses many of the same visuals but the book is so much better. It combines the materials spread over multiple l,"I have been working with Timothy Moser's online Spanish learning materials. Having studied Spanish over the years, the Accelerated Spanish approach is amazingly different. It starts with the most used words and builds on that foundation. After a couple of lessons you will know about 25% of the language. But that is only the beginning. As you explore Joel's world, you will build visual memories of the necessary words and grammar to accelerate your learning.

The online course uses many of the same visuals but the book is so much better. It combines the materials spread over multiple links online in one place. The pictures are more professional and lodge themselves more firmly in your memory.

If you have any interest in learning Spanish, try this approach. You will enjoy it.",49
GameMaker,3.0 out of 5 stars,"Mathematics for 3D Game Programming and Computer Graphics, Third Edition",Math majors rejoice,"To be honest, while I find this book to be a decent reference, I find it to be pretty inaccessible in terms of sitting down and reading through it in an attempt to learn the concepts. As a non-math major (I'm actually an engineer and software developer) these math concepts are by no means beyond me. But rather than simply being presented with equation after equation, proof after proof, what I find a lot more valuable is more discussion on the usage of these equations. Specifically I'd like to see examples, diagrams, and code, and there is precious little of any of that in this book.

In other words, this book is very much like what you expect to find in a very dry upper devision college math text for the consumption of math majors who are used to such things. But for a non math major just trying to make use of these concepts in order to get the job done and make games? eh, not so much.

Still, I do think this book is useful as a reference when I want to look up an equation as there are a ton of them crammed into this book, but for me, I just don't find this book to be very good as a learning tool.",49
Let's Compare Options Preptorial,5.0 out of 5 stars,Probably Approximately Correct: Nature's Algorithms for Learning and Prospering in a Complex World,"Outstanding, too short, you'll want more!","Talk about fuzzy logic on steroids! After reading the subtleties of this ""math"" book (translate: studying-- every sentence is so PACKED with insights, that you can't really just speed ""read"" this), you'll be stunned, and hungry for a LOT more. In a very short couple hundred pages, the author integrates everything you've always wondered about how Godel, Cellular Automata / the game of life, thousand page programs of differential equations reduced to two algorithmic lines, Darwinism applied to a new definition of computer learning, etc., relate to each other! The subtitle of the book should be ""non expert generic learning algorithms"" or ""Darwinian computers"" or something unprecedented like that. You'll even learn why we can't put Sherlock Holmes' brain in an algorithm.

In brilliant fashion, Valiant twines natural (as in nature) problem solving and learning with the algorithmic processes of neural learning, and potentially machine learning (redefined), and sneakily hints at how the brain can process systems of dynamic partial diffential equations as matrix calculus without us even knowing it! If you've ever wondered how your brain can hold dual uncertainties (time/motion or frequency/time etc.) constant with PDE's (Fourier transforms) as you cross a street, without your ""conscious"" mind even being able to solve a partial differential without peeking at the text examples (let alone a Fourier inverse), this amazing book finally gives the closest I've ever seen to a believable answer. WOW are we EVER smart without ""knowing"" it!!! One of the many ""ahas"" is how ""non experts"" (eg our ""conscious"" brains) can invent things like calculus.

There's no advanced LaTex such as complex exponential superscript equations for e-readers to bugger up, so don't hesitate to get this on Kindle. There are polynomials and subscripts, but my Fire digested them just fine. A few of the many diagrams, tables and illustrations are too tiny to view, but a double tap takes care of that. Yes, the underlying math ""discussed"" really is post grad in some cases, but the author doesn't burden us with that level of notation, choosing instead to describe verbally (and with at most inequalities and a few polynomials and tables) the much simpler underlying ""ecorithm"" (algorithms that learn from their environment).

This book is relevant on too many levels to thoroughly list, but just a few include psych, engineering, algorithms, computational complexity, machine learning, AI, dynamic systems, education, consciousness, neurology, math... and onward. For non math major ""lay"" readers, the text is crisp, clear, readable/studyable with a nice pace and stories/illustrations that make it an unlikely but well written page turner. Strangely also, I truly believe it will appeal to both lay and pro readers/researchers -- the author strikes a very unusual balance with deep computational examples while not coming off as a show off-- one of the best teachers you'll ever want to meet, or if you're a technical author, emulate.

A bunch of books have now been written about how algorithms are taking over the world-- and how ""unseen robots"" (smart phones, cars and 777's) really are ""thinking."" This is better than the whole group of them combined! If you want a peek into your great great grandkids' planet-- get this asap! There are sincerely numerous new insights - discoveries - revelations on each page. The connections described are being researched in many fields right now, but silos prevent a lot of the overlaps between disciplines this author has spotted. They say Poincaire was the last great generalist-- this book makes me wonder. Even so, the author is humble in asking us to question HIS insights and discoveries every time he posits one as novel-- a true scholar.

A NOTE ABOUT COPING: Do NOT mistake the publisher's statements about ""how to cope"" with some self help promo or advice book. This is a very well written, but technical book about learning algorithms (usually relatively short ""guiding"" programs that tell other programs what to do), NOT coping in the usual sense of getting by strategies. Coping here refers more to how algorithms and organisms (yes, including us) can ""navigate"" environments too complex to understand, with shortcuts and guesstimates that work practically.

Author/Publisher: MORE! Expand for another 300 pages in your next edition! DO a version with the PDE's and pseudo code for those of us that don't mind trying to trudge through them.

Library Picks reviews only for the benefit of Amazon shoppers and has nothing to do with Amazon, the authors, manufacturers or publishers of the items we review. We always buy the items we review for the sake of objectivity, and although we search for gems, are not shy about trashing an item if it's a waste of time or money for Amazon shoppers. If the reviewer identifies herself, her job or her field, it is only as a point of reference to help you gauge the background and any biases.",49
Ralph Hodgson,3.0 out of 5 stars,Programming the Semantic Web: Build Flexible Applications with Graph Data,"Welcomed book, but some disappointments","While I am glad to see books about Semantic Web technologies that are written specifically for software developers, I am disappointed that I cannot give this book more than 3 stars. Why? The book contains misleading statements that may lead a developer new to these technologies astray and encourage non-optimal practices. I will give a few examples illustrating what I mean:

-On page 131, the example explaining property domains may lead the reader to believe that having two separate domain statements (ex:hasEyeColor rdfs: domain ex:Human and ex:hasEyeColor rdfs: domain ex:Animal) is ""the"" way to do things. Such a practice creates issues which are not properly explained. And the diagram 6-1 illustrating this modeling example is wrong. Looking at it, the reader is left believing that the domain of ex:hasEyeColor property is a universe of things that includes Humans and Animals, while in reality it is an intersection of Humans and Animals. If someone were now to add another domain triple such as ex:hasEyeColor rdfs: domain ex:Dog, the domain would become the intersection of Humans, Animals and Dogs and a conclusion could be drawn that Jamie Taylor is a dog - obviously, not what was intended.

-On page 140 it is stated that RDF schemas are usually stored in the same graph with the data they represent. This is not true and, to the contrary, is considered to be a poor practice - keeping schema and data separate is important for schema reuse. Did the writers intended to say that they are usually put in the same triple store? The statement is confusing and it is contradicted by the book examples such as those using FOAF. It is clear that FOAF schema and FOAF data files are separate graphs.

-While modularity is talked about (""semantic data model is not a monolithic thing""), the key mechanisms used for modularity (e.g., imports and named graphs) are not mentioned anywhere.

-Describing SPARQL as a ""read only"" language is not correct. While INSERT or DELETE keywords are not part of SPARQL 1.0, the CONSTRUCT keyword provides a way to create new triples. Developers can also use CONSTRUCT to identify triples to be deleted. I also believe it would have been useful to mention that Jena API (arguably the API most used by the developers building Semantic Web applications) already directly implements inserts and deletes and this implementation is being used in the upcoming SPARQL 2.0 spec. Perhaps, this was not known at the time certain chapters of the book were written.

-The cursory of SPARQL is disappointing. SPARQL mastery is as important to the developer working with the Semantic Web data as SQL mastery is to the developer working with the relational data.

-The blank node example of address raised a concern that the imprecise language used in describing the motivations for using the blank node does not make it clear that a blank nodes can never be referenced across graphs.

In conclusion, the book does a good job covering a broad range of topics in a very concrete, down-to-earth way. It directly addresses some of the key misconceptions about the Semantic Web standards. For example, it makes it very clear that RDF is a data model and RDF/XML is simply one serialization of it. The depth of coverage is insufficient and uneven impacting the book's effectiveness for developers. Some choices of the areas authors decided to focus on are questionable. For example, I would have preferred to see less coverage of Freebase and more of SPARQL. I am also left wondering how much of a peer review the book had received prior to publication. An even modestly rigorous review process would probably have caught the most notable errors, imprecisions and omissions and resulted in a stronger book.",49
PaperCowboy,1.0 out of 5 stars,How to Create a Mind: The Secret of Human Thought Revealed,"Buy ""On Intelligence"" instead","Spoiler summary: String Markov Models around Jeff Hawkins &co theories (in print 8 years ago), repeatedly remind everyone that you're Ray Kurzweil and the key insight in this idea is somehow, fundamentally yours, talk about the old days, and voila: mind created!

This book is a sad fumble: a rehash of his old books (almost word-for-word in some cases), punctuated by some vaguely interesting personal nostalgia, and an awkward landgrab as he reveals his grand ""PRTM"" (that looks uncomfortably like other people's work).

Go and buy ""On Intelligence"" by Jeff Hawkins instead.",48
Dr. Lee D. Carlson,5.0 out of 5 stars,Statistical Learning Theory,An excellent overview,"The field of statistical learning theory has not only seen considerable advances in the last fifteen years, it has also found many applications, some of these appearing in commercial packages. It is now classified as a subfield of artificial intelligence, and as such gives an alternative, and frequently more general viewpoint on such topics as pattern recognition, regression estimation, and signal processing. The author of this book is one of the originators of statistical learning theory, and has written a book that will give the mathematically sophisticated reader a rigorous account of the subject. Most of the main results are proven in detail, but the author does find time to include insightful discussion on the origins and intuition behind the concepts involved in statistical learning theory.

Along with a brief introduction, the book consists of three parts, the first being an overview of the statistical theory of learning, the second giving the details of the now widely used support vector machines, and the last one (the most sophisticated mathematically) giving the statistical foundations of learning theory. In writing the book, the author wants to put forward a new approach to dependency estimation problems having their origin in learning theory, and being able to deal with the ?curse of dimensionality?. The origins of the subject lie in the pattern recognition problem and the Glivenko-Cantelli problem in statistics. Both of these problems were discovered to be essentially the same, and the author?s task is to use their similarities to construct a general theory of statistical inference and (inductive) learning. Indeed, a new induction principle, called ?structural risk minimization? (SRM) is paradigmatic in the book, along with the now ubiquitous VC dimension, the latter of which originates in the author?s early research. Both the SRM and the VC dimension illustrate the tension between the need for high accuracy and the need for the minimization of error in data sets.

The learning problem, as the author sees it, is the problem of selecting the correct dependence on the basis of empirical data. Two approaches to this problem are discussed, the first using a ?risk functional?, and the second involving the estimation of stochastic dependencies and the consequent solution of integral solutions. Both of these approaches are modeled in terms of a general model of learning from examples, which consists of a data generator, a supervisor, and a learning machine. The learning machine can either imitate the supervisor or identify how the supervisor operates. These two methods are different, the author says, in that the first one searches for the best prediction based on the data, while the second one attempts to approximate the operator representing the supervisor. Both approaches are studied in the book, with the first one being the easier of the two, while the second involving the solution of ill-posed problems. The author views the learning process in terms of choosing the right function from a given function collection.

Both perceptrons and their generalizations, neural networks, are briefly discussed in the book, along with the back-propagation method. The author gives reasons why he does not think neural networks are well-controlled learning machines, such as the existence of local minima, the slow convergence of the gradient method, and the choice of scaling factors. These problems serve as motivation for the introduction of support vector machines, which are introduced as optimal separating hyperplanes. Support vector machines take input vectors into a high-dimensional feature space via a nonlinear mapping, and an optimal separating hyperplane is then constructed in this feature space.

Similar to the need for neural networks to generalize well, separating hyperplanes must do the same, and due to the large dimensionality of the feature space, a hyperplane that separates the training data may not generalize well. In addition, the large dimensionality of the feature space makes the construction of the hyperplane computationally demanding. The author shows that optimal hyperplanes, found using various mathematical techniques such as quadratic optimization, do generalize well. Also, as the author points out, the explicit form of the feature space need not be known, since only the inner products between the ?support vectors? and the vectors of the feature space need to be calculated. The calculation of the inner product is done with the insight gained from Mercer?s theorem, which gives the existence of a kernel function such that there exists a feature space where this function generates the inner product. This inner product in feature space allows the construction of a decision function that is nonlinear in the input space but that is equivalent to a linear function in the feature space. Different choices of the kernel function give different types of learning machines. The author discusses three examples of support vector machines for pattern recognition: polynomial, radial basis function, and two-layer neural network support vector machines. An entire chapter is spent on the problem of digit recognition using support vector machines.",47
John Mount,5.0 out of 5 stars,"The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Second Edition (Springer Series in Statistics)",Actually does something (huge) with the math,"I have been using The Elements of Statistical Learning for years, so it is finally time to try and review it.

The Elements of Statistical Learning is a comprehensive mathematical treatment of machine learning from a statistical perspective. This means you get good derivations of popular methods such as support vector machines, random forests, and graphical models; but each is developed only after the appropriate (and wrongly considered less sexy) statistical framework has already been derived (linear models, kernel smoothing, ensembles, and so on).

In addition to having excellent and correct mathematical derivations of important algorithms The Elements of Statistical Learning is fairly unique in that it actually uses the math to accomplish big things. My favorite examples come from Chapter 3 ""Linear Methods for Regression."" The standard treatments of these methods depend heavily on respectful memorization of regurgitation of original iterative procedure definitions of the various regression methods. In such a standard formulation two regression methods are different if they have superficially different steps or if different citation/priority histories. The Elements of Statistical Learning instead derives the stopping conditions of each method and considers methods the same if they generate the same solution (regardless of how they claim they do it) and compares consequences and results of different methods. This hard use of isomorphism allows amazing results such as Figure 3.15 (which shows how Least Angle Regression differs from Lasso regression, not just in algorithm description or history: but by picking different models from the same data) and section 3.5.2 (which can separate Partial Least Squares' design CLAIM of fixing the x-dominance found in principle components analysis from how effective it actually is as fixing such problems).

The biggest issue is who is the book for? This is a mathy book emphasizing deep understanding over mere implementation. Unlike some lesser machine learning books the math is not there for appearances or mere intimidating typesetting: it is there to allow the authors to organize many methods into a smaller number of consistent themes. So I would say the book is for researchers and machine algorithm developers. If you have a specific issue that is making inference difficult you may find the solution in this book. This is good for researchers but probably off-putting for tinkers (as this book likely has methods superior to their current favorite new idea). The interested student will also benefit from this book, the derivations are done well so you learn a lot by working through them.

Finally- don't buy the kindle version, but the print book. This book is satisfying deep reading and you will want the advantages of the printed page (and Amazon's issues in conversion are certainly not the authors' fault).",46
Karen E. Pittman,2.0 out of 5 stars,"Mathematics for 3D Game Programming and Computer Graphics, Third Edition","Kindle Edition: Careless errors, diagrams too small.","This book is just what I have been looking for: something that presents and cogently explains the math that is most useful for implementing 2d and 3d computer graphics. If the Kindle edition did not have the problems it has, I would give it 5 stars. However, it gets a poor rating for two reasons. One, the diagrams are too small! Other Kindle documents allow the reader to scale images, but not this one. Two, and this is just INEXCUSABLE: The Kindle edition, but not the print edition, has errors that make the equations and proofs worthless. I can't quote examples exactly because special characters don't show up properly, but here's a description of three examples:

1. print p. 13, Theorem 2.2
Kindle uses improper notation in (c), and an ill-formed expression in (d).

2. print p. 14, fig 2.1: ""The triangle inequality states that [equation]""
Kindle reverses the inequality in the equation.

3. print p. 15,
""Definition 2.3. The dot product of two n-dimensional vectors P and Q, written as ...""
Kindle leaves out a crucial character in the ""written as"" formula.",46
Mario Schlosser,3.0 out of 5 stars,"Superintelligence: Paths, Dangers, Strategies","Sometimes friends over a beer philosophizing, sometimes clever analogies","I love the general idea of evaluating the potential perils of artificial super intelligence, and I buy into the concept of thinking this through at an abstract level, not tied to the current state of AI algorithms in today's computer science. That's what this book does - systematically explore every branch of a pretty large decision tree around everything that could or could not happen when an artificial intelligence starts developing super-intelligence, and how we should deal with it. So, conceptually cool. But practically, in the case of this book, not very interesting. For a couple of reasons.

First, the level of abstraction really is taken to an extreme. Forget about any relation between arguments in this book and anything we've actually been able to do in AI research today. You won't find a discussion of a single algorithm or even exploration of higher-level mathematical properties of existing algorithms in this book. As a result, this book could have been written 30 years ago, and its arguments wouldn't be any different. Fine, I guess (the author after all is a philosophy professor, not a computer scientist); but I found this lacking at times. It gets particularly boring when the author actually does spend pages over pages on introducing a framework on how our AI algorithms could improve (through speed improvement, or quality improvement, etc.) - but still doesn't tie it to anything concrete. If you want to take the abstraction high road, just dispense with super generalized frameworks like this altogether and get to the point. Similar to the discussion of where the recalcitrance of a future AI will come from, whether from software, content or hardware: purely abstract and speculative, even though there are real-world examples of hardware evolution speed outpacing software design speed and the other way around (e.g., the troubles of electronic design automation keeping up with Moore's Law).

Second, even if you operate fully in the realm of speculation, at least make that speculation tangible and interesting. A list of things an AI could be good at lists stuff like ""social persuasion"" (= convince governments to do something, and hack the internet). Struck me a lot of times as the kind of ideas you'd come up with if you thought about a particular scenario for a few minutes over a beer with friends. Very few counterintuitive ideas in there. One chapter grandly announces the presentation of an elaborate ""takeover scenario"", i.e., how would a superintelligence actually take over the world - and again it remains completely abstract and not original or practical. (""AI becomes smart, starts improving itself, takes over the world"" - couldn't have guessed it myself.)

Third, a lot of the inferences in the book struck me as nothing more than one-step inferences, making it a relatively shallow brainstorming-type book. (""This could happen, and also this other thing could happen, and this third thing as well."") Systematic exploration of a large decision tree gets interesting when you start combining lots of different scenarios in counter-intuitive ways. Again the ""friends over a beer"" problem. At times the philosophizing in some chapters reads like a mildly interesting Star Trek episode (such as the one about how to best set goals for an AI so that it acts morally and doesn't kill us). In the best and worst ways.

But every now and then, there's a clever historical analogy, and an interesting idea. Ronald Reagan wasn't willing to share the technology on how to efficiently milk cows, but he offered to share SDI with the USSR - how would AI be shared? Or, the insight that the difference between the dumbest and smartest human alive is tiny on a total intelligence scale (from IQ 75 to IQ 180) - and that this means that an AI would likely look to humans as if it very suddenly leapt from being really dumb to unbelievably smart and bridge this tiny human intelligence gap extremely quickly. But what struck me with regards to the best ideas in the book is that the book almost always quotes just one guy, Eliezer Yudkovsky... which made me think that if I wanted to read a thought-provoking, counter-intuitive book on AI super intelligence (as opposed to a treatise that appears to at times gloss over the shallowness of its ideas by making up with long text), I should just go and read Yudkovsky.

All in all though, the topic itself is so interesting that it's worth giving the book a try.",45
Joseph Johnson,5.0 out of 5 stars,An Introduction to Statistical Learning: with Applications in R (Springer Texts in Statistics),cover all of your bases,"If you want to build a comprehensive machine learning library, this would be the first book to purchase. While it does cover all of the basics, it is not watered down by any means. (I had the same fear as BK Reader) I found the following to be especially helpful;

1. Straight talk - These experts come right and say which methods work best under which circumstances. While there are many fancy algorithms covered in the book, they highlight the advantages of the simpler ones.
2. Emphasis on subjects that are not heavily addressed in most ML books - They thoroughly cover the challenges of high-dimensionality, data cleaning, and standardization. They do not limit their attention to these subjects to one chapter. They bring them up continually throughout the book.
3. Expertise - Dr. Hastie and Dr. Tibshirani are two of the thought leaders in statistical learning. You can be assured that you are learning from the best.
4. Many levels of depth - While the book does cover the basics, it is not watered down by any means. (I had the same worry as BK Reader) There is a great deal for any student of statistics; beginner or advanced.
5. R code - You are given enough code and examples to gain confidence in your ability to independently perform excellent analysis and modeling.
6. The concepts are just plain exciting! - You will feel an excitement as you discover and re-discover the algorithms they present.

The book is a standard work along with Elements of Statistical Learning and Pattern Recognition and Machine Learning (the Bayesian approach). If you enjoy the book, you may also want to consider Applied Predictive Modeling. It has the same style and approach.",45
John Smith,3.0 out of 5 stars,Programming in Prolog: Using the ISO Standard,Dissatisfied,"Pros:
- Even someone with no programming or math knowledge could pick up the book, read it, and learn Prolog
- Uses ISO-Prolog
- Large section of helpful example programs

Big Cons:
(I'll give citations, only from the first 100 pages to keep things short, lest anyone think I am lying about the problems with the book)
- Frequent syntax errors *in program statements* - in Prolog, every comma and period is absolutely essential, when they are missing it entirely changes the meaning of the statement - the book misses them pretty routinely (p 81, twice)
- Frequent logic errors - in Prolog, the order of facts and rules is extremely important. The book commonly mixes things up, presenting you with programs that will not work (p 56 - note here that they are trying to give an example of what will/won't work, and they get it backwards)
- Frequent editing/formatting errors - charts, diagrams etc are fairly often on the wrong page or in the wrong location, etc. (p 48)
- Poor organization - looking through the table of contents, you would think the book is extremely well organized, but as you read it, you'll find new and important ideas thrown into random sections - if you forget something, and need to find it later, you'll probably need to re-skim the entire book. Things are almost never presented in convenient bullets/numbering, almost always in paragraph form, again, making essential ideas tedious to find.
- Confusing - I have degrees in math and computer science, and have been programming for 15 years, and I still found parts of the book hard to follow - note that it had nothing to do with Prolog itself, which is actually very straightforward, but rather with the explanations given, which sometimes seem meandering and poorly worded.
- A really short and crummy index makes things hard to find. For example, look up ""atoms"", a concept first mentioned on page 26, and routinely mentioned afterwards, a concept absolutely essential to understanding Prolog - the index shows that the first (and only) time it appears is on page 123.

Average Cons:
- Authors use an ""arrow system"" to trace Prolog decision making, I think a table system (which could easily show previous, current, and future steps, and details of each iteration) would have been better while presenting more information in a clearer fashion.
- Code re-use - normally a good thing, frustrating in this book. You might have a rule (like a function) called ""mother(X)..."" early on in the book, not use it for 100 pages, and then it appears again. If you want to try the program out yourself, you'll need to know the exact definition of ""mother(X)..."". There's no way to find what page the function was on in the index or TOC, so you find yourself spending 30 minutes leafing through the book to find it. 99% of these are a single line of code, so there's really no need to reuse them, it's hardly saving any space.
- Overly complex examples - sometimes the authors illustrate an idea with 20 lines of code, when 4 would have been sufficient. It makes for a lot of extra reading and deciphering.

Small Cons:
- (This could be a pro or con - since I don't know too many people who *start* their programming experience with Prolog, I assume the reader has some experience with programming, and so list this as a con) Book is far too detailed for someone with moderate programming or math experience. This helps some people, but makes it a tedious read for others. Every concept is thoroughly explained. If you're a programmer, this gets a little old during things like variables and recursion. If you know any math, verbose explanations of predicate logic will become tiresome. In fairness, it was no doubt the authors' intention to make a ""complete"" introduction to Prolog, and so it is hard to criticize this.
- (Another pro/con, depending on the reader) British examples - the authors are British (or at least one of them is), and use British references in their code all the time (9th century princes of Wales, p 34; horses who won races in Britain in 1927, p 53) - if you're British this might break up the monotony and make things a little more interesting, if you're not, it just gets a little old, I'd rather see every example just use ""cat"",""dog"",""mouse"".

Other:
- NOT a good reference book (and it wasn't meant to be), if you know Prolog already and need a reference book, look elsewhere. This is for people who do not know Prolog.

Conclusion:
- I wish I bought a different book. BUT despite everything, I did adequately learn Prolog from this book, so will reluctantly give it 3 stars.",45
NELDA BOLIVAR,5.0 out of 5 stars,Amazon Echo: Master Your Amazon Echo; User Guide and Manual,"All what you need to set up and daily use your echo, and a bit more!","The best guide to take the most out from your echo device. My son bought a new echo and gift me the old one, but he is in a different state so I needed a bit of assistance, I decided to get this book and I'm very comfortable with it, I could know better what does my new echo have inside and how I can get the best of it. The set up was made very easy so I decided to make all the initial configurations needed to get the best. Knowing the echo's functions, what does every light and sound means, and linking the echo to its own app is great to improve the way you can interact with Alexa.

This book easily teached me the features I was not being able to found, like linking the echo with other home devices and setting up my music playlist. Also loved the tips and the fun tricks that were added to this book!. If you need your echo to do something, sure you'll find out how on this book.",44
R. Johnson,5.0 out of 5 stars,Artificial Intelligence: A Modern Approach (2nd Edition),Stunning textbook--best I've ever used,"Until recently, my Algorithms book was my favorite text book ever. However, AI: A Modern Approach has supplanted it. This book is the most thoughtfully designed, easily understandable, clear text I've ever used in over 28 years of attending schools. I really knew nothing about AI when I took my first grad class in AI, but this book, along with a pretty great instructor, has been a wonderful resource, more than any other book I've used. I have not need to google for more information or speak to the professor. The answers are here--clear and concrete.

Have no fear and trust this book!",44
N/A,5.0 out of 5 stars,Shadows of the Mind: A Search for the Missing Science of Consciousness,A work with far reaching implications,"Between the beautifully written prologue and epilogue, this book approaches a range of topics in modern physics in a unique and readable way. Through a continuation of some earlier work, Penrose furthers an argument for brain function and conciousness that many in the artificial intelligence field will not appreciate. He presents his case that the human mind will never be simulated with digital a computer, no matter how complex. But that is not his main focus of this book.
Even more facinating are his calculations which indicate how mathematically unique our existence is under the 2nd law of thermodynamics. To me, it's ultimately ironic that the physical principal which orders our universe and makes intelligent life possible (the 2nd law), is the result of an unimaginably improbable set of initial conditions. Although Penrose never invokes the concept of a creator or supreme being, in my mind, this poses an interesting challenge to those in the scientific community who claim our universe is simply the result of random particle collisions over a long period of time.
If we combine the concepts of similar structures scaling across space and time (tensegrity and fractals), with Penrose's ideas that consciousness may be associated with quantum gravity interactions in microtubules (present in all living cells), perhaps there is far more mystery and beauty to this existence than some would now believe...
This book was satisfying and throught provoking, and I highly recommend it to anyone interested in the mysteries of the very large and the very small.",44
Barry,5.0 out of 5 stars,Write Great Code: Volume 1: Understanding the Machine,Great information... But do you really need it?,"This is a great book but I have to disagree with the overall viewpoint. I've been doing embedded programming for a while and if that's all I'd ever done I would totally agree that understanding low level concepts helps write better code. However, I also write a lot of code in C#. People who normally use high level languages such as C#, VB.Net, or JAVA are probably not going to benefit much from this book. These languages are so far abstracted from the hardware level that the concepts are hard to apply anywhere. On the other hand, if you still use malloc on a daily basis, you need to read the book :) Anyway, the book is easy to read and I never caught any errors. If you want to learn about computers at a low level, then this is a great book to start with!",44
N/A,1.0 out of 5 stars,"G??del, Escher, Bach: An Eternal Golden Braid",Choose wisely before spending $$$,"Hello Folks,
I consider myself something of a seeker. I'm an avid reader of Lucid Dreaming, Zen Buddhism, Carl Jung, Herman Hesse, W. Somerset Maugham, Ghandi, Einstein and other amazing intellectuals......When I first heard about this book, I was positively thrilled. What an amazing idea I thought. Unfortunately, I was deeply disappointed. It is a laborious read, and I don't know that my understanding has broadened significantly by reading this book....in all fairness, I haven't finished the book yet, and maybe the last few pages will tie everything together nicely. But I'm a little annoyed that I bought this book. I won't tell you not to buy it. But I highly recommend browsing through it at a book store or library. It's a great title, and a terrific premise. However, it's extremely logical (for those of you who haven't taken logic/statistics or higher math, you're in for 800 pages of confusion). Perhaps if I was a programmer, this book would have done something different for me. I know that I'm in the minority here, but I offer this review based on my own experiences. Reader reviews is a great resource, but obviously it should not be the end-all be-all of your buying decision. It was for me, and I'm out $15 for a book that I don't really care for. Choose wisely my friends.",42
S. Gupta,5.0 out of 5 stars,Quantitative Technical Analysis: An integrated approach to trading system development and trading management,Finally a book that teaches application of machine learning to trading -- with real working examples!,"Everything I wished in a book to apply machine learning techniques for trading is here! I began reading the book in the evening and could not put it down. I ran through all of the Python machine learning algorithms and by 3am had a complete understanding of how to put the lessons into practice. A decent trading system in Python is provided with code. This is using logistic regression and some very simple RSI based predictor variables. Change the predictor variables a bit more to get significantly better results.

A bit about my background so you know what I'm writing about:

I'm an individual trader. I have about 10 years of trading experience and all of it was using trading system development platforms (not machine learning). After experimenting with many platforms such as Tradestation, Ninjatrader, Telechart, StockFinder I settled on Amibroker as my platform since 2011. I consider myself a competent user of Amibroker. I also have Dr Bandy's prior books and consider them outstanding.

I have a software development background and early in career (almost 20 years ago) was exposed to some machine learning concepts. My application of machine learning was however, not for trading or any financial services. My machine learning experience was using C and C++ as programming languages. Since 2012, I elected to learn Python and have come to use it and love it!

Given my machine learning exposure I have been on the lookout for books that bridge the gap between theory and their application to trading. Quantitative Technical Analysis does that extremely well. Just to be clear, this book is a great asset if you use Amibroker and have no intention of using machine learning methods, but I'll focus my review on the topics of my interest -- namely the application of machine learning using Python to trading.

Here is what I loved about the chapter progressions:

- The opening chapters discuss the key concepts with respect to key risk in trading -- the risk of drawdowns and provide a framework for managing this risk algorithmically. I have learnt tremendously from Dr Bandy's prior books and welcome this summary of the concepts along with more and detailed explanation of the concepts.

- Next, the design of a trading system are considered. Assume a system accuracy and maximum holding period, what is the profit potential and draw down?

- Armed with the knowledge from the earlier step, now the implementation of the actual trading system is tackled. This is where the books is unique. It provides the classic (what Dr Bandy call's the indicator based approach) way of developing systems using a platform like Amibroker and in *parallel*, introduces the use of Python as a platform for trading development. For me, this was a great way to bridge the concepts of system development using Amibroker to Python. Amibroker with its rich library of indicators and charts and access to data sources makes many things easy. Python, on the other hand, is a great language for complex analysis of data and monte carlo simulations. Comparing the two approaches side-by-side makes it easy to decide the approach you want to take. (I'll take a hybrid approach for now).

- Next, the use of machine learning to predict prices is introduced. For me, this was the part I have been waiting for a long time. Dr Bandy takes the classic Iris classification problem to illustrate the various machine learning algorithms (from the now widely available scikit Python ML library). He then follows up with a real trading system (using logistic regression as the algorithm). This is a fully functional system and if you follow the Iris examples, you can easily experiment with different learning algorithms. If you have prior exposure to machine learning concepts, you should be up and running with a working system in a few hours (like me). If you are new to machine learning, this is the best book I know of that takes the concepts of machine learning, combines them with freely available Python code and libraries and free data sources and puts you in a position to advance your learning about real trading systems.

- A Python implementation of the dynamic position sizing technique is introduced. The concept of dynamic position sizing, once explained, seems intuitive and obvious. What is challenging is the actual execution of the concept. This book provided a complete working example. Heck, the ""for education only"" examples here are a lot better than many production systems.It provides a daily management of the position size of the trade based on changing risk conditions. It is brilliant!

Very few books can boast of providing working examples and fewer can boast of working examples that work for the reader. Dr Bandy has set a high bar with his prior books so we've come to expect this. Still, getting all of the Python code to work withing hours of getting the book is an amazing testament to his attention to detail. If you are at all interested in applying machine learning to trading, getting this book is a nobrainer!.",42
Chris Anderson,5.0 out of 5 stars,"Out of Control: The New Biology of Machines, Social Systems, & the Economic World",Perhaps the most important book of the 90s,"Why are the three most powerful forces in our world--evolution, democracy and capitalism--so controversial? Hundreds (in the case of democracy, thousands) of years after they were first understood, we still can't quite believe these three phenomena work. Socialist Europe resists capitalism, the religious right in America questions evolution and the Middle East makes a mockery of democracy. When you think about it, it's easy to understand why: all three are radically counterintuitive. ""One person, one vote?"" What if they vote wrong?

But that's the problem--we're thinking about it. Our brains aren't wired to understand the wisdom of the crowd. Evolution, democracy and capitalism don't work at the anecdotal level of personal experience, the level at which our story-driven synapses are built to engage. Instead, they're statistical, operating in the realm of collective probability. They're not right--they're ""righter"". They're not predictable and controllable--they're inherently out of control. That's scary and unsettling, but also hugely important to understand in a world of increasing complexity and diminishing institutional power (mainstream media: meet blogs; military: meet insurgency).

Fortunately, this book that makes sense of all of this. Out of Control was first published in 1994, well before its time, but it's one of those rare books that sells better each year it gets older. That's because Kelly recognized that the messy markets of natural selection, enlightened self-interest and invisible hands all anticipated the Internet and the delights of watching peer-to-peer cacophony create the greatest oracle the world has ever seen. Some of the examples may be a bit dated a dozen years later, but the message has only become more true: ""There is no central keeper of knowledge in a network, only curators of particular views,"" he writes. The emergent mob wisdom of the blogosphere and Wikipedia were unimaginable then, but somehow Kelly imagined them all the same. This may be the smartest book of the past decade.",42
Stephen C. Clark,5.0 out of 5 stars,The Singularity Is Near: When Humans Transcend Biology,"Agree or disagree, it's well worth a read","I'm going to rate this book five stars, because at nearly 500 pages packed with important ideas (plus another hundred pages of notes) there is no question that this weighty book was well worth my $20.

As you might expect, Ray is at the top of his game when examining trends in computer science. He has many examples of ""narrow"" A.I. to share. More importantly, he believes that computer modeling of brain functioning will yield the algorithms we need in order to eventually achieve an artificial general intelligence. Indeed, cognitive science is exploding thanks to increases in computing and scanning power, and the brain will likely yield up many of its secrets in coming years. I find his predictions in this area quite believable.

I found some of his arguments regarding nanotechnology to be less convincing. In particular, his predictions for nanorobotics seem optimistic beyond all reason given the currently nascent state of this technology. Examples drawn from the current state of the art seem almost hopelessly far removed from the robust and exceedingly powerful technology he imagines within 25 years. On the other hand, if these surprising predictions are borne out it will be a powerful confirmation of his ""law of accelerating returns"". I guess I'll be reserving judgement until then.

There's alot more I could say (good and bad) about this important book, but the bottom line is that if you frequently find yourself wondering about the role of technology in the future of our species, ""The Singularity is Near"" will give you far more than your money's worth in food for thought.",41
David Fa Richards,1.0 out of 5 stars,Our Final Invention: Artificial Intelligence and the End of the Human Era,"Intelligence, artificial or otherwise, would have been welcome.","I want to comment on two things. Firstly, Barrat warns us not to anthropomorphise about mechanical intelligence but in his book he does little else. Machines are reluctant to be turned off because they love life; they want to finish their given programs at all costs like college students; they have hidden drives of their own, like many a billionaire; they will be amoral regarding the acquisition of our mollecules which they will take without asking and in a brutal fashion, neglecting our screams (he actually says this), and none of this with any shred of evidence. Only interviews with programmers (I have yet to verify who they are) along with descriptions of their appartments, neighbourhoods, physical appearance and other crappy twaddle that have nothing to do with his tenuous argument. Perhaps he was paid by the word. The second thing is that there is insufficient information about the military/governments, the most likely patrons for this research, with their dubious motives but access to the capital required for the cosmological budgets that all this will cost. Who should we fear most, the military or the machines per se? Who has access to the capital required other than governments? Under these circumstances, I would favour the machines. The human species has done conspicuously badly up to this point : perhaps AI can do better. I didn't like this book. I thought it was alarmist fluff and a waste of money and time.",41
cultofmetatron,5.0 out of 5 stars,The Annotated Turing: A Guided Tour Through Alan Turing's Historic Paper on Computability and the Turing Machine,should be on every aspiring mathematician's bookshelf,"this is a fantastic book. It manages to explain simply and clearly the entirety of turing's landmark paper and providing a thorough grounding on the base mathematical knowledge. though I had taken some set theory in college, I am fairly confident that even a devoted highschooler with some experience in geometry proofs could understand and follow this book. Of course, I should also mention that this book is written extremely well such that at no point did I feel bored. when was the last time you found a math book completely riveting?",41
Patrick Rouse,5.0 out of 5 stars,"Mathematics for 3D Game Programming and Computer Graphics, Third Edition",The definitive guide for 3D math,"As a word of warning, do not purchase this book expecting it to teach you math fundamentals. If you do not have a background of at least algebra and trigonometry (and preferably a bit of calculus), you owe it to yourself to pick up another book and brush up on these fundamentals. While there are a few appendices covering a handful of topics, they are less about explaining the topic and more of reference pages.

Mathematics for 3D Game Programming and Computer Graphics is an excellent reference book for anyone doing 3D work. The topics are very to the point and few pages are wasted explaining basic math principles (hence the warning about having a decent math background). The book probably won't teach anyone who doesn't know they underlying principles but will be your go-to reference for any algorithm you implement.

The book starts with the reviews of the requisite vector, matrix, transformation (including rotations by quaternions) and basic geometry for a view frustum, but quickly dives into more advanced topics. Ray tracing is covered for all areas of use, from light maps to reflections. The lighting chapter covers texturing using several map types as well as lighting models with a very enjoyable discussion of specular reflection models.

Solid chapters on culling using bounding volumes and portal systems, shadowing and curve algorithms round out the first half of the book. The second half is devoted to the mathematics of physics, with chapters on basic collision detection, linear and rotational physics. The simulation of fluids and cloth (one of the more difficult physical models to accurately compute in a game) gets it's own chapter and it's a highlight for anyone implementing character clothing animation or a realistic water volume.

Every chapter has exercises (with and appendix of answers) to reinforce the material. The C++ and GLSL shader code is available on the books companion website ([...]) much of which forms the basis for the math classes of the authors own engine.

Anyone who needs a math reference book for 3D would do well to own this book. If you are writing your own engine, you owe it to yourself to pick up what will be the only math book you will need. While many technical books do not age well, this hardcover book will last through many late-night coding sessions both physically and with regard to the material within at a low price point. Never again will you have to scour through your old textbooks or search online for the algorithm you are trying to implement. The author has done the impossible; make a truly terrific math textbook.",41
T. Dean,2.0 out of 5 stars,Data Smart: Using Data Science to Transform Information into Insight,Great if you're in Marketing or Sales,"This is a well thought out and designed tutorial for the beginner or for a power user that doesn't have large data sets to work with. If you need to produce reports for sales or you own a small business and want your basic BI, this book is great. However, once you start working with large enterprise level data sets with millions of rows and hundreds of columns of information, Excel becomes useless.
The samples the author provides are very tiny sample sets compared to what most people need to use, and the 'Solver' add-in only works on these very small sample sets. If you have over 4 or 5 variables, you will receive an error, which makes the solutions the author provides basically useless for larger data sets - any BI you extract will not be from this method of doing things.",40
Amazon Customer,5.0 out of 5 stars,Machine Learning with R - Second Edition,"Less tech speak, more meaty","First off, I am newbie to both machine learning and R and wanted find a starting point somewhere. I browsed around many books before deciding on this one. The writing style of Mr. Lantz is provided in a very understandable/readable manner. It's akin to someone sitting next to you and explaining things in a down to earth, layman's fashion rather than try to ""tech speak"" you to death with complicated explanations (aka formal textbook). Just the right amount of hand holding for me. I highlight quite bit and it's actually difficult with this book as there isn't much fluff. He's very succinct. The books states that it's for someone who know some ML and no R or R and no ML. I don't know either and the material is digestible except for one thing: review your stats! I took statistics long ago in college and never really learned it well the first time so I had stop and reread core concepts before continuing. Do yourself a favor and review basic statistics and probability before you start this book. I read both ""Naked Statistics"" and ""Statistics in Plain English"" and it helped me a great deal (and probably will continue to do so since it appears a bulk of machine learning is stats and prob). Currently into about a third of the way in and I am finding it to be very enjoyable and practical. Other reviewers point out that this book is too basic and this may be the case, but for someone like me who is starting from absolute scratch and who needs to understand basic ML concepts (AND basic R) I find it a great book. Will post an addendum once I complete it.",40
William C. Burkett,4.0 out of 5 stars,The Sciences of the Artificial - 3rd Edition,Comprehensive philosophical view on thinking and computing,"Although the language is a little stilted at times and difficult to read, the range and scope - and implications - of Simon's ideas are profound. The relationships he describes between thinking, computing, and human behavior are extremely interesting and provide a ""look toward the future"". And the fact that Simon has been working and researching in this area for, like, FOREVER (some of the citations of his work is from the 50's) lends a lot of credence to his ideas.",40
Amazon Customer,5.0 out of 5 stars,Machine Learning with R,"Less tech speak, more meaty","First off, I am newbie to both machine learning and R and wanted find a starting point somewhere. I browsed around many books before deciding on this one. The writing style of Mr. Lantz is provided in a very understandable/readable manner. It's akin to someone sitting next to you and explaining things in a down to earth, layman's fashion rather than try to ""tech speak"" you to death with complicated explanations (aka formal textbook). Just the right amount of hand holding for me. I highlight quite bit and it's actually difficult with this book as there isn't much fluff. He's very succinct. The books states that it's for someone who know some ML and no R or R and no ML. I don't know either and the material is digestible except for one thing: review your stats! I took statistics long ago in college and never really learned it well the first time so I had stop and reread core concepts before continuing. Do yourself a favor and review basic statistics and probability before you start this book. I read both ""Naked Statistics"" and ""Statistics in Plain English"" and it helped me a great deal (and probably will continue to do so since it appears a bulk of machine learning is stats and prob). Currently into about a third of the way in and I am finding it to be very enjoyable and practical. Other reviewers point out that this book is too basic and this may be the case, but for someone like me who is starting from absolute scratch and who needs to understand basic ML concepts (AND basic R) I find it a great book. Will post an addendum once I complete it.",40
Carl Podlesny,2.0 out of 5 stars,Neural Networks and Learning Machines (3rd Edition),Disgruntled,"It appears that the author and/or publisher have decided that the purchaser of this book does not REQUIRE a MATLAB (or other language) support CD to be able to effectively use it.

A MATLAB CD is available, but only to professors who adopt the book for teaching. This approach will dramatically reduce the popularity of this book. First off, the reader/purchaser would have to already have extensive expertise in the subject matter (I really like the Kalman Filter coverage). Next, in order to put any of this mathematically-intense exposition into practice, the reader must be quite fluent in some scientific programming language.

Without an accompanying MATLAB CD, this great book remains no more than an expensive paperweight.

I did send an email to Dr. Hakin at McMaster expressing my disappointment asking how I might be able to access the MATLAB code for the book, but I never received a reply (haykin@mcmaster.ca)

The book has been returned for credit.",39
Heavy Reader,2.0 out of 5 stars,Programming Collective Intelligence: Building Smart Web 2.0 Applications,Nice introduction to exciting topics but lacks depth,"I think this is a good, easy-to-read intro to several interesting data-centric software technologies, but it is superficial.

For example, their collaborative filtering (ratings + recommendations) section illustrates only the most simplest of algorithms and completely skips over more advanced techniques (improved normalization, matrix factorization, and others), it skips over even basic benchmarking of the rec system (IMO, if you aren't doing objective benchmarks and tuning it off of those metrics, your rec system is useless), and doesn't address any of the common pitfalls and problems (sparsity, overfitting, normalization problems, scalability issues).

I guess that is expected. If you want a book that's easy to read that can get you excited about some cool ares in software development, this book is great. If you want information beyond the introductory casual reading level, look elsewhere.",38
Boris S,5.0 out of 5 stars,Code: The Hidden Language of Computer Hardware and Software,"Great, but it's not ALL for a ""Novice""","The book starts out very solid, describing all the building blocks of a computer. The beginning is the best book I've seen so far describings everything from the binary system to electrical circuits, to gates to simple calculators, to memory, to a complete machine with a ""control panel"". But after that, the book started getting a LOT more broad (not necessarily a bad thing). It seems almost as if Petzold wanted to tell you everything about the world of computers, but couldn't fit it in a book such as this; so he dabbed a little here and there of a few terms, history, etc... (allowing you the option to look up anything you wanted if you had the interest).
My oppinion is that the book is _great_ up to about the middle of the book, after which he just condenced all the rest of the information which would otherwise takes thousands of pages to describe in as much details as he described how to build a physical logic machine... I think that if someone isn't a ""techie"" or isn't in the computer field, they may have some hard time understanding a few minor points... but overall, this is a GREAT book.. one of a kind.
Greatly recommended for everyone's library... I can honestly say, I always told people ""a computer is nothing more than zero's and one's""... but until I read this book, I couldn't BUILD one... now I can (given time! :).
P.S. This book is perfect for those who didn't necessarily go to college and learned everything on their own... it covers some CS, CE, and EE. Those who went to college with either of those majors probably learned the greatest part of this book... but it's a great review.",37
M.R.,4.0 out of 5 stars,Artificial Intelligence: A Modern Approach (3rd Edition),Close enough to the U.S. Edition for most purposes,"Since this version of the book is for the Indian market, I was a bit worried about the potential differences from the U.S. 3rd edition. But after doing a first-hand comparison, I found a LOT more similarities than differences.

The biggest difference is the absence of the last two chapters. The U.S. edition includes: Chapter 26, ""Philosophical Foundations"", which covers arguments over consciousness in machines and the possibility of robot uprisings; and Chapter 27, ""AI: The Present and Future"", which *briefly* describes some things AI researchers need to work on before we can build a ""general-purpose intelligent agent"" (a.k.a. one single AI that will be good enough at a lot of different tasks). These two chapters are interesting, but I wouldn't call them core material, so I'm not surprised they got left out.

Other than that, the differences are astonishingly minor. The chapters are unnumbered, and some of them swapped places for no reason, but all the content from chapters 1 through 25 is here, plus the two appendixes. The ONLY edits to the text are removals of cross-chapter references. The U.S. version will say something like, ""When we discussed whatzits in Chapter 4, we mentioned that they come in two flavors, X and Y"", while the same line in this book will say, ""Whatzits come in two flavors, X and Y"". Again, those are the ONLY edits. All the other sentences are the same. The equations are the same. The diagrams are the same. The exercises at the end of each chapter are the same.

In short, if you can do without those last two chapters, buy this version and save your money.",36
Samantha Atkins,2.0 out of 5 stars,Probabilistic Graphical Models: Principles and Techniques (Adaptive Computation and Machine Learning series),bad kindle format,It seems to want to be viewed in some PDF ish format on the Kindle Reader on my iPad. This means I can't set the font to something readable. I can pinch zoom each page but this makes for a not happy reading experience. Amazon should warn people when a book is in a different format or views differently. If they did so then I certainly missed it.,36
Sandro Saitta,4.0 out of 5 stars,An Introduction to Support Vector Machines and Other Kernel-based Learning Methods,More for mathematicians than computer scientist,"This book introduces the concepts of kernel-based methods and focuses specifically on Support Vector Machines (SVM). It is hard to read and a good background in mathematic is clearly needed. The book has a strong emphasis on SVM starting from the very first line of text. Concepts are well explained, although equations are not clear. The notation doesn't facilitate the reading at all. The book covers linear as well as kernel learning. The kernel trick is well described. It is easy to understand ideas behind SVM while reading the corresponding chapter. Finally a small chapter on SVM applications is proposed. Unfortunately, it only contains typical SVM applications (i.e. standard problems).

I think this book is good if you:

* Have a strong mathematical background

* Work in the specific domain of SVM (or kernel-based methods in general)

* Want to write a research paper about SVM and need the correct notations

However, this book is NOT intended for people who:

* Don't like to read theorems, corollaries and remarks

* Are not interested in reading hundreds of proofs

This is my personal opinion as a computer scientist: this book is definitely written for mathematicians.",36
Keto,5.0 out of 5 stars,An Engineers Guide to MATLAB (3rd Edition),Great title for mechanical and other engineering fields,"Many 'engineering' matlab books don't live up their titles. They are simply written as general introductions to matlab with a few useless thoughts about engineering thrown in.
In my opinion, a good matlab engineering book focuses less on general tips that you could get anywhere, and more on practical problem solving techniques and methodologies that provide insight into a paticular engineering problem and its solution.
This books succeeds in that respect. Though it gives space to the more general issues of using matlab, it gives ample room to specific engineering problems. I found its information and examples very useful. The topics are focused on mechanical engineering fields, such as vibration and control; however, the math used for such topics are used across engineering and science disciplines. Thus, any scientist or engineer will find this book useful.
The book is written so that engineers at many levels can benefit from it. For example, as a former graduate student, I found the treatments of vibration response analysis insightful. However, an undergraduate or otherwise inexperienced user would benefit from this book as well, because there is alot of general discussion of how to effectively and efficiently use matlab and write m-files.
All in all, I found this book excellent for both its treatment of high level engineering analysis issues and its more general matlab tips and discussion.",36
Machine Learner,4.0 out of 5 stars,Introduction to Machine Learning (Adaptive Computation and Machine Learning series),Superb Organization of Ideas!,"The topics and concepts in this book are exceptionally well organized. After reading it from cover to cover, I could easily see how all the ideas and concepts fit into place. I have two main criticisms. First, the notation is sometimes non-standard, e.g. the r vector is used to denote the label vector and superscripts are used sometimes as subscripts. Second, the explanations are sometimes too brief. For example, when deriving the solution for Least Squares Regression with Quadratic Discriminants, Vandermode matrices are used but the author fails to identify them as such, or to explain why they are useful. If the author were to write an extra sentence on every other page, the explanations would be perfect!",36
Igor Kleiner,5.0 out of 5 stars,"Fundamentals of Machine Learning for Predictive Data Analytics: Algorithms, Worked Examples, and Case Studies (MIT Press)",best book for practioner and not good book for programming or math background,"I am ML specialist and instructor.

There are many different types of books in Machine Learning. That cover various aspects of the field.
Some books are base on theoretic side: Learning from the Data.
Some books provide a gentle way for programming for Machine Learning in different languages
Some books combine theory and programming

This book ""Fundamentals of Machine Learning"" a good written book for practitioner in machine learning. For people that want to know how machine learning experts work. That processes they use, and how them organize there work.

In additional basic properties and ideas of general algorithms discussed.

This book uses excellent plant English, many examples and real cases

But if you need mathematical background or programming background I think you need use another book.",35
beavis,1.0 out of 5 stars,Amazon Echo: Master Your Amazon Echo; User Guide and Manual,very little useful information about features,very little useful information about features. mostly telling you how great it is and how to use the remote it ships with. I did not get a remote with mine. did you? waste of money.,35
Teknisk L??sare,5.0 out of 5 stars,The Most Human Human: What Artificial Intelligence Teaches Us About Being Alive,The Art and Science of Conversation,"This book is wonderfully readable, timely, informative and intriguing. The author makes potentially difficult subjects such as artificial intelligence and super-computer technologies accessible and entertaining. We learn how even the most sophisticated and complex machines humans can create, struggle mightily to do a simple, basic human activity - engage in conversations.",35
Dr. Lee D. Carlson,4.0 out of 5 stars,"The Emotion Machine: Commonsense Thinking, Artificial Intelligence, and the Future of the Human Mind",An effective critic-selector of AI research,"Progress in the design and creation of intelligent machines has been steady for the last four decades and at times has exhibited sharp peaks in both advances and applications. This progress has gone relatively unnoticed, or has been trivialized by the very individuals who have been responsible for it. The field of artificial intelligence has been peculiar in that regard: every advance is hailed as major at the time of its inception, but after a very short time it is delegated to the archives as being ""trivial"" or ""not truly intelligent."" It is unknown why this pattern always occurs, but it might be due to the willingness of researchers to engage in philosophical debate on the nature of mind and the possibility, or impossibility, of thinking machines. By indulging in such debates, researchers waste precious time that is better used dealing with the actual building of these machines or the development of algorithms or reasoning patterns by which these machines can solve problems of both theoretical and practical interest. Also, philosophical musings on artificial intelligence, due to the huge conceptual spaces in which they wander aimlessly, are usually of no help in pointing to the right direction for researchers to follow. What researchers need is a ""director"" or ""set of directors"" that are familiar with the subject matter, have both applied and theoretical experience in the field of artificial intelligence, and that eschew philosophical armchair speculation in favor of realistic dialog about the nature and functioning of intelligent machines.

The author of this book has been one of these ""directors"" throughout his professional career, and even though some of his writings have a speculative air about them, many others have been very useful as guidance to those working in the trenches of artificial intelligence. One can point to the author's writings as both inspiration and as a source of perspiration, the latter arising because of the difficulty in bringing some of his ideas to fruition. It would be incorrect to state that the author's ideas have played a predominant role in the field of artificial intelligence, but his influence has been real, if sometimes even in the negative, such as his commentary on the role of perceptrons.

There are intelligent machines today, and they have wide application in business and finance, but their intelligence is restricted (but highly effective) to certain domains of applicability. There are machines for example that can play superb chess and backgammon, being competitive with the best human players in this regard, but these machines, and the reasoning patterns they use in chess and backgammon cannot without major modification indulge themselves in performing financial prediction or proving difficult theorems in mathematics. The building of intelligent machines that can think in multiple domains is at present one of the most difficult outstanding problems in artificial intelligence. Some progress is being made, but it has been stymied again by overindulgence in philosophical speculation and rancorous debates on the nature of mind and whether or not machines can have true emotions.

Humans can of course think in multiple domains. Indeed, a good human chess player can also be a good mathematician or a good chef. The ability to think in multiple domains has been christened as ""commonsense"" by many psychologists and professional educators, and those skeptical of the possibility of machine intelligence. It is thought by many that in order for a machine to be considered as truly intelligent, or even indeed to possess any intelligence at all, it must possess ""commonsense"", in spite of the vague manner in which this concept is frequently presented in both the popular and scientific literature.

The nature of ""commonsense"" is explored in an atypical manner in this book, and in this regard the author again shows his ability to think outside of the box and phrase issues in a new light. This is not to say that advice on how to implement these ideas in real machines is included in the book, as it is not. But the ideas do seem plausible as well as practical, particularly the concept of a ""panalogy"", which is the author's contraction of the two words ""parallel analogy"". A panalogy allows a machine (human or otherwise) to give multiple meanings to an object, event, or situation, and thus be able to discern whether a particular interpretation of an event is inappropriate. A machine good in the game of chess could possibly then give multiple interpretations to its moves, some of which may happen to be similar to the interpretations given to a musical composition for example. The machine could thus use its expertise in chess to write musical compositions, and therefore be able to think in multiple domains. On the other hand, the machine may realize that there are no such analogies between chess and musical composition, and thus refrain from attempting to gain expertise in the latter. Another role for pananalogies, which may be a fruitful one, is that they can be used to measure to what degree interpretations are ""entangled"" with each other. Intepretations, which are the results of thinking, algorithmic processing, or reasoning patterns as it were, could be entangled in the sense that they always refer to objects, events, or situations in multiple domains. A panalogy, being a collection of interpretations in one domain, could be entangled with another in a different domain. The machine could thus switch between these with great ease, and thus be effective in both domains. It remains of course to construct explicit examples of panalogies that can be implemented in a real machine. The author does not direct the reader on how to do this, unfortunately.

The author also discusses a few other topics that have been hotly debated in artificial intelligence, throughout its five-decade long history, namely the possibility of a conscious machine or one that displays (and feels!) genuine emotions. The nature of consciousness, even in the human case, is poorly understood, so any discussion of its implementation in machines must wait further clarification and elucidation. Contemporary research in neuroscience is giving assistance in this regard. The author though takes another view of consciousness, which departs from the ""folk psychology"" that this concept is typically embedded in. His view of consciousness is more process-oriented, in that consciousness is the result of more than twenty processes going on in the human brain. An entire chapter is spent elaborating on this view, which is highly interesting to read but of course needs to be connected with what is known in cognitive neuroscience.

It remains to be seen whether the ideas in this book can be implemented in real machines. If the author's views on emotions, commonsense, and consciousness are correct, as detailed throughout the book, it seems more plausible that machines will arise in the next few years that have these characteristics. If not, then perhaps machine intelligence should be viewed as something that is completely different from the human case. The fact that hundreds of tasks are now being done by machines that used to be thought of as the sole province of humans says a lot about the degree to which machine intelligence has progressed. Whenever the first machines are constructed to operate and reason in many in different domains, it seems likely that they will have their own ideas about how to direct further progress. Their understanding of ideas and issues may perhaps be very different than what humans is, and they may in fact serve as directors for further human advancement in different fields and contexts, much like the author has done throughout a major portion of his life.",35
John Dalesandro,3.0 out of 5 stars,An Introduction to Genetic Algorithms (Complex Adaptive Systems),Not for beginners,"I have an engineering degree, and I found this to be a little tough to follow for two reasons:
1. Not enough step by step prodecure especially at the beginning. Mitchell is too quick to start with the math formulas. It turns out that Genetic Algorithms are fairly straight forward and easy to follow, but you have to read this book twice before you ""get it"" because Mitchell clouds the discussion with proofs and mathematical representations of systems. It is tough to follow.
2. Mitchell does a poor job of selecting meaningful examples to illustrate the points. A nice simple set of examples where the average person easily picture the system would have been delightful. Instead this author chooses to illustrate the Genetic Algorithms through uncommon neural networks amoung other exotic applications. I found myself struggling to understand both the example (I didn't know a thing about neural networks!) and the genetic algorithm.
When buying an Introduction type book, I expected it to be more 'down to earth'. this book is for advanced minds!",35
Glenn Gallagher,2.0 out of 5 stars,Alan Turing: The Enigma,Excruciatingly Detailed,"This biography on Alan Turing would have been so much better if the author had just thrown out about half the excruciatingly detailed descriptions of every single thing that happened in young Turing's life.

The first 100 pages and he's not even out of college yet. Boring and a little bit pointless. I'd like to recommend the book, but I'm only about half-way through and find myself skipping entire pages - I mean, who really wants to read all those letters he wrote to home when he was at boarding school? It's a little like reading the shopping list of a famous person - no matter how interesting that person may have been, it's just not that interesting to read about the mundane details of his or her life.

For a really great biography on another enigmatic scientist, try ""Tesla - Man Out of Time"" by Margaret Cheney. Now, that's the way to write a biography.",35
Dr. Lee D. Carlson,5.0 out of 5 stars,Algebraic Geometry and Statistical Learning Theory (Cambridge Monographs on Applied and Computational Mathematics),Excellent,"Statistical learning theory is now a well-established subject, and has found practical use in artificial intelligence as well as a framework for studying computational learning theory. There are many fine books on the subject, but this one studies it from the standpoint of algebraic geometry, a field which decades ago was deemed too esoteric for use in the real world but is now embedded in myriads of applications. More specifically, the author uses the resolution of singularities theorem from real algebraic geometry to study statistical learning theory when the parameter space is highly singular. The clarity of the book is outstanding and it should be of great interest to anyone who wants to study not only statistical learning theory but is also interested in yet another application of algebraic geometry. Readers will need preparation in real and functional analysis, and some good background in algebraic geometry, but not necessarily at the level of modern approaches to the subject. In fact, the author does not use algebraic geometry over algebraically closed fields (only over the field of real numbers), and so readers do not need to approach this book with the heavy machinery that is characteristic of most contemporary texts and monographs on algebraic geometry. The author devotes some space in the book for a review of the needed algebraic geometry.

Also reviewed in the initial sections of the book are the concepts from statistical learning theory, including the very important method of comparing two probability density functions: the Kullback-Leibler distance (called relative entropy in the physics literature). The reader will have to have a good understanding of functional analysis to follow the discussion, being able to appreciate for example the difference between convergence in different norms on function space. From a theoretical standpoint, learning can be different in different norms, a fact that becomes readily apparent throughout the book (from a practical standpoint however, it is difficult to distinguish between norms, due to the finiteness of all data sets). Of particular importance in early discussion is the need for ""singular"" statistical learning theory, which as the author shows, boils down to finding a mathematical formalism that can cope with learning problems where the Fisher information matrix is not positive definite (in this case there is no guarantee that unbiased estimators will be available). This is where (real) algebraic geometry comes in, for it allows the removal of the singularities in parameter space by recursively using ""blow-up"" (birational) maps. The author lists several examples of singular theories, such as hidden Markov models, Boltzmann machines, and Bayesian networks. The author also shows to generalize some of the standard constructions in ""ordinary"" or ""regular"" statistical learning to the case of singular theories, such as the Akaike information criterion and Bayes information criterion. Some of the definitions he makes are somewhat different than what some readers are used to, such as the notion of stochastic complexity. In this book it is defined merely as the negative logarithm of the `evidence', whereas in information theory it is a measure of the code length of a sequence of data relative to a family of models. The methods for calculating the stochastic complexity in both cases are similar of course.

In singular theories, one must deal with such things as the divergence of the maximum likelihood estimator and the failure of asymptotic normality. The author shows how to deal with these situations after the singularities are resolved, and he gives a convincing argument as to why his strategies are generic enough to cover situations where the set of singular parameters, i.e. the set where the Fisher information matrix is degenerate, has measure zero. In this case, he correctly points out that one still needs to know if the true parameter is contained in the singular set, and this entails dealing with ""non-generic"" situations using hypothesis testing, etc.

Examples of singular learning machines are given towards the end of the book, one of these being a hidden Markov model, while another deals with a multilayer perceptron. The latter example is very important since the slowness in learning in multilayer perceptrons is widely encountered in practice (largely dependent on the training samples). The author shows how this is related to the singularities in the parameter space from which the learning is sampled, even when the true distribution is outside of the parametric model, where the collection of parameters is finite. This example leads credence to the motto that ""singularities affect learning"" and the author goes on further to show to what extent this is a ""universal"" phenomenon. By this he means that having only a ""small"" number of training samples will bring out the complexity of the singular parameter space; increasing the number of training samples brings out the simplicity of the singular parameter space. He concludes from this that the singularities make the learning curve smaller than any nonsingular learning machine. Most interestingly, he speculates that ""brain-like systems utilize the effect of singularities in the real world.""",35
Jack Sparrow,3.0 out of 5 stars,"Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics and Speech Recognition","Good oveview, slightly overrated: broad and shallow","GENERAL IDEA: Broad coverage, it lacks depth and details - particularly practical details. That is, the presentation is often sketchy, mainly because it approaches too many subjects for its available space. I would not say that this book is strong on theory either. It is quite obvious that it avoids getting too formal and precise, probably to remain attractive for non-specialists too.

CASE STUDY: One specific problem I had with the Hidden Markov Models, that are supperficially presented (or spread I could say) in several separate sections of the book, so it's not been a pleasure trying to actually understand them properly and completely as a fundamental concept, to make them work in my particular application.

TITLE: The book's title IS misleading because it starts with ""Speeech"" and this book's main subject is not speech but (written) language. Actually there are only a few chapters on speech.

CONCLUSION: Get this book if you are looking for a good overview of the field. The book will introduce you to a thousand of topics. As soon as you need in-depth coverage of some particular topic, you will look for additional resources.",35
Matthew Reat,2.0 out of 5 stars,"Superintelligence: Paths, Dangers, Strategies",Difficult to read and follow...,"When hearing about the premise of this book, I was excited and snapped it up. Unfortunately It hasn't meet my expectations. It is clear that Mr. Bostrom is a brilliant man with some very interesting perspective and ideas; however I found myself lost in his prose. It is often rambling, containing long run-on sentences that appear to be more a stream of consciousness than an actual defensible position. I place some of the fault on myself for not being a philosophy student, but the book states early on that it is accessible for a lay person. I found this difficult to reconcile. The points the book addresses are important. A superintelligence can definitely pose an existential risk to our society, but the convincing arguments made in this book leave one more confused and frustrated than enlighted. At least that's one poor critics view, but one I have found myself concluding.",34
Dr. Lee D. Carlson,1.0 out of 5 stars,How to Create a Mind: The Secret of Human Thought Revealed,Fails to deliver,"The areas of cognitive neuroscience and artificial intelligence have grown by leaps and bounds in the last two decades, and both of these areas have found real-world application. These applications are the consequence of the concentrated efforts of hundreds of researchers, technicians, and venture capitalists, who typically had to spend a lot of time in the trenches doing the grudge work that is the rule rather than the exception for difficult areas such as these. There were false leads and conceptual barriers that had to be overcome, and success was and is measured by working applications, and not by the ability to counter arguments against those who claimed that advances in machine intelligence were either impossible or very limited. There is much remaining to be done, but whatever goals are set and attained should not be dictated by marketing hype or philosophical objections to the idea of artificial intelligence.

The author of this book has been one of the early innovators in domain-specific artificial intelligence, meaning that the applications and devices he helped to created are limited to very narrow domains of expertise and knowledge. In that respect he is not so much different than most of the talented individuals who have contributed to the field of machine intelligence. The major difference between the author and others lies in his vision of the future of this field. Progress in this field will be hyper-exponential he has argued in prior books, and this progress will include the creation of an artificial brain that can not only perform the functions of the human brain, but do them much, much faster. This book gives an overview of how to build such a brain, with pattern recognition being the predominant tool by which this brain will deal with knowledge and build its expertise. Such a tool is the primary method by which humans deal with the world, the author argues, and he gives some evidence drawn from the field of neuroscience to support his claim.

Although the author's discussions are interesting and thought provoking, as a whole the book does not deliver, and one of the main reasons for this is the lack of a quantitative measure of intelligence that will gauge progress in the development of an artificial brain. The word ""intelligence"" appears in at least sixty-five places in this book in the context of both human and machine intelligence, but absolutely no quantitative measure of it is described or articulated upon. If progress in machine intelligence is ""hyper-exponential"" as the author claims, than he needs to inform the reader to what extent a machine is for example 2 times, or 4.6 times more intelligent than another machine. Such a measure would not only support his case on the rate of advance in machine intelligence but would also be extremely valuable to AI researchers as a whole. The field of AI is begging for a workable/practical definition and measure of intelligence.

Readers will have to accept the qualitative assessments the author makes in the book regarding the advances in AI. He seems to be very impressed with the IBM Watson machine and its ability to understand both spoken and written language in any domain of knowledge, but the author does not give any examples where Watson has taken the initiative to seek out or create new knowledge on its own. The reviewer is not aware of a Watson-like machine that can devise new theories independent of domain or area of knowledge. Humans of course are able to do this with gusto, and more than ever it is this ability, and not token assimilation of existing knowledge, that characterizes human intelligence.

There are also many other problems with this book, even anecdotal ones like the authors mistaken notion of the motion of the Crookes radiometer, and the lengthy diatribes on consciousness and free-will. The book ends with even more refutation of arguments raised by philosophers and academics against the notion of machine intelligence. The author is successful in the refutations of these arguments, but the building of an artificial brain depends on constructive work, not the winning of philosophical debates. If the author could refrain from indulging in these debates and get on with the difficult task of creating intelligent machines, the AI research community, and the popular audience he is addressing would be much better served. As it stands, the book offers no constructive guidance to creating an intelligent machine, and its contents would be very different if it did.",34
Steven K,4.0 out of 5 stars,"The Emotion Machine: Commonsense Thinking, Artificial Intelligence, and the Future of the Human Mind",Excellent book on thinking machines - but misleading title,"I agree with the reviewer who noted how odd it was that a book titled ""The Emotion Machine"" does not discuss Joseph LeDoux, even if only to refute him. But I think that the problem is with the title, not the book. I found many of Minsky's insights very helpful - it is a very good book about how machines think. And if you are not a dualist, then those insights apply to people too. The book is very well organized and clearly written, and helps you think about thinking. I especially enjoyed his discussion of qualia (although he does not use the term), and why he thinks it is not quite the problem that so many philosophers want to make it.

Minsky's main take on emotions is that emotional states are not fundamentally different from other types of thinking, and that the entire dicotomy of rationality v. emotion is misleading. He prefers to view them all as different ways of thinking - of utilizing various mental resources at one's disposal, some conscious and some not. He organizes his discussion of difficult material very well, but I wish there was more grounding in the underlying neural anatomy of human emotion.",34
W. Birkett,3.0 out of 5 stars,Neural Networks and Learning Machines (3rd Edition),Kindle Edition Riddled With Typos,"This is an excellent book. However, the Kindle edition is full of errors. There are hundreds of missing spaces and extra hyphens. That is annoying. The serious problem (that led me to write this review) is that math symbols used in the text are frequently wrong and/or indecipherable. This is a math book. These errors are just unacceptable. I'm sure the author would be horrified to see what Amazon has done to his masterpiece!",34
Riccardo Audano,2.0 out of 5 stars,AI for Game Developers: Creating Intelligent Behavior in Games,Intelligent agents should steer clear from this book,"Terrible and useless even for a book on AI for budding game developers. The theory and explanations in this book are sometimes decent but more often than not quite lacking. (es: in one of the first chapter the author uses Bresenham algorithm without taking the time to explain it). The use of tile based examples introduce unnecessary overhead, and the continuos attempts to introduce physics related code and references to the author's other book on game physics are just plain annoying. The range of subjects covered is very broad (chasing and evading, pathfinding, emergent behaviours, rule based reasoning, bayesian networks, neural networks, fuzzy logic, finite state machines, genetic algorithms), definitely too broad to treat each of these subject in decent depth and with clarity. Example code is of low quality and just superficially object-oriented. If you are looking for a decent introduction to game AI I recommend Matt Buckland ""Programming Game AI by Example"" and ""AI Techniques for Game Programming"".",34
Mercenary Trader,5.0 out of 5 stars,Dark Pools: The Rise of the Machine Traders and the Rigging of the U.S. Stock Market,Meet the New Market Makers (Same as the Old Market Makers),"'Dark Pools' is a fun, intelligent, beach weekend read.

Apart from the obvious Wall Street / HFT focus, the book struck me as a cross between War Games, The Matrix, and Terminator: Rise of the Machines. You immediately enter a world of high tech mayhem, with super-algos, blaster bots, and hunter-sniper cloaking devices duking it out at the speed of light.

Re, War Games parallels, you get an iconoclastic, vaguely teenage anti-hero - Josh Levine, the misift-hacker-genius creator of Island - who pursues an idealistic vision of ""making markets free,"" with no impure thoughts of capitalistic gain, until one day his mutated ECN creation all but comes alive and says: ""Good morning, Professor Falken. Do you want to play a game?""

Re, Matrix parallels, by the end of the book we have fast-forwarded from the humble beginnings of electronic trading to the near birth of AI (artificial intelligence)... the ""desert of the real"" (in this case the real being markets)... and the grand vision of supervillainesque networked undersea substructures, monitoring global data flows from strategic ocean points all around the globe.

Re, Terminator, in the final stretch I kept waiting for Patterson to write: ""As future tech historians will note, SkyNet showed signs of self-awareness on X-X date, 2012...""

It was all a bit much - but in a good way. As Keynes once said, ""Words ought to be a little wild, for they are the assault of thoughts on the unthinking."" This book will definitely get you thinking about the impact of high frequency trading on markets.

My two cents: At the end of the day, high frequency traders are the new market makers... the superfast replacements for the hand-signaling floor traders and post-sitting NYSE specialists of old. Yours truly predicted as much would happen in a review of ""The Predictors"" by Thomas Bass, titled ""The New Market Makers?"" circa 2005 (still available via my Amazon review page).

As I wrote nearly seven years ago:

""These guys occupy a very specific niche in the market ecosystem. Before the onslaught of computers, human floor traders provided vital liquidity to the markets (and got paid plenty well to do so). As physical exchanges lumber towards extinction, `smart' algorithms are filling the shoes of floor traders, extracting profits tick by tick with high volume, high frequency strategies. These automated players are thus becoming the new liquidity providers and market makers of the 21st century. Daytraders and scalpers may find themselves swept up in a technological arms race, but longer term traders and investors have little to fear... it's a different game.""

Such is why this review is titled, ""Meet the New Market Makers (Same as the Old Market Makers)"". In a lot of ways, despite all the technological advancement, the biggest things haven't changed.

Take the infamous ""Flash Crash"" of May 2010, for example. When you understand the role that high frequency traders play these days - in terms of facilitating the majority of volume and liquidity in markets - it makes sense to expect chaos when they all ""pull their bids"" at once.

From the perspective of a freak occurrence where a large portion of the HFT community ""backed away,"" exposing ridiculously far-off placeholder bids that were never meant to be hit, the market makers of the 21st century acted just like the market makers of the last century amidst the crash of 1987. They left a void at a point of severe dislocation, just as the old school guys did so long ago.

Perhaps now that GETCO - which stands for Global Electronic Trading Co, the most supervillain-like shop of them all - has assumed official market maker duties in many household names, such bid pulling will not be a future problem.

The question remains: Are the new guys worse than the old guys? I'm skeptical.

Anyone nostalgic for the old days of physical pits and human specialists may not remember the day-to-day reality of such a system.

As an international commodity broker in the late 1990s, I had the privilege of phoning into the pits on behalf of hedge and commercial clients, to yell at some guy named Vinny or Frankie or Sol - inevitably the brother-in-law or cousin of the Refco floor trader who executed our order - to try and get restitution on a criminally bad fill. This kind of thing happened far too often.

And as for being an NYSE specialist? Talk about a license to print money. There is a reason such jobs were handed down from one generation to the next. In many cases, the opportunities provided were the legal equivalent of stealing.

Not to mention the commissions - good lord, the commissions! - that retail and institutional clients alike were forced to pay in the old days. Add it all up, and I don't think the pennies and nickels hoovered up by the HFT shops, mitigated by the incredibly low-cost commissions available via technology today, amount to such a bad deal.

A bit of wildness that made me laugh out loud was the notion that computers are going to take over the markets one day, as in, putting directional investors and traders out of a job. Seriously? Puhleeze. These bots may be great at nano-scalping, playing for blips on a mass scale, but true directional market involvement is another matter entirely.

If you're truly worried about thinking machines eating your lunch in a multi-day or multi-week time frame, don't be. Marvin Minsky, a noted forefather in the Artificial Intelligence field - a very confident AI optimist 15 to 20 years ago - recently admitted the following:

""The bottom line is that we really haven't progressed too far toward a truly intelligent machine. We have collections of dumb specialists in small domains; the true majesty of general intelligence still awaits our attack.""

""Dumb specialists in small domains"" well describes the proliferation of tick-hungry algos. They are good at what they do in a very tight timeframe, but the inputs required to parse incalculable variables across extended time horizons are another matter entirely. As I wrote some time ago, the most powerful supercomputer on the planet is not smart enough to figure out the turbulence in a glass of water - and yet we expect it to crack the self-referential human feedback loop that is markets?

The book closes with a glimpse of the supposed future in ""Star,"" the self-learning, self-teaching virtual machine assigned to make investment decisions for a tiny hedge fund, Rebellion Research. To the extent that Star is supposed to be a threat to humans, color me skeptical. (Those who are just mediocre at their jobs - rather than very good - have much to feel threatened by, of course... but such has always been thus.)

Patterson makes brief allusion to computer-assisted chess, the powerful combination of hardware and wetware (software programs plus human guidance). For cream of the crop money managers, I think this is closer to the true way forward - using technology to enhance human capability, not replace it.

In terms of thinking games, the best metaphor / AI-intelligence test is perhaps not the fixed Western game, Chess, but the fluid Chinese game, Go, which contains far too many variables within the scope of possible movements for any computer, even Deep Blue, to brute-force calculate the optimal strategy path. (For this reason, no Go champion has ever fallen to a machine.)

At the end of the day, trading and investing strategies will continue to evolve. High frequency traders, and various forms of new technology, will continue to influence markets in unexpected and interesting ways.

But I believe the following words from ""Reminiscences of a Stock Operator,"" which were true in 1923, will remain just as true a century hence: ""There are men whose gait is far quicker than the mob's. They are bound to lead - no matter how much the mob changes.""",33
James F. Kadlec,2.0 out of 5 stars,GIMP for Absolute Beginners,Not for anyone with Gimp experience,"The book title says it all, unfortunately, I didn't take it at its word and bought a copy from Amazon. Since Gimp is such a dynamic program I thought I could really get something out of the text. I don't mind having a basic book because usually one can glean something in a new presentation.

However, this book has really been written about digital photo editing with Gimp or creating art with Gimp. What photo editing it has is fine, but if that is the subject and someone really wants to learn that, he or she would be better off using the freeware program Irfanview than Gimp. He or she could easily learn what is explained by trial and error. Irfanview has everything covered for editing and while Gimp can do the same things, the main purpose of Gimp is probably photo manipulation, rather than simple digital photo editing.

The complexity of what Gimp can do is far beyond what someone needs for straightforward photo editing. When working with digital photos, I do basic photo editing in Irfanview which takes only 15 or 30 seconds, then if something more is required, I go to Photoshop or Gimp or even Paint for a few things. However, beginning in Gimp or Photoshop to do simple photo editing is like using a cannon when you need a slingshot.

Even with photo editing or manipulation, this text fails. It has only black and white images. Before you buy it, consider if you want a book which tells you how to do things in color, then gives you an illustration of results in gray scale.

There is also a big section on how to create art in Gimp. Perhaps if this is your intent, this book on Gimp might have some application, however the title is then misleading.

All in all, if you have any basic knowledge of Gimp, this book is not for you. If you are looking for simple photo editing, use the intuitive program Irfanview.

It is too bad that the authors have utilized their expertise for something which I doubt has much value for people looking for basic instructions in Gimp (a niche which is still unfilled).",33
Todd Ebert,4.0 out of 5 stars,Learning in Graphical Models (Adaptive Computation and Machine Learning),"Recommended, but not the place to begin","The title of the book is somewhat misleading, in that most of the research papers involve advanced issues concerning one particular graphical model, namely the Bayesian network. For this reason I highly recommend, as a prerequisite to this book, Finn Jensen's ""Bayesian Networks and Decision Graphs"". Jensen's book is adequate in giving a good introduction and overview of the subject, but not sufficient for calling oneself an ""expert"" upon successfully digesting it.
To its credit, ""Learning in Graphical Models"" has several well-written and interesting papers, but the tutorial papers just did not seem enough of an introduction for me to feel comfortable using it as a first source of introduction.
What I find most compelling about Bayesian networks is the fact that they seem both highly modular (which facilitates reusability and network interconnectivity) and can be designed in a semi-rational manner (contrast this with neural-network architectures for which few good algorithms exist for determining size and number of layers). For this reason I imagine they will be important players in future engineering projects that require learning and adaptation.",33
lutusp,1.0 out of 5 stars,"Superintelligence: Paths, Dangers, Strategies",computers might become very smart and eat us for lunch,"I rarely see a book that possesses such an embarrassing ratio of words to ideas, but this book exceeds all prior experience. After reading 100 pages and noting a complete absence of original or enlightening ideas or anything resembling narrative structure, I gave up. It seems that philosophy training confers a talent for squeezing the maximum number of words from an absolute minimum of ideas.

I can summarize the entire book for you: computers might become very smart and eat us for lunch, but on the other hand, maybe they won't. There you have it -- nothing original, nothing resembling insight, delivered in a blizzard of words.",32
Zac,4.0 out of 5 stars,Pattern Recognition and Machine Learning (Information Science and Statistics),Another book about machine learning without a clear theoretical backbone.,"Bishop's book about machine learing and pattern recognition is well written and the figures are really pretty because they are in color and informative. Overall the book looks very nice and it is fun to read in. In my opinion only the book 'The Elements of Statistical Learning' by Hastie et al. looks comparably well.

The book is a textbook rather than a monograph and, hence, intended for students rather than researchers and the coverage of machine learning topics is thorough without being able to cover every topic in deepth. This is not really a draw back because no book is able to do this anyway. The presentation of the methods is informative and, depending on the background of the reader, clear enough to figure out how it works to use the method.

What is the problem: I do not like that the methods are introduced not rigourously but by examples. That mean Bishop does not have the definiton, theorem, proof style but is more heuristic. This may sound very helpful for the reader not familiar with the topic to reduce the barrier of understanding by providing examples to visulalize the problem. The problem is, in my opinion, that this is not the case but the oposite. In think it is never wrong to provide examples and it is absolutely desirable but after the examples are given and one has an intuitive understanding of the problem one wants to see its formal solution because that's what machine learning is about, it is applied statistics. For this reason I give only 4 instead of 5 points (but not less because also all the other books about this topic fail in this respect).

Overall, the book is well done and certainly a good source of information for students and researches.",32
David L. Parnell,5.0 out of 5 stars,Make Your Own Neural Network,Such authors and teachers are invaluable to the human race !,"Tariq Rashid reminds me of Isaac Asimov who could marvelously render a highly technical topic into an interesting narrative that any average human could read, enjoy, and understand the fundamentals of technology or science. While I had Googled many documents purporting to explain neural networks, none penetrated my brain in any meaningful way. However, as soon as I began reading Tariq Rashid??s book, ??Make Your Own Neural Network,? I realized I had found an author and a book which could load an average, non-mathematical mind with an understanding of this topic of interest. Such authors and teachers are invaluable to the human race !",32
Sam Lynch,3.0 out of 5 stars,Amazon Echo: 2017 Edition - User Guide and Manual - Learn It Live It Love It,Starter only,"This book is a good one to use as your first overview of Echo. The text is easy to read and covers the essential nature and some uses for this product. It will not, however, satisfy you long-term reference needs.",32
Blaine Lilly,5.0 out of 5 stars,The Sciences of the Artificial - 3rd Edition,Incredibly thought provoking and original...,"This book is one of the most thought provoking, challenging books I've come across in many years. Simon tosses off ideas like a Border Collie shaking off water. This is not a book to be skimmed, or to be taken lightly, but a slow careful reading will certainly pay off. I read this book for insights into product design, and it did not disappoint.",32
Mark A. Weiss,4.0 out of 5 stars,The Grammar of Graphics (Statistics and Computing),"skip details (esp. formalisms); instead get hilighter ready for principles, perspectives","Most of what other reviewers say has factual accuracy. But first I must say that the ""subset"" of people who enjoy CLEVELAND (WILLIAM S.)'s works will enjoy the Grammar of Graphics book.

Sorry, but people who enjoy TUFTE are not potential candidates for this book because Tufte has way too little to say about graphics (despite his books, lectures, which ultimately are about $$$ for Tufte). Tufte's main thing is his admonition ""don't do chart junk"" followed by his second favorite thing: join with him and disparage the ""cognitive style"" of PowerPoint. The former is true, but is not terribly subtle. As for the second, the tool of PowerPoint need not be used in the boring ""cognitive style"" with bullets and ""branding"". I for one have made plenty of PowerPoint presentations totally unlike these.

The summary of ""subset""s of folks: William S. Cleveland followers: yes, you'll love this book; those who mistake Tufte for the ultimate graphical guru probably will find this book ""too much"". Note that the author of the Grammar of Graphics book literally says how Cleveland wins the citations contest in his book. No surprise, because Cleveland has made many creative developments for statistical graphics and has also studied graphical perception. (As just ONE of a myriad of examples: residuals are very badly ""mis-read"" by our perception when there is a steeply sloped curve; residual in y- direction may be very large, but we see only a very much shorter perpendicular distance.)

(Finally, in fairness, Tufte has had two good ideas -- but only two compared to Cleveland's several dozen. Tufte's tics-at-data (for x- and y- separate marginal distributions [essentially 1-D scatterplots made by tics]) and Tufte's white-grid-run-thru-of-bar-plots are his two contributions of any substance.)

OK. Thanks for bearing with my review which, thus far, has covered the Cleveland and Tufte subsets of readers. Time for the Grammar of Graphics book character itself --without context of being a Cleveland reader or a Tufte Reader.

If you have not experienced reading Cleveland's books (Elements of Graphing Data and/or Visualizing Data), I admit that this book will be more difficult for you.

The above point aside, you should know, like other reviewers said, that this book is not a how-to. Nor is it like Cleveland's books -- chock full of guideline principles. There are plenty of principles in the book, but with its size, the CONCENTRATION of principles to pages of text is low.

THE BEST PERSPECTIVE ON THIS BOOK: The best perspective is to not sweat consuming every little detail. Especially skip all the formalisms (even though this is ostensibly the topic of the book!) Instead, just enjoy. This is one book definitely to apply your highlighter to. Forget the formalisms completely. Concentrate on the important points made throughout -- but you'll need to highlight them. If you come to the book from Cleveland (William S.) it will be easier for you to spot the important points. Just don't think you have to learn details and formalisms.

One tip -- Cleveland reader or not -- whenever there is any text suggesting a perspective, that text may well be calling for your highlighter -- not always, but often.

Go for principles, perspectives and ignore formalisms. You'll be more at ease and enjoy the book.

If you think you might do both William S. Cleveland's books AND the Grammar of Graphics book -- no question, do Cleveland first (Elements of Graphing Data [more basic] and Visualizing Data [more advanced statistical questions addressed graphically]).

P.S. I don't recall if other reviewers mentioned it, but Wilkinson (author of Grammar of Graphics) is creator of the SYSTAT statistical software package.",32
Arun R,3.0 out of 5 stars,Machine Learning in Action,Good attempt but needs LOT of improvement,"Looking at many good reviews on amazon, I decided to purchase this book. It's a decent book, but IMO it has been edited poorly and the code has not been tested properly.

The introduction chapter got me really excited, just like other Manning's ""in Action"" books do. But once I started executing the code in chapter 2 ""Classifying with k-nearest neighbors"" I realized that the code had bugs. Though I could figure out what's wrong and fix the bugs, I did not expect this from Manning, after having read some of their excellent books like (The Quick Python Book, Second Edition,Spring in Action and Hadoop in Action).

Moreover the book has some introduction to python and numpy in appendix A. I believe the author could have pointed the reader elsewhere for learning python and those pages could have been used to explain more of numpy and matplotlib, which the author uses freely without any explanation in the text. (Yup, be ready to read some online numpy and matplotlib tutorials and documentation.)

If you don't know python, then you can do what I did: read The Quick Python Book, Second Edition and then attempt this book.

The figures in the book are not in color so you need to execute the code to understand what the author is telling. It forces you to actually run the code, which is good, but you can't read this book without a computer in front of you.

Finally, I am a big believer in following the conventions of a language. I would have been really happy had the author followed PEP8 ([...]), because along with learning machine learning, you could have learnt some good python coding practices.",32
Dr. Lee D. Carlson,3.0 out of 5 stars,Conceptual Spaces: The Geometry of Thought (MIT Press),A little disappointing,"If one is to design a machine that can formulate concepts and engage in such things as inductive inference and its corollary scientific discovery, then one must be able to quantify the notion of a concept in such a way that it can be implemented into the cognitive structure of the machine. One must be able to distinguish one concept from another, be able to tell when one concept is similar to another, and understand in detail how concepts are related across domains. It would not be enough to have qualitative notions of these distinctions or similarities, since they must be able to be formatted in such a way, either via coding, language, or electronically, so as to be used by the machine.
This book gives an interesting approach to the problem of concept classification, but it does so only from a qualitative point of view. It is a good start in this regard, and readers will gain a lot of insight into the problems that it addresses. It does not however give any advice on how to implement its ideas into a real thinking machine. Mathematical concepts are brought in order to talk more meaningfully about spaces of concepts, but they are really restricted to metric spaces and not general enough to deal with the plethora of concepts that could present themselves in typical environments. The book should be considered more as a work in philosophy, so those interested in this field might enjoy the book more than those who were expecting a book more geared towards artificial intelligence and computer science. Those readers interested in automated theorem proving or automated mathematical discovery might find the discussion on geometric categorization models of interest, and will find an interesting application of Voronoi tessellations, namely that of accounting for the varying sizes of concepts in a categorization.
By far the most interesting chapter in the book is chapter 6, wherein the author gives a highly original discussion of inductive inference. The ability of human cognition to generalize from a limited number of observations is viewed (correctly) by the author as very impressive, but he is careful to note that inductive inference cannot be done free of side constraints. Quoting the philosopher J.S. Peirce and his evolutionary explanation of why induction is so effective, the author uses his theory of conceptual spaces to develop a theory of constraints for inductive inferences. The main notion in this theory is that of ""projectability"", which attempts to delineate the properties and concepts that are may be used in inductive inference. The author wants to arrive at a computational model of induction, and he offers interesting proposals for doing so, even if they lack immediate empirical justification.
Central to the problem of induction the author argues is how observations are to be represented. This has been neglected in the history of philosophy he says, and so he then proceeds to outline his ideas on how to represent observations, distinguishing three levels, namely the `symbolic', the `conceptual', and the `subconceptual.' At the symbolic level, observations are represented by describing them in a specified language. At the conceptual level, observations are characterized relative to a conceptual space. At this level induction is viewed as concept formation. At the subconceptual level observations are characterized by inputs from sensory receptors. Induction is then viewed as the attaining of connections between various inputs. The author views the processing taking place in artificial neural networks as an example of modeling at the subconceptual level.
The problem of induction is more complicated than is typically presented in the literature, the author argues. Inductive inference will look different depending on which approach to observations is taken. In his elaborations on the processes of induction, one of the key issues that arises is the how discovery takes place across different domains. The process of conceptualizing across different domains takes place, as expected, at the subconceptual and conceptual levels. The symbolic level is delegated to formulating laws.",32
Phillip T. Carson,5.0 out of 5 stars,Blondie24: Playing at the Edge of AI (The Morgan Kaufmann Series in Artificial Intelligence),Most compelling AI book I've read,"I was already interested in neural networks, and have read several other books on the subject, all for information on how to design and build neural networks to do various tasks, so I was primed to like this book, but I had no idea how compelling it would be. Fogel does give most of the details necessary to recreate Blondie, but some of the specifics for the later modifications are missing and can be found, I believe, in his and his partner's scientific articles referenced in the book.
The first half is quite good, giving very basic background information on neural networks and machine learning algorithms as well as a brief history of the two best known checkers programs, Samuels' machine learning checkers player and Chinook, the best ever player (so far).
It's the second half of the book, however, that kicks the story into overdrive. Fogel begins describing how he and his partner, Kumar Chellapilla, made their design decisions, evolved a neural net, then began playing it against humans over the internet. Even if you aren't all that interested in checkers (I am not) the games as they are described by Fogel become at least as interesting as any close sporting event, especially in those cases where the neural net set up traps for its opponents that neither Fogel nor the other player could foresee. There were times that I couldn't stop reading. I'd get off the bus to work, get in the office, and continue until I could pull myself away. The second half of this book is as much a page turner as the best novels I've read.
An absolute must read for anyone interested in where AI needs to go.",32
Nutty Prof.,1.0 out of 5 stars,How to Create a Mind: The Secret of Human Thought Revealed,Does not explain how to create a mind.,"This book is written by an upper management type who has not been in the trenches for years. He has very little knowledge of AI and this book is an exploration into unproven theories of intelligence production. He starts out with what he calls ""Pattern Recognizers "" and then continues to quote the use of those without ever providing a solid explanation for what they are and what they do. He just says they work and that he did a lot of research on them.

He talks about the biological functions of the brain but never makes a connection for how that view of the brain produces intelligence (a mind). He gives a complicated view of the brain and shows the storage methods the brain might use, the way words are stored and other unimportant facts that do nothing to make the reader understand how a mind is produced.

He also attempts to explain the functions of the human brain in computer science terms which may be OK for computer science professionals but is probably cumbersome for the layman. I have a computer science background and I found it a very hard read. He never gives even a perfunctory explanation of how the brain produces thought, which I would assume would be included in a book that claims it knows how to create a mind. The book does nothing of the sort.

Secret of human thought revealed? I don't think so!",31
spikedlatte,4.0 out of 5 stars,Probabilistic Graphical Models: Principles and Techniques (Adaptive Computation and Machine Learning series),A comprehensive and tutorial introduction to the subject,"I have read this book in bits and pieces and find it extremely useful. Finally, we got a book that can be used in classroom settings. There are some typos (hence four stars) that will hopefully get fixed in the future editions. The book also has a lot of new insights to offer that can only be gleaned from the vast existing literature on the topic with excruciating labor. Agreed that this book is pricey but for what it has to offer, I think it was money well spent.",30
Stephen Rowe,3.0 out of 5 stars,"Introduction to Automata Theory, Languages, and Computation (3rd Edition)",Disappointing - Not a great first book,"I had to use this for a Formal Models of Computation class last semester. It's okay but can be hard to follow. It is often hard to learn from the examples. The formalism and proof gets in the way of intuition. It would make a better 2nd book or reference than a first book on the subject. I supplemented the book with Sipser and found that a much better book for learning from. Hopcroft (this book) is more mathematical in nature but the explanation is harder to follow. If you have a choice, go with Sipser.

As near as I can tell, the big improvement in the 3rd edition over the 2nd is the inclusion of some online practice problems. If your class isn't going to be using these, can you save money by going with the older copy.",30
Lowell,4.0 out of 5 stars,"Amazon Echo: The Ultimate Guide to Learn Amazon Echo In No Time (Amazon Echo, Alexa Skills Kit, smart devices, digital services, digital media) (Amazon Prime, internet device, guide) (Volume 6)",Perfect guide for amazon echo!,"This guide about the echo is a quick and easy to use instruction manual that you can read through if you want to explore the device and experience the power of it.I learned a lot from this book, and for me, this book is very informative. Using the book as a walk through manual worked very well and I feel like I really understand the product very well due to the book. This book was written for people who are new to Echo and who are non-computer nerds.I highly recommended this book.",30
Paul D. Tozour,5.0 out of 5 stars,Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference (Morgan Kaufmann Series in Representation and Reasoning),Fantastic!!!,"This book is an absolutely essential book for AI programming. I've found no better book for explaining the recent advances in probability theory and its relevance to real-life, practical artificial intelligence development. It's written in a very down-to-earth and highly entertaining style with plenty of examples.
I've been looking for a good introduction to Bayes nets for a long time, and this one is by far the best and most comprehensive.
Probability is increasingly becoming one of the major foundations of effective artificial intelligence, and I strongly recommend this book to anyone with an interest in AI or probability theory.",30
Amazon Customer,3.0 out of 5 stars,"Decoding the Universe: How the New Science of Information Is Explaining Everything in the Cosmos, from Our Brains to Black Holes","Well written, but only for the true layperson","This is a gentle introduction to a fascinating subject: that information actually has a physical basis in the universe and that information theory (based on the work of Shannon to determine how much information can theoretically be transmitted across phone lines, but carried by Shannon and his successors far, far further)may actually be fundamental in explaining quantum mechanics and indeed our entire universe.

The book starts with basic description of entropy and definitions of information and proceeds to discussions of quantum mechanics, quantum computing, and such interesting topics as whether Black Holes destroy information or not (Hawkings bet they did, but ultimately conceded...as Seife notes, Hawkings may be the only one who actually changed his mind).

Seife is a clear writer and great at creating an argument step-by-step.

However... I was a math major, a physics minor and am a working computer scientist with years of coursework in automata and complexity theory. Though there was new material in this book for me, vast swathes were way too introductory for me. I really didn't need a 20 page description of how bits are the fundamental element of information and strings of bits can encode anything, or for that matter to rehash special relativity or the selfish gene theory. Though it mostly succeeds, this book may be a little too ambitious. It tries to start with first principles for the layman, but spans so many fields (thermodynamics, information theory, quantum mechanics, biology, cosmology, special and general relativity) that providing basic introductions to all of them greatly dilutes the new and interesting material.

I really wish I knew what to read next. From here it appears most things are other popularizations or deeply technical works for specialists in quantum computing. Hopefully somebody will write a ""Selfish Gene"" or ""Elegant Universe"" that goes into more detail while remaining popularly accessible for the scientifically trained.",30
Stephen Rowe,3.0 out of 5 stars,"Introduction to Automata Theory, Languages, and Computation (2nd Edition)",Disappointing - Not a great first book,"I had to use this for a Formal Models of Computation class last semester. It's okay but can be hard to follow. It is often hard to learn from the examples. The formalism and proof gets in the way of intuition. It would make a better 2nd book or reference than a first book on the subject. I supplemented the book with Sipser and found that a much better book for learning from. Hopcroft (this book) is more mathematical in nature but the explanation is harder to follow. If you have a choice, go with Sipser.

As near as I can tell, the big improvement in the 3rd edition over the 2nd is the inclusion of some online practice problems. If your class isn't going to be using these, can you save money by going with the older copy.",30
Michael R. Chernick,5.0 out of 5 stars,The Frailty Model (Statistics for Biology and Health),first serious book dedicated to Frailty Models,"The authors are academics who have done serious research in survival analysis and are very familiar with frailty models. The topic comes up when time to event data for one event is correlated with the time to event data for another or other events. This topic is sometimes referred to a subject in multivariate survival analysis or the analysis of clustered survival data.

As a professional biostatistician with a keen interest in survival models I have attended professional meetings in recent years and heard the term Frailty Model mentioned but I didn't know what it was. There of course is the natural connotation of weakness as in a feeble or frail person. But the actual formal dtatisticial meaning was a mystery. Other books that I am very familar with deal in part with frailty models but this is to my knowledge the first serious text dedicated to this topic. It also covers related methods to accomplish the same goal such as copulas (another term common in recent books and literature but one I was not familiar with either). For example Philip Hougaard wrote the first advanced text on multivariate survival models and covers parametric forms of frailty models. Klein and Moeschberger wrote a generaal survival analysis book that includes a chapter on semi-parameric fraility models. It showa how the EM algorithm is used to estimate parameters of the models. Ibrahim and colleague wrote a book on Bayesian methods in survival analysis and cover the Bayesian approach to both semi-parametric and parametric fraility models. Therneau and Grambsch wrote a recent book on the Cox proportional hazard model and its extensions. It included information on semi-parametric frailty models using the penalized partial likelihood approach to estimation.

This book is a well-written introduction to fraility models that includes all these methods provides real world examples and good explanations on how to interpret the results. The examples are illustrated using the freeware language R. This book could serve as either an undergraduate or graduate text in statistical methods and is a great reference for biostatisticians.",30
N/A,5.0 out of 5 stars,Algorithms for Image Processing and Computer Vision,Excellent cook book of advanced IP techniques,"At its best, this book is a wonderful cookbook of image processing techniques. For example the author's presentation of the Canny and Shen-Castan methods of edge detection is clear and detailed. Full C source is provided for this and all the other techniques discussed in the book. The book does not pretend to be a basic introduction to image processing -- if you do not have Castleman or Pratt or something similar on your bookshelf, you probably should not start by acquiring this book. A possible source of irritation for some readers will be the variation in depth of coverage of topics. For example, when the author discusses wavelets, the coverage is very scant and qualitative. It is well done, but quite different in kind from the aforementioned coverage of advanced edge detection techniques. Similarly, the author will cover specific aspects of image processing, such as motion blur for an image, in the context of a rather general discussion of image restoration. In short, the book seems to reflect the author's interests more than attempting to be an objective coverage of the current state of the art in image processing. Nonetheless, the high quality of the information that the author provides and the bibliography to further coverage of the given topics are well worth the price of the book. You just need to approach it on the author's terms rather than on a preconceived notion of what you should get out of the book.",30
Randall K Julian,5.0 out of 5 stars,Machine Learning: An Algorithmic Perspective (Chapman & Hall/Crc Machine Learning & Pattern Recognition),Outstanding guide to Machine Learning using Python,"I am updating my review of this book because apparently in my first review I didn't do a very good job. This made the review less than useful. I will try to do a better job this time. If it still isn't helpful let me know and I will try again.

Like the title says, this book takes an algorithmic approach to teaching machine learning - as opposed to an applied or example based approach. The expectation is that you would get a tutorial on all the main algorithms rather than how to put various algorithms together to solve a particular problem in, say, fraud detection.

The Contents reveal the algorithm basis:

1. Introduction (types of machine learning, why you would want to do it in the first place and a quick introduction to supervised learning)
2. Preliminaries (Key ideas about the problem of over fitting and the what I consider the most important topic: how to test and know when you have a program that has learned something other than the noise). Here the author also covers some ideas about the role of probability. Calling it ""turning data into probabilities"" is a bit odd, but that's really what we do. Early on he gets the key ideas of the ROC curve out of the way - something many texts just gloss over.

I think the secret to understanding machine learning is understanding the idea behind the bias-variance trade-off (it is also handled very well in The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Second Edition (Springer Series in Statistics) which I used to teach a class and read before I read this book.

3. Coverage of Artificial Neural Networks starting with the perceptron and why you would want to go beyond linear discriminators
4. The multilayer ANN
5. Radial Basis Functions and Splines - this is interesting because, Andrew Ng presents a linear regression as the most basic learning algorithm in his Coursera course which means all of the fitting methods, even when not used for classification are relevant.
6. Is a section on dimensional reduction - feature selection and other methods like PCA and even factor analysis (most people stop with PCA which I personally think is a mistake, because you can accidentally end up keeping the features with all the noise and throwing out the meaningful linear combinations.
7.This is a cool section not seen in basic books on probabilistic methods - sure everyone teaches k-NN, but this one has a nice discussion of Gaussian mixture models
8. Talks about the support vector machine. Most people don't get introduced to the idea that ANN and SVMs are actually very similar - they are both large margin classifiers and so knowing something about SVMs will help, even if you end up with some other large margin classifier (with or without kernels)
9. This section talks about search and optimization. The way Ng teaches machine learning, you always begin with the error surface, take the derivative and then search for a minimum in the learning function. You quit teaching when you have minimized the error on the training set without out driving the error too high on the validation set - so in a way all these approaches are optimization methods.
10. A whole section of genetic algorithms (which I jumped to first) a very clear explanation and a good example that really ran so I could see what was going on.
11. Reinforcement learning
12. Learning with trees - CART trees end the chapter something everyone working in this area should know something about. He saves random forests for the next section (where I suppose it really belongs)
13. This section is on bagging an boosting and then compares the idea of a collection of weak learners (like stubby random trees) as a powerful tool - the idea behind random forests.
14. Unsupervised learning. People tend to focus on supervised learning for a very good reason, but there are lots of examples where the cost of putting a label on a data example is too high, so an unsupervised method is a good call.
15. Coverage of Markov Chain methods (MCMC) - again this does not get covered in every applied book.
16. Graphical models - the Bayesian Network and Probabilistic Network Models along with the hidden Markov models
17. Deep belief networks
18. Gaussian process regression and classification

The book concludes with an appendix on Python - getting started etc. I don't think this is quite enough Phython unless you are already pretty familiar with the language.

A critic of my first review suggested that I just bashed R and didn't talk about the book - not a completely unfair statement. R keeps data in data frames and Python is much more list and directory based. Data frames and collections are related and there are ways to do list comprehension in both languages. and Python has a data frame package to make using R-like constructs easier if you happen to be coming from R and like them (the package is called Pandas) Both are good languages, but I will stand by my original statement that R is a statistical language at its core. Many of the packages are written in C so they are fast (like the ones written for Python). It has been my experience that the open source tools for R development are just what the commentator said: they are adequate. I my humble opinion, R-Studio has a lot of catching up to do to be as good as professional tools like the JetBrains stuff (PyCharm). Look at MatLab compared to Octave. At lest the community version of PyCharm is free. R-Studio is not fast, and he dirty secret of R is that everything you do has to fit in memory at once, so you have to be very careful with memory management or you will run out and R will crash - it happens to me everyday. Almost all of the ML methods are statistically based so R and all the books (like An Introduction to Statistical Learning: with Applications in R (Springer Texts in Statistics) are totally brilliant. But if you want to see what it is under the hood, I suggest you look at Advanced R (Chapman & Hall/CRC The R Series). This will give you a deep dive on the internals. Compare it to Python Scripting for Computational Science (Texts in Computational Science and Engineering) and make the call for yourself.

I have used both R and Python for both prototyping advanced algorithms and putting code live in production. What tipped the scale for me was the productivity. Now that the data science community has started building state-of-art tools for Python, (not to say anything negative about the statistics community who put all of machine learning on a solid footing), I prefer a rapid development language with good tools, test-first frameworks and solid software engineering practices as part of the culture. The book reviewed here allows you to learn almost all of the algorithms used for machine learning and in the end you will be able to produce fast, readable, testable code.",30
Samantha Atkins,1.0 out of 5 stars,Artificial Intelligence: A Modern Approach (3rd Edition),Warning: Extra Kindle DRM on this title,I loaded the Kindle version up on my iPad. Great. But I needed it on my laptop (Mac) for class. I tried to load it with Kindle for Mac and it claims it has exceeded the maximum allowed licenses. I am extremely pissed. I bought the hard back for a small fortune and only slightly smaller fortune for e-access and I can't even read it on a measly two devices? This is totally and completely unacceptable.,29
Alexei Lebedev,4.0 out of 5 stars,On Intelligence,"motivating, but bites off way more than it can chew","I found the reviews and blurbs very intriguing, and once I had the book I didn't put it down until I had read it all.

This book does *not* have the kind of science-is-wonder attitude you might find in Sagan; it does not convey the message ""Study science, it's a noble thing to do, your curiosity will be greatly rewarded"", like some reviewers write. It's not the kind of book that summarizes the state of what's known about the brain today, while getting you excited about finding out more.

This book is really a monograph by someone who thinks they have literally figured out the brain, and it contains mostly what the author has to say. So you won't see a mention of the holographic theory of the brain, or the brain-as-dynamic-system view. In my opinion, in a book addressed to the general public, that's a problem.

It's a problem, because on one hand the book is written for the general public, while on the other hand it presents utterly untested (by anyone, even the author) hypotheses, mostly made by the author himself or hand-picked from existing research.

In this respect, it reminds one of ""A New Kind of Science"" by Stephen Wolfram, another ""scientific"" book which aims to directly impress the layman with something he's not likely to understand, while bypassing specialists.

Next, what annoyed me somewhat is the the fact that the subject, admittedly the biggest mystery of our time, is given such a simplistic treatment. No, we're no closer to creating something that can, say, semi-intelligently fly around the room and land on things, or since the author prefers non-behavioral intelligence, detect whether a given picture has a cat in it. So why such extraordinary claims of no results were obtained?

Finally, there is no evidence that the author or his colleagues have actually built any software or hardware that can detect any meaningful patterns in visual or audio streams.

Yet, I'd still recommend this book, because it highly readable, and it'll make you think (even if it's about the outrageous claims). Because of that it gets four stars.",29
Oliver J Reeves,3.0 out of 5 stars,Nine Algorithms That Changed the Future: The Ingenious Ideas That Drive Today's Computers,"Good for those new to the field, a little drab for geeks","The book was enjoyable but did in many ways feel like a father trying to explain things to his toddler. The style of the book felt unnecessarily ""soft"" given that the topic is Algorithms. Even the pictures that were used seem almost childlike. Some of the chosen algorithms were interesting, some were a little boring. The last chapter on what is computable was way too long and mostly uninteresting. Having said that, for those who have never before experienced, or had exposure to, algorithms and/or the science of computing there is something to be found here.

The Kindle version wasn't really up to scratch. For example big chunks of chapter 10 were centered rather than justified making it surprisingly hard to read and the imagery was almost impossible to digest in some points. I'm sure the experience of the physical copy would be better.

On the whole, not a bad read, but not recommended for geeks who already have a background in algorithms.",29
Rusty,5.0 out of 5 stars,Artificial Intelligence for Games,Excellent and approachable,"The vast majority of software development books, whether it be for line-of-business app dev or game development, seem to have little to no information that can be found via a casual internet search.

This book is one of the few exceptions. There is a refreshing breadth and depth of game AI knowledge in this book that has been of tremendous help. Unlike the common ""Gems"" series of books, this book contains enough information on nearly every topic for the reader to build a 'ground up' implementation of their own.

My only complaints are that the pseudocode seems to be overly simplified and not as easily converted to a concrete implementation as I'd like, and that even for a book on game-specific AI implementations, the authors seem to enjoy a bit more of an academic/idealized approach to the design. That might be less bothersome to a professional game developer, but I'm at the hobbyist/indie level, and sometimes need a quick-and-dirty implementation before I begin to really understand what's going on.

Having said that, I was able to use the book to learn about and implement goal-oriented action planning, fast and flexible A* path finding (with additional info on modified funnel algorithm online), and several other critical components.

I would absolutely recommend this book.",29
Dave,1.0 out of 5 stars,Alan Turing: The Enigma,Very technical. Turing gets lost in the wiring.,"If you want to know about only Alan Turing the man, this book is not for you.
Hodges spends far too long on the technicalities, circuitry, and internal workings of the Enigma machine, the inner workings of the ""Bombe""s used to help break the code, and the society and culture of war-time and post-war Great Britain. Turing, the man who paved the way for developing our modern-day computers is lost, and almost forgotten, in the technical minutae on which Hodges spends page after mind-dulling page.

The sections on Logic were interesting to me, but only because one of my undergraduate minors is in Logic, but I'm not sure how enlightening they would be for those not familiar with it.

You've got to give Hodges an A for effort, though. The tome is thoroughly researched, footnoted, and attributed. Turing becomes a minor subject in may chapters, though.",29
Luap Rewop,1.0 out of 5 stars,Alan Turing: The Enigma,Tiny print,Tiny print makes this extremely difficult to read. Perhaps that's why the only samples shown in the looking inside are from the Kindle edition. This isn't a comment on the content of the book because I couldn't read it. I'm commenting anyway because potential buyers should know what the physical qualities of the book are.,29
Nikita,4.0 out of 5 stars,Deep Learning (Adaptive Computation and Machine Learning series),Free version of the book available.,"On the accompanying web-site, there is an easy to print ""HTML"" version of the book. They don't have PDF version, because of the contract with MIT that forbids it, but what they have to print is even better. It's free, obviously.",28
Andres C. Salama,3.0 out of 5 stars,Code: The Hidden Language of Computer Hardware and Software,"Good, semipopular book about how computers work","I'm sure many people, faced with a computer (or another high tech gadget) wonders how it really works. Parts of its functioning are explained in the popular press, but you almost never get the whole picture: to many people (even highly educated people) the functioning of a computer must be something akin to magic. Petzold's book tries to remedy this by trying to explain how the computer works from the bottom up. The book is fascinating stuff, and is easy to follow at first. He easily explains concepts such as the binary code, logical gates, switches, the merging of boolean algebra to electrical engineering (this was first considered in a master theses by Claude Shannon, and its probably the great breakthrough that led to modern computing), the roles of transistors, microprocessors, etc. Inevitably, the complexity rises in the later chapters, and if you are not a physicist or an electrical engineer, you would be unable to understand everything. But it is nevertheless a good, recommended read.",28
L. W. Noronha,3.0 out of 5 stars,Code: The Hidden Language of Computer Hardware and Software,A laudable effort. But the book is an enigma.,"A commendable effort. But I couldn't tell if Petzold set out to teach an introductory computing course to the non-technical reader or if he meant to include everbody. In either case, he will probably disappoint both camps. He is best when he introduces a topic with fascinating insights. But then he cannot resist giving computing lectures that are best left to a text book. A discussion of edge-triggered D-type flip flops and timing diagrams don't belong in a popular book.
In the chapter on ""Two Classic Microprocessors"" I was hoping for a comparison of the Intel and Motorola architectures and how Motorola lost to Intel in the marketplace despite having a more elegant architecture. Instead, we get a boring treatise of the two instruction sets and sentences like ""The 6800 doesn't have a Parity flag like the 8080, but it does have ... an Overflow flag"". He might have been forgiven if he was using it to make the CISC vs. RISC case. Instead RISC gets only a cursory mention.
I still like the book as a reference.",28
missir,3.0 out of 5 stars,"G??del, Escher, Bach: An Eternal Golden Braid","Dilettantish, but may be good for teenagers","I would certainly have been facinated by this book if I had read it soon after it appeared but not 20 years later. There is a lot inside to stimulate the imagination of a teenager. Unfortunately, for anyone with a formal education in some of the subjects touched upon, it is too clear that the work was written by a passionate dilettante.",28
Scott Davies,5.0 out of 5 stars,Pattern Recognition and Machine Learning (Information Science and Statistics),If only all textbooks were this well-written,"I was a big fan of Bishop's earlier ""Neural Networks for Pattern Recognition"" despite my not being particularly interested in neural networks (as opposed to other aspects of machine learning), and so I was pretty excited when I heard about this book. Reading it has not left me disappointed. Like his earlier book, this text is quite mathematically oriented, and not well-suited for people who aren't comfortable with calculus. However, also like in ""NNPR"", the writing style here is very clear, and everything past basic calculus and linear algebra is well-explained before it's needed. The appendices alone are a goldmine. (Appendix B is a great ""cheat sheet"" for commonly used probability distributions; Appendix C has lots of useful matrix properties you may have forgotten or never known; Appendix D quickly explains what you need to know about the calculus of variations; and Appendix E does the same for Lagrange multipliers.) The author also does an excellent job throughout the text of marrying math and intuition without giving either short shrift.

However, note that the material covered is inherently pretty complex, so the book can still be intimidating in parts despite the excellent writing. It's more appropriate for, say, Ph.D. students and professional researchers in statistics or machine learning than people who just want to crank out code for a simple classifier. There is very little pseudocode (although copious MATLAB code will supposedly be made available in a companion book due out in 2008), and the book's overall approach to machine learning is basically hard-core Bayesian statistics. If you are not willing to scratch your head for a while over lots and lots of equations, this may not be the book for you.

On the flip side, people who are already experts in machine learning may be mildly disappointed with the lack of coverage some of their pet topics get. For example, while the chapter on graphical models is excellent as far as it goes, it only mentions the problem of learning graphical model structures (one of my areas of interest) in passing. Reinforcement learning (another personal area of interest) is discussed briefly in the introduction and then written off as beyond the scope of the book.

However, the book is already a fabulous resource as it stands; complaining there's not even more of it would be gauche. The cover may look like goat barf, and there are some innocuous missing words here and there (hey, it's a first edition), but if you're serious about machine learning and not afraid of a little math, you should definitely own this book. I can only imagine how much cooler my own thesis research might have been if this book had been around a few years earlier.",28
Richard of Connecticut,5.0 out of 5 stars,The Singularity Is Near: When Humans Transcend Biology,An Absolute Gem of a Book,"Ray Kurzweil is a national treasure, a man who thinks at the level of Einstein but only 50 years later. There are a number of people like Kurzweil walking around on the planet. You have to search for them. When you find them, try to learn everything you can from them. They will help you move exponentially to the next level. He is a solitary thinker, operating on the outer limits of human knowledge, and then some.

I have read his other books, and in many ways, this book is the sequel to ""The Age of Spiritual Machines"". What Kurzweil is writing about in this book is his belief that we are moving towards s UNION if you will, of human intelligence and machines or objects that will have equal and eventually superior intelligence. Is this the goal of the people who spend their lives working in Artificial Intelligence, probably?

The difference is that Kurzweil knows so much more than his fellow thinkers, and more importantly for us, he has the capacity to convey it to those of us who are not full-time players in his arena. This quality of information conveyance is a vastly underappreciated skill. In my work investing billions of dollars in stock investments, I have access to just about anybody I want, because I have the capacity to write a check. You have no idea how many actual geniuses I deal with who CAN'T speak, let alone write the English language.

Kurzweil is different. He can get these concepts across to us in an interesting language spiced with stories that we can all understand. He does not visibly suffer from the ego needs of most geniuses. He is comfortable in his own skin, and that feeling is conveyed to us also.

Due to his position in the exalted world of the super Mensa types, Kurzweil can also access the top minds of who's doing what in the world today. Men who run Fortune 100 companies are more than willing to share the knowledge of their research departments with this famous thinker.

At the upper levels of the Central Intelligence Agency, the National Security Agency, and the Defense Department are some of the smartest people on the planet working on Artificial Intelligence, and edge-of-knowledge sophisticated computer applications. Kurzweil is in a position to interact with all of them, and this accounts for why much of what he writes about appears nowhere else.

He also brings something else to the table. He is a very successful inventor and entrepreneur who is now independently wealthy. He knows what works in what environment, and what doesn't. He knows when something is being brought to market too early, or way too late. In the book he states, ""I realized that most inventions fail not because the R&D department can't get them to work, but because the timing is wrong. Inventing is a lot like surfing: you have to anticipate and catch the wave at just the right moment."" I am an investor; I have never heard it said better.

His concept of his ""intuitive linear view of history"" is absolutely fascinating, and compelling. He believes that the rate of change is accelerating. For years we have all heard the concept that the only constant is change. Kurzweil believes the calculus is changing. We have already entered a world where we are witnessing a dramatic change in the rate of acceleration of change.

Just ten or so years ago, cell phones had minimal impact. The Internet was nowhere near the adaptive state it is in today, and universal information flow did not exist. There were no bloggers, traditional media dominated, and people were more easily lied to by politicians with impunity. Things are changing aren't they?

Here's the bottom line on Kurzweil. Most of the time you read a book to take one major thought out of the document. Sometimes it's a single page; sometimes it's a single line. Occasionally, you find that rare book where there is something on every page that is outstanding, motivating, even framework changing. This is such a book, and therein lays its importance.

There's one more reason to read a book like this. Do you remember when Ross Perot ran for President? One of the metaphors he used to refer to was a story of the carpenter he knew. The words were ""Measure twice, cut once."" This is an example of what I call the need to be mentored. There are people that can teach you things that if you spent 20 years studying the topic, you would never learn. The carpenters' of ""Measure twice, cut once,"" is an example of that.

When you read Kurzweil, you are eliminating the need to read hundreds to thousands of other books. There is knowledge on every page for you to absorb and ponder. Buy this book, and have an orgasm of the mind.

Richard Stoyeck",28
KimoKailua,3.0 out of 5 stars,How to Create a Mind: The Secret of Human Thought Revealed,Not as good as previous work..,"I'm a big Kurzweil fan and I particularly liked ""The Singularity is Near"", so I was looking forward to this with great anticipation. Therefore I was surprised to find many chapters to be nearly unreadable. The language becomes ponderous and technical and when the author had to make a word choice he invariably chose the most obtuse or technical. The obtuse language and description takes away from the power of his arguments which are quite convincing. I recognize that some of the areas require technical language but that doesn't excuse the lack of editorial choice. If he wants a wider audience for his work, he should consider finding a good science writer to assist with this. He's obviously so bright that he may not be aware of the flaw that his general readers would prefer more accessible work that isn't quite so painful to read.

Pros:
*clearly and convincingly makes the case for human level machine intelligence within a reasonable timeline
*clearly and convincingly dismantles the contrary arguments of his many critics

Cons:
*overly technical chapters in some areas
*unnecessary obtuse language and opaque sentence structure make some chapters nearly unreadable

Summary:
Can't recommend this for a general audience. You really have to want to read the book to wade through. If you have a predilection towards technical or academic literature, this will undoubtedly be fine.",28
john kane,5.0 out of 5 stars,Make Your Own Neural Network,I haven't found anything like it.,I'm a retired sociology PhD trying to make sense out of machine learning and AGI with 50 years since my last math class. This book is remarkable for its clarity and coverage of the subject....I haven't found anything like it.,28
Philip H.,3.0 out of 5 stars,Machine Learning with R - Second Edition,There are some useful gems in this book,"I'm torn. There are some useful gems in this book, and for the most part, the presentation is simple, albeit a bit pedantic and cartoonish at times. If I was trying to get up to snuff on a new machine learning method, I might start here, since it *does* provide starter code for a variety of problems. That's quite handy. It doesn't, however, go into much depth at all on any one topic. You can't read this book and expect to know how to do any one of these methods well. Certainly, it's a tall order to ask any one book to cover all ML topics in depth, but any potential reader should be aware that this just skims the surface of a whole bunch of topics.

On top of this, who in the world edited this book? Every other page has horrible typos, missing words, repeated sentences. These are not trivial errors either. This is a book about data analysis and yet the reported data are clearly wrong in places, e.g., a result is listed as .06 percent in one spot and then .0006 in another (p. 271). Basic subject-verb agreement errors riddle the text, e.g. ""These output is shown as follows"". Sometimes these are trivial errors, but other times you have absolutely no idea what the intended meaning is. I have about 100 pages more to read but I'm starting to wonder if I'm just wasting my time.",28
Life long learner,5.0 out of 5 stars,Machine Learning with R - Second Edition,Excellent book,"This is a great book. I liked the way authors highlight syntax for models and discuss strengths and weeknesses. It has a nice balance of theory and hands-on training. However, I would need to use a R book, such as R in action, in conjunction with it.

I have looked at many books on the topic. I will put my review for all of these. Perhaps this can save you some time.
1) http://www.amazon.com/dp/0470650931 : Good theoretical book, but badly written and does not have any hands on exercise.
2) http://www.amazon.com/dp/1466503963 : This is another great book. Good balance of theory and hands-on exercise. This is an excellent book to start learning data mining and R. However, this book relies on a GUI RCommander. It does a good job and one can do a lot with it but it has its limitations. However, I will still use this book.
3) http://www.amazon.com/dp/1439810184 : This is an advanced book and heavily entrinched in cases. This makes it difficult to replicate things unless your work is directly related to one of the case studies covered.
4) http://www.amazon.com/dp/0133412938 : Good examples, but does not explain much about the interpretation. This leaves one wondering what is the purpose of certain graph, what are the axis and how to interpret it. if appropriate explanation is added, this would be an excellent book.
5) http://www.amazon.com/dp/111844714X : This book is very expensive and almost totally devoid of any theory or discussion. I would not use it.
6) http://www.amazon.com/dp/1441998896: This is a decent book. It relies on another GUI, Rattle. It is a strong contender to the book 2 in this list.",28
Paul R. Adams,3.0 out of 5 stars,On Intelligence,"Approach excellent, but details need work","This is an important book, though perhaps not for the reason the author intends. It's important because it forcefully advocates a view that most neuroscientists have, for various reasons, shamefully neglected: the neocortex is built to understand the world. It has rather distinctive and puzzling circuitry and physiology which is repeated in all areas and all mammals, and which somehow equip it for the general task of learning about an animal's world. Furthermore, the central task of neuroscience is to explain how this basic machinery works, by combining insight from experiment and theory.

Most neuroscientists think that different cortical areas, since they are clearly solving completely different problems (vision, audition, movement etc), which require completely different solutions, must operate quite differently: there would be no ""canonical"" cortical operation. Confronted with the overwhelming evidence for a standard circuit, they tend to dismiss it as an insignificant evolutionary vestige, like the navel, or else to shift the conversation to the undoubted variability of the wiring (the ""fluff""). This approach is reminiscent of the way that biologists operated before Darwin.

A sizeable minority of neuroscientists does like the idea of a ""canonical circuit"" but none can agree what it is. The mistake they make is in trying to decide what is ""canonical"" without focussing on what is ""distinctive"". Many features of the neocortex (eg recurrent pathways) are also found in other brain areas (especially hippocampus and olfactory cortex). Adding these to the canonical recipe enormously complicates, and confuses, the task, and tends to hide the important things.

In a nutshell the distinctive features are: 6 layers, thalamic input (with burst/tonic transitions), slow/REM sleep, subplate waiting, inside-out development, and, especially, layer 6 connections. Hawkins touches on some of these things, but doesn't really seem at home in the cortical basement and attic.

The weakness of the book is in the more detailed speculations. The ideas are not rubbish, but they are (somewhat inevitably) not sufficiently clearly described. The biggest problem is that they are not linked to previous work, so that the reader has to struggle to understand the new stuff. The point here is not that Hawkins fails to be courteous or ""academic"". The point of extensively citing and explaining old ideas and findings is that this is the only way to explain new concepts. Hawkins is not trained in these areas, but he's smart and can travel lightly, without much academic baggage. But necessarily the ideas he is explaining are rather tricky, and the best way is to rely on shared knowledge. I suspect that if he made greater efforts to place his ideas in the context of previous work, he could also greatly improve his model.",28
Mario Schlosser,4.0 out of 5 stars,Probably Approximately Correct: Nature's Algorithms for Learning and Prospering in a Complex World,Great thought starter on applying machine learning to evolution,"In short: whether you're a computer scientist familiar with machine learning algorithms, or whether you don't know much about artificial intelligence, this book has profound and novel insights to offer. I've been a practitioner of machine learning for a long time, and yet the book's framework relating machine learning to evolution gave me a whole bunch of ""aha"" moments. So pick it up and give it a read.

The book's thesis in a few words: cognitive concepts are computational, and they are acquired by a learning process, before and after birth. Nature, the grand designer, uses ecorithms to guide this process - systems whose functioning and whose parameters are learned and evolved, as opposed to written down once (like algorithms). The processes of learning, evolution and reasoning are the building blocks of ecorithms.

This, in and of itself, is not a new framework. Open any artificial intelligence textbook, and the table of contents will be organized into algorithms for ""learning"" and ""reasoning"". So nothing new there. But then, the book launches into an excellent, simple and mind-blowing thought experiment: what if nature were simply relying on the same simple learning algorithms that we as humans have been researching, with the same constraints - and evolution is just that formal learning process in action? And then: given all we know about the parameters of these learning algorithms, would evolution have been mathematically possible?

To answer that, the author goes into some detail on computational complexity theory. Computer science has shown that there are many seemingly simple processes that aren't solvable in polynomial time - meaning, if you make them big enough, solving them will take longer than the universe existed. The question of the shortest overall path in visiting all cities in a particular geography is such a problem. So if it is so easy to mathematically prove that so many really simple problems aren't solvable in the time the universe existed, how would it even be remotely possible that evolution build something as complex as the human brain in an even shorter time frame?

The book then essentially explores areas of machine learning just deep enough to show that it probably would be possible. There are enough real-world functions of the ""probably approximately correct""-learnable class that are learnable in polynomial time, and algorithms that do the learning that we already know (and use) today, that it's imaginable that nature relies on variants of those. The book has some strong tidbits it throws out in the course of discussing this. For example, it turns out that parity functions (deciding, without counting, whether something is odd or even) aren't PAC-learnable. So far, so satisfying a read.

One of the book's drawbacks is that a lot of the details are left open. In the author's thesis, the genome and our protein networks somehow encode the parameters of the learning algorithms nature uses. But of course we have no idea how that actually happens (and the book doesn't pretend that it knows). Another drawback is that the book seemingly can't quite decide on its audience: is it pop science or more serious work? It oscillates strangely between being very concrete and being hand-wavy: for example, when discussing the limits of machine learning (semantics, brittleness, complexity, grounding), there isn't anything offered in terms of why machine learning is so brittle (just try Apple's Siri). It also somewhat casually throws around ideas that are mind-blowing but totally unproven: for example, it is known that our working memory can only hold 7 +/- 2 objects at any point in time. The author argues that this is by design, so that the subsequent learning algorithms have an easier time picking up features. That's a pretty cool line of thinking, because it would suggest that nature uses the same heuristics that we as computer scientists use when tackling a learning problem (reduction in features and dimensionality). But it's also totally unproven that THIS is why we have limited working memory, or that THIS is what it does. The book also doesn't go into any depths on learning algorithms we already know, even though a lot of the known algorithms actually have pretty simple intuitions underlying them that could nicely be treated for a non-computer science audience.

But overall, there are some awesome thought starters in this book. It is not always an easy read. But certainly worth it.",28
Philip H.,3.0 out of 5 stars,Machine Learning with R,There are some useful gems in this book,"I'm torn. There are some useful gems in this book, and for the most part, the presentation is simple, albeit a bit pedantic and cartoonish at times. If I was trying to get up to snuff on a new machine learning method, I might start here, since it *does* provide starter code for a variety of problems. That's quite handy. It doesn't, however, go into much depth at all on any one topic. You can't read this book and expect to know how to do any one of these methods well. Certainly, it's a tall order to ask any one book to cover all ML topics in depth, but any potential reader should be aware that this just skims the surface of a whole bunch of topics.

On top of this, who in the world edited this book? Every other page has horrible typos, missing words, repeated sentences. These are not trivial errors either. This is a book about data analysis and yet the reported data are clearly wrong in places, e.g., a result is listed as .06 percent in one spot and then .0006 in another (p. 271). Basic subject-verb agreement errors riddle the text, e.g. ""These output is shown as follows"". Sometimes these are trivial errors, but other times you have absolutely no idea what the intended meaning is. I have about 100 pages more to read but I'm starting to wonder if I'm just wasting my time.",28
Life long learner,5.0 out of 5 stars,Machine Learning with R,Excellent book,"This is a great book. I liked the way authors highlight syntax for models and discuss strengths and weeknesses. It has a nice balance of theory and hands-on training. However, I would need to use a R book, such as R in action, in conjunction with it.

I have looked at many books on the topic. I will put my review for all of these. Perhaps this can save you some time.
1) http://www.amazon.com/dp/0470650931 : Good theoretical book, but badly written and does not have any hands on exercise.
2) http://www.amazon.com/dp/1466503963 : This is another great book. Good balance of theory and hands-on exercise. This is an excellent book to start learning data mining and R. However, this book relies on a GUI RCommander. It does a good job and one can do a lot with it but it has its limitations. However, I will still use this book.
3) http://www.amazon.com/dp/1439810184 : This is an advanced book and heavily entrinched in cases. This makes it difficult to replicate things unless your work is directly related to one of the case studies covered.
4) http://www.amazon.com/dp/0133412938 : Good examples, but does not explain much about the interpretation. This leaves one wondering what is the purpose of certain graph, what are the axis and how to interpret it. if appropriate explanation is added, this would be an excellent book.
5) http://www.amazon.com/dp/111844714X : This book is very expensive and almost totally devoid of any theory or discussion. I would not use it.
6) http://www.amazon.com/dp/1441998896: This is a decent book. It relies on another GUI, Rattle. It is a strong contender to the book 2 in this list.",28
Nikita,1.0 out of 5 stars,Cognitive Computing and Big Data Analytics,Watery water,"There is no ""how"" in this book, there is no detailed guidance, there is no guidance at all. First I thought that it might get 3 stars just for being an encyclopedia for dummies with no interrelation between entities. No, it's not even that.

Here is one phrase you pay for buying this book, it's located on page 71: ""[cognitive computing] is analogous to the way a child learns about the world through observation, experience, and perhaps instruction"". There is nothing before that phrase in the book, nothing (new) after. There is no ""how"" besides a lot of hand weaving, speculations, stating obvious facts (sometimes), and a LOT of water in between. A lot. Just plain water, no information at all.

Maybe not surprisingly, the authors wrote more than 5 books together in the ""For Dummies"" series. I would argue that even book for a ""dummy"" have to have some knowledge synthesis, some information, and most of them do.

This book is just a fake. A rip off?",28
Scott P. Stewart,5.0 out of 5 stars,Knowledge Representation and Reasoning (The Morgan Kaufmann Series in Artificial Intelligence),Don't have to be a math buff to understand,"I came across this book looking for a text that would explain the context of First Order Logic, why it is used for so many knowledge representation problems, how it is used to solve them, and its limitations. I must say that this is far and away the best book I've found to answer these questions. If you search around a little at the competition, you will find much of the text quickly turning to mathematical proofs and deductions in their explanations. While this is of course necessary and helpful, it doesn't (for me) really give an idea of how and why these methods are used practically. You can tell that these authors spent some time on ensuring consistency and fluency of the writing, which I find so very helpful.

I'm trying to think of something bad to say about it: I wish it were longer! If you read the preface you will see the authors call it an introduction, which is definitely true. Maybe they will team up again for a more in-depth text on some aspect of this subject.",28
Sean A. Fulop,3.0 out of 5 stars,"Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics and Speech Recognition",Needs a second volume which explains the first,"This book is by now an accepted classic in the field. It is basically the only textbook that covers so much of computational linguistics, so I have had no choice but to use it for the past several years. Just the same, I'd rather not use it for teaching linguistics students. While the book has much to offer the professional, including a broad range of topics extensively researched, it is much more useful in this ""handbook"" capacity than as a textbook for the uninitiated. The chief reasons for this are: 1) It is pedagogically very poor; the majority of concepts are either explained in a confusing and obfuscatory manner or are not explained and are simply left in algorithmic form. This is not usually edifying to the linguistics student with no computer science background. 2) There are too many mistakes in its algorithms and method overviews. So far as I can see, even the famed Earley parsing algorithm is wrong here, it will not yield the correct output. 3) It is not written in a language that linguistics students can understand. With no background in mathematics, computer science, or pseudocode, such students need much more coddling than is provided by this book, and they are virtually unable to read it. Basically, as the title to this review states, what is called for now is a book to explain the contents of this book. Perhaps if my students keep encouraging me to write it. . .",28
Richard G.W. Kenyon,4.0 out of 5 stars,Blondie24: Playing at the Edge of AI (The Morgan Kaufmann Series in Artificial Intelligence),Best AI Story to date,"Story is full of good scienctific thought and contains enough meat to interest someone learning about AI. If you're familiar with some of the technology you'll race through the first half quickly, but the progression of blondie in the second half is well worthwhile for the excitement of the challenge they set themselves and also the psychology of their opponents. A little bit pricy for the size, but good value for the content, and if you're really interested you'll probably buy it anyway.",28
Eddie G Powers,5.0 out of 5 stars,Amazon Echo: Master Your Amazon Echo; User Guide and Manual,Great Book,Great book. Very helpful.,27
Romann M. Weber,3.0 out of 5 stars,Machine Learning: A Probabilistic Perspective (Adaptive Computation and Machine Learning series),Slowly Converging to a Very Good ML Book,"""Machine Learning: A Probabilistic Perspective"" is truly ambitious in its scope. A major selling point of this work is that it covers material, such as deep learning, that other large surveys leave out. There are also some genuine insights in the book. A new perspective is always welcome in this growing technical field, and Dr. Murphy appears to have a lot to offer here.

However, the book suffers in its current form (my copy is the second printing) from the author's and publisher's hurry to get it in print. (The author admits, on the site devoted to the book, that such a rush existed.) The result is a book that, as other reviewers have noted, is less than perfectly organized and riddled with typographical and technical errors.

The errata notes on the author's site suggest that the third printing will be much improved over the first and second (including, among other things, an essentially rewritten chapter). My guess, though, is that it will take a good few years before the book's errors are altogether extirpated. (Aside: Why is it nearly impossible to determine the current printing of a book before you're actually holding it in your hands? This is pretty important if you're trying to get the cleanest copy possible.)

This book has all the ingredients of a five-star ML text. At the moment, though, it is hard to justify more than a three-star rating (especially given its hefty price). I suspect that my ultimate rating will be a function of the book's printing number, its exact shape depending largely on the diligence of the publisher, the author, and his readership.",27
William P Ross,2.0 out of 5 stars,Introduction to Machine Learning with Python: A Guide for Data Scientists,Plauged by broken code and poor explanations,"I started determined to go through all the code samples in this book.

The book starts with only four sentences about the Jupyter notebook although is the main environment for the whole book. The first code sample shown starts on line two of a cell, and it was very strange there was no line one. I was wondering if there was some type of misprinting.

The code as printed is broken on page 10 where there is a line with 'display(data_pandas)'. This line gave me an error that display was unrecognized. I thought maybe this was a built-in Jupyter function so I went online to search. Eventually, I had to go to the author's GitHub and ask about this problem where I was told that he simply forgot to include 'from IPython.display import display'. It was a surprising admission because he did not say there was a misprint or mistake, but simply that he forgot to do that. It is very obvious there were zero technical reviewers for this book, because they would have also noticed the broken code right away.

On page 11 we are introduced to a library called 'mglearn' which is a utility function that authors say they wrote for the book. Strangely, this repository has 733 stars on GitHub so it is obvious the library is not just for the book. Then in chapter two the author has tons of calls to mglearn which take in multiple parameters. The parameters are never explained and you have to go to the author's GitHub to see what the code actually does. In the 2nd chapter multiple of these mglearn calls broke for me. One seemed to be a conflict with numpy, and another I never figured out. I went to look at dicussions on mglearn to discover it is still a work in progress and there were sections where somebody was notifying the author that something was broken, and the author replying that he would look at it soon.

The second chapter has 120 cell entries for supervised learning techniques. Each cell has roughly 5-10 lines of code, so there are nearly 1000 lines of code for the second chapter and they are all tossed into one gigantic Jupyter notebook. Explanations are very weak often defaulting to a brief description followed by code and then more code. Function calls and parameters are rarely explained at all.

The last chapter is about natural language processing which is the machine learning subject I am most familiar with. Terms are often introduced with zero effort to define them, and it is assumed you already know many of the concepts. TF-IDF barely had any explanation at all, except to show the forumla for it. You can find much better explanations online.

For a book which is so heavy on code and light on explanations, it is unacceptable that the code is broken.",27
T SANTOSO,5.0 out of 5 stars,The Psychology of Judgment and Decision Making (McGraw-Hill Series in Social Psychology),A lot of materials in this Great Book,"This is a very dense book, relatively easy to read, and very2 helpful. I love Blink and The Tipping Point, but this book probably has much much more materials, arguably more than 5 times of inside that those two best sellers combined.

I am very interested in the popular psycology stuffs, and Influence by Cialdini is my fav. So this book in some way give you the same chockful of surprises and new insight that will change the way you think.

I came across recomended by a University of Chicago MBA -email friend- who has much similar books favourites and he recomended this highly, and i absolutely agree and i would be glad to recommend this to anyone interested in human behaviour and psychology of bias.

MBA students should read this one and surely will enjoy this. I always draw, marks and put notes on my book and i think i end up marking so much of the materials.

Section one: Perception, Memory and Context

Section two: How Questions affect answers

Section three: Model of Decision making

Section Four: Heurictis and Biases.

Section five: The Social side of judgment and decision making

Section six: Common traps.

Some will complain that this book derived from a lot of previous psychological research, i agree, so for the psychology veteran out there, this might not the right book for you, but for most of us, this book will enlight, entertain and amuse us all...",27
Daniel Garcia,2.0 out of 5 stars,"The Age of Em: Work, Love, and Life when Robots Rule the Earth",Disappointed.,"As an economist interested in AI, this book appealed to me greatly (so I pre-ordered it). I was extremely disappointed. I found it poorly written and badly organized (e.g. in the 'Implementation' Chapter the author discusses the possibilities of Mental Theft before describing the required Hardware).
The style of the book is as follows. Use a combination of Physics, CS and engineering on the one side and observations about our world on the other to predict the environment in which EMs will live. These conclusions are often unwarranted. For instance, we learn that cities today induce productivity gain according to a power of its size and that the cost of cooling down em cities will be logarithmic in its size. From this, the author concludes that there will be mega-cities, without explaining which are the gains from agglomeration in cities and whether these gains will be present in Em cities (faster interactions seem to matter little for reasonably large areas).
What I found most puzzling is the simplified theory that the author holds about the current world. He claims that the efficient world would have no differentiation or variety because of economies of scale, assuming that almost anything that pushes to individuality is a maladaptation. Individual values, therefore, are also a maladaptation and he even argues that Ems will be more religious because individualism is related to atheism (so is culture and scientific knowledge, which Ems presumably will have in bunches).
Overall, one of the worst pop-science books I have ever read.",27
Yung-Hsuan Chao,5.0 out of 5 stars,Understanding Machine Learning: From Theory to Algorithms,Excellent book based on statistical learning theory,"This book provides a great story line along with solid proofs of machine learning theories and algorithms.
Each chapter is rather short (15-20 pages), yet is well written to convey the topic in detail, making the book comfortable to read.
Moreover, the connection among consecutive chapters is strong, giving an excellent coarse-to-fine introduction on sophisticated theories.

Over the past few years, I have read several machine learning books, and this is the one solidly based on ""statistical learning theory"".
Compared to other books that give only brief description to this aspect, this book does a good job not only on providing the basic proofs, but also on extending the theories to well-known practical algorithms, supporting the success of these algorithms and showing how theories can be used to design or analyze practical algorithms. For whom eager to know more about learning theory, this is a must-read book.",27
Mike,4.0 out of 5 stars,Write Great Code: Volume 1: Understanding the Machine,The computer book you'll NEVER read..,"If you're like most IT people out in the workforce today, you've got pressures from all sides - deadlines, keeping current with changes in platforms, hardware, software tools, etc. Gah! It never ends!

So, you pick up these ""Write Great Code"" books, thinking that you'll be a better programmer.

And it's interesting in a way that you remember when you were just getting into the IT field as a student and later as an employee and maybe now as a consultant or contractor.

But, then you realize that this is like thinking about how your car's components are working while you're driving madly to work on some beltway. Only your skills as a driver can keep you from getting hit by a big semi, not the working knowledge of your V8 engine. Guys who work on their cars on the weekend, know more about them than you do, but hey, it gets you to work and back.

And so, you sigh and put the book down and concentrate on your SQL, or your VB or whatever else keeps you employed.

Why?

Because your users and your manager don't care about what goes on at the machine level. They want the deliverables NOW. The efficiency of your code is of no importance to them, though it is to you.

However, with enough discipline and some thought to what you're doing, you CAN make this book work for you, and get an edge over someone else's sloppy code and maybe even save yourself some programming time.

Because this book is for the guys who are the computer counterparts of the greasy-looking guys on the street who could tell you what's wrong with your car, even if you can't.",27
RHV,2.0 out of 5 stars,Machine Learning in Python: Essential Techniques for Predictive Analysis,Code implemented is poor. Explanation of algorithms is good.,"I have no idea why the author didn't implement pandas or numpy instead of devoting pages to reading csv files with base python. He chose to store data in lists of lists. Why??? He chose to normalize and store data ""the ol' fashioned way"" instead of using numpy arrays. This makes the code less readable. (Seriously, every example begins with several lines of code simply to read the data, loop through each line, split on a "","", append to a list, etc. Using pandas' read_csv or numpy's genfromtxt code have accomplished the same thing in one line!)

The author does say, however, that he included a lot of code to help explain how the algorithms work. This is actually helpful--when it relates specifically to a machine learning algorithm. He subsequently makes use of scikit-learn objects in the examples, as he should.Why he didn't follow the same approach when reading CSV files, I have no idea.

My recommendation is as follows. If you're looking for code to implement, I would not use this book for proper examples. If you're looking for an explanation of penalized regression and ensemble algorithms, this book is pretty good for that purpose in my opinion.",27
Un francais en angleterre,3.0 out of 5 stars,Knowledge Representation and Reasoning (The Morgan Kaufmann Series in Artificial Intelligence),"Ok, but not enlightening","I own an old edition of the classic Russell and Norvig (R&N) which I read 10 years ago and did not feel like going through the huge new 2009 edition to learn about current topics, so I went looking for something a bit more recent with a focus on knowledge representation, and came up with this book. I have to say unfortunately that while not a bad book, it does not cover much more than the old R&N (side note on this: R&N is very comprehensive and covers the full AI spectrum. This book seems biased toward one particular school of AI. This may or may not be bad for you: if you're not interested in the additional material in R&N, such as neural nets, you're possibly better off with this book. I doubt there are many of you in this case though) and tends to be less pedagogical. It is also more uneven regarding the depth at which topics are covered, with a fairly strong bias toward the topics where the authors appear to be active researcher. Such a bias would be ok for a more advanced textbook, but we're talking about a fairly introductory text here, and it feels a bit unbalanced. I cannot therefore recommend it highly, but I am not highly critical either, as I still managed to learn a couple of things. Below are detailed notes, which I hope might be of interest to outline the stronger points. As a side note, this is a very theoretical book, with no direct programming application or exercises. This did not bother may, but may not be clear from the other reviews.

The introduction sets the scene well and provides a useful conceptual background. How the following chapters are articulated against the principles discussed in the introduction is not always straightforwardly clear though. In that sense, the authors may fall a bit short of their overall goal.

The second chapter (the language of first order logic) is unlikely to be big news for anybody schooled in undergraduate mathematics, but I understand the material must be included for the sake of completeness and autonomy. The third chapter is entitled ""expressing knowledge"" and in my view does not really do justice to the topic, as demonstrated by the matter covered in the afterthought section ""other sorts of facts"": these ""other facts"" include statistical and probabilistic facts, default and prototypical facts, intentional facts (beliefs etc...). The book deals with some of these later to be fair.

At this point in the book, all that has been achieved is to show how one can use first order logic (FOL) to deal logically with some problems that a six years old can probably solve without the need for the framework. Chapter 4 shows that it is possible to teach FOL to a computer and to have him assess the truth of a statement formulated in FOL given a number of others FOL statements. The algorithm is not completely trivial but not overly complex either. Unfortunately, the time taken to deal with such tasks is potentially very large for problems not amazingly complex if one allows FOL statements of arbitrary structured. Chapter 5 is dedicated to the exploration of Horn clauses, which are basically a type of FOL statement for which algorithms are available that converge faster. This motivates the need to embed some hints on how to reason with a given problem within computer languages. Chapters 6 and 7 explore this respectively in the context of PROLOG and of the so-called ""production rules systems"". As one gets familiar with the above approaches, a number of limitations become clear and the subsequent chapters are about moving away somewhat from FOL. Chapter 8 introduces object oriented representation, using a formalism a bit on the heavy side for a concept that's actually fairly clear. Give or take a few examples, a reader of R&N is on familiar ground up to this point in the book. The next chapters, respectively on description logics and inheritance cover material that was less familiar to me and might be a reason to dig into this book. It shows a couple of neat ideas (taxonomies, inheritance networks) and how reasoning with such data structures can be difficult when one encounters contradictions. This motivates the need to clarify the concept of ""default"", which is done in chapter 11, another good chapter in my view. Chapter 12 includes an introduction to probabilities that probably ranks with chapter 2 as something most readers don't really need. It also covers fairly superficially bayesian networks, influence diagrams and the Dempster Shafer theory. In all honesty given the brisk pace at which this is all done, I don't think it's really possible to get much out of what's covered here.

The concepts in the next chapter (Explanation and Diagnostic) were newer to me. While not straigthforward to implement, it seems the core approach of the authors is here at an advantage over other more opaque techniques.

The next two chapters (""Actions"" and ""Planning"") deal with topics that are closer to the preoccupation of standard AI. As they're both good topics to motivate the AI endeavour, introducing them earlier might have made more sense.

The last chapter is about ""the tradeoff between expressiveness and tractability"". The authors look back at the big picture that had been evoked during the introduction, but which had to some extent taken the back seat during most of the time. Fairly uncontroversially, they point out that being able to deal with very expressive languages is desirable, but typically fraught with tractability issues. One senses that the

PS: I bought the Kindle edition of the book, and as unfortunately too frequent, it suffers from some navigational issues: the table of content does not link correctly to the materials referenced (links are off by a few pages) and citations are not hyperlinked, which makes it less than user-friendly to determine what book or article stands behind the reference [137]. This is something the publishers really ought to sort out, as I cannot think of any good justification for such sloppiness.",27
Windweller,4.0 out of 5 stars,Scala for Machine Learning,"Errors, errors, errors, there are many many ...","Errors, errors, errors, there are many many many errors in the book. You need to check the book and the actual code (available on the website) to work this out.

This is a good book however. There isn't any machine learning book on the market that takes such a deep dive into the subject matter, and the author really writes fantastic Scala with dazzling skills. However, code in the book is inconsistent to the source code (downloadable from website). You need to check the actual code, cross-examine/compare with the code in the book in order to understand the whole thing.

The math part is fine, but this really isn't a mathematics book, so prior knowledge is required. It covers an astonishing range of machine learning topics, even the algorithms no other book will ever cover. So I'd say, this is a must have book. Is it flawed? Deeply. They need at least two or three revisions to make this a book with fewer flaws. Is it worth buying? Yes. The incredible benefit outweighs the flaw.",27
Peter Faller,1.0 out of 5 stars,"Superintelligence: Paths, Dangers, Strategies",Tedious speculation,"It is seldom that I do not finish reading a book. What I found absolutely frustrating about this book is that it is all speculation - no concrete examples of events or developments that have occurred. A word-count analysis would show that the most frequently used words are 'maybe', 'could', 'might' - not 'did', 'has' or 'definitely'. I got to about 40% through the book, and gave up in disgust. I am sorry that I spent a cent on buying this book.",26
unifex,1.0 out of 5 stars,Code: The Hidden Language of Computer Hardware and Software,WARNING: For hardcore geeks only!!!,"I am the manager of a computer store and a graphic/web designer and as such I use and troubleshoot computers every day and know rather a lot about them.

This book looked interesting because on the jacket it uses phrases like, ""illuminating narrative"" and ""eminently comprehensible"" and ""no matter what your level of technical savvy"".

In reality though after the 1st few chapters the book falls into an absolute quagmire of circuit diagrams and boolean logic tables and RAM address schemes and loses all sense of narrative or comprehensibility.

Unless you are really into math and/or are a programmer I would highly recommend AVOIDING THIS BOOK.

I am not a stupid person nor unfamiliar with computers but this was wayyyy beyond where I wanted to go with this. And my guess is that it's way beyond for most other folks as well.

If you are interested in learning how computers work I would highly suggest the series titled ""How Computers Work"" by Ron White.

(...)

'How Computers Work' contains very clear diagrams and explanations that while technical aren't at the picky and obtuse levels reached in the book 'Code'.

(...)",26
LaChelle,5.0 out of 5 stars,Accelerated Spanish: Learn fluent Spanish with a proven accelerated learning system,"An active approach to learning anything, really.","I really appreciate the creativity and unique approach to Spanish this provides. There is really nothing like it out there. What is better, is that once you learn the technique that Timothy has created, there are no limits for you for applying it for the rest of your Spanish-learning life. Actually, it goes beyond that to give you the framework to memorize and learn anything efficiently. This is active learning, the way we all really need to learn. You can't really learn a language by sitting back and letting it magically happen. You need to really think about it and mold it to make sense for you. Know something intimately. That's the mindset that this book will help you access.",26
Christopher Farrell,1.0 out of 5 stars,The Age of Spiritual Machines: When Computers Exceed Human Intelligence,A book built on fundamentally flawed assumptions,"This was a book so torturous, so sensationalistic, it was a brutally difficult read. Unfortunately, the premises of this book are so crucially flawed for all but the most fundamentalist believer in the power of technology, it's almost a complete waste of time.
Kurzweil's claim of thinking machines for less than $1000 within 20 years is clearly outlandish, obviously designed to make headlines. Even if the hardware continues to accelerate at his predicted rate, a somewhat dubious assumption, he doesn't even seriously address simple software engineering issues. In fact, virtually all of his assumptions and analogies have an excessive technological zeal and don't hold up to any real questioning; it is, after all, easy to believe you could create a human-equivilant computer if you have an extremely low opinion of human intelligence (which Kurtzweil does, apparently).
I think one of the advantages of a liberal education is that it teaches you not to try to see every problem and issue within the narrow scope of your own specialty, and it gives you a certain respect for history. Kurtzweil seems to think of absolutely everything (including art and music) as purely technological developments and engineering problems, and seems to be possessed by the late-19th century belief that (technological) progress is not only inevitable but the driving force of our existance; i.e., his stated belief is that technology is simply a seamless continuation of evolution, inevitable and involuntary.
If we assume human intelligence were really this trivial (in one telling example, Kurtzweil mentions the harpsichord as being obsolete in the same way as a manual typewriter - perhaps not completely untrue, but clearly not a particularly compelling analogy on which to build an arts-as-technology argument), then perhaps we could develop computers of human intelligence just by giving them a motivation for continuous self-improvement. Despite Kurzweil's fervor, it is not so simple to say this with any real conviction. In order to predict with confidence that we can create a being of human intelligence, we would have to understand what we would be creating. Kurtzweil's assumptions, that everything we do is technology- and progress-oriented, don't pass logical muster for me (can you really believe that Mozart composed for some evolutionary advantage?); since he rapidly convinced me he doesn't have any more of a clue as to the nature of life or human intelligence than the rest of us, in my opinion it makes all of his outlandish claims of being able to create somthing as good or superior unsustainable and the book superflous.",26
N/A,1.0 out of 5 stars,Pattern Classification (Pt.1),Pretty Bad,"I am using this book for class right now. Our professor complains about the book constantly because 1) the text is explained in too complicated of a way, 2) there are too many errors, and 3) some of the errors are quite mathematical in nature. Our professor said he tried to E-mail the author, but the author said he ""didn't have time because so many people like the book.""",26
Max Rower,5.0 out of 5 stars,"Amazon Echo: Dot:The Ultimate User Guide to Learn Amazon Dot In No Time (Amazon Echo 2016,user manual,web services,by amazon,Free books,Free ... Prime, smart devices, internet) (Volume 5)",Simple and straight to the point.,"The Amazon Echo Dot is a cut-down but still impressive version of the Echo. If you want Alexa but don't want to pay a premium price, this is a great option. The best thing about the Amazon Dot is that it gets smarter every time you use it. I was hesitant to purchase the item at first because I am not into technology but part of me want to buy it too for my class. With the help of this guide, there would be no hesitation anymore. It covers the basic information how to use the item and everything is already stated there. Easy to understand. Good details. Simple and straight to the point.",26
Abel Brown,3.0 out of 5 stars,"Pattern Recognition, Fourth Edition",It might be the bible for pattern recognition but ...,Although there is a TON of info in this book it's really not that great for learning pattern recognition. It's definitely more of a reference than anything else. You can't really read a section and then sit down at your computer and code it up. There a so many details missing. And the equations are so compact that you spend most your time decoding bad notation. If this book were a piece of software it would suffer from feature bloat. If you need to actually do any real applications using the techniques in this book you should definitely by the MATLAB companion text.,26
Abel Brown,2.0 out of 5 stars,Deep Belief Nets in C++ and CUDA C: Volume 1: Restricted Boltzmann Machines and Supervised Feedforward Networks,Poor Self-Publishing Effort -- Many Better Resources Available,"I really wanted to like these books but the quality is just too low. TM thinks that just b/c some C++ code is included that the writing doesn't matter. The explanations of core concepts are terrible. There are many typos and confusing sentences and even whole paragraphs that just don't make sense. Much of the content for the other two books just copies content word for word from each other. There is very little in the other two volumes. Literally, whole sections are copied and pasted into Vol 2 and Vol 3. There a very few diagrams of anything and the diagrams and graphs that are included are of such low quality as to not be useful. I really want to support self publishing but these books are basically C++ code documentation. With all the DNN frameworks available such as Caffe, Torch, Theano, TensorFlow, CNTK there really isn't much point in studying this guys C++ code. Not to mention there is cuDNN with many of these core operations implemented.

There are many good resources on the internet that are of much higher quality. Checkout Michael Nielsen's free on-line book, also deep learning dot net has many good resources. Additionally NVIDIA offers self-study course for deep learning (just google) and also their deep learning institute (again just google).",26
Dr. Lee D. Carlson,5.0 out of 5 stars,The Computational Brain (Computational Neuroscience),Excellent,"This book can be viewed as one of the first attempts to use results from psychology, neuroscience, computer science, and philosophy with the intent of gaining an understanding of how the mind/brain works, but all of this is done within the ""computational mind"" paradigm. The approach taken by the authors is one of the most honest of those in the literature, for throughout the book they are careful to note just how much evidence there is to support their position(s), and to what extent further work is to done. Philosophically speaking, the authors are clearly in the materialist camp, believing that Cartesian dualism does not cohere with current scientific knowledge. But they state that materialism is not an established fact, allowing the possibility, but not the probability, that dualism may in fact be true. They reject early on though any ""arguments from ignorance"" in their assertion that just because neuroscience does not have an explanation of consciousness, that such an explanation is impossible. The authors call the failure to be able to think of consciousness in terms of neuronal activity ""intuition dissonance"", and reject completely its efficacy in establishing the truth of the nature of the mind/brain.
The underlying theme in the book is to explain emergent properties as ""high-level"" effects that are dependent on ""lower-level"" phenomena, hence rejecting the thesis that they are ""nomologically autonomous"", i.e. that such a dependence cannot be done and is outside the domain of science. The science in this book recognizes its historical origins, and it is clear that the authors will not accept explanations of the mind/brain that do not involve scientific experimentation and analysis. Much has been done experimentally in neuroscience since this book was published, especially using the techniques of magnetic resonance imaging (MRI). A brief discussion of MRI is given in the Appendix of the book, but no doubt if the book were updated there would be a lengthy overview of it. The current experimental situation in neuroscience has led some to predict a total ""reverse engineering"" of the brain in the upcoming decades. This prediction is an optimistic one, but no doubt detailed knowledge of the brain will continue to accelerate, this being a sign of what the authors call ""a remarkable time in the history of science"".
The authors devote an entire chapter to the computational modeling of the brain, mostly of course dealing with the mathematics of neural networks. The approach in this chapter though is still at a level that would allow a general audience to follow it. Readers with a background in physics, especially statistical physics, will appreciate more the discussion on Hopfield networks and Boltzmann machines. Experimental results are inserted as graphs throughout the book, with detailed explanation. As a whole the discussion of the biology of the brain is purely descriptive, and the line drawings could stand some improvement.
The chapter on neuronal plasticity is the most interesting in the book, the authors viewing the brain as an entity that is continuously undergoing modification. Their stated goal in the chapter is to explain how the ""local"" property of plasticity can result in the ""global"" property of learning. Clearly intelligence to the authors is an emergent property, i.e. an object or device may be characterized as intelligent without its components being intelligent. Particularly interesting in this chapter was the discussion of the amnesia of a patient who underwent bilateral resection of mesial temporal lobe structures. The time scales of the patient's memory are striking: he remembered things before the surgery but could not remember things that happened a few minutes or hours ago, but could remember things within a minute in his past. The authors also mention the fascinating work of Antonio Damasio and his collaborators, this research being even more important at the present time. The scientific study of consciousness is just beginning and no doubt this study will give many surprises as it develops throughout the twenty-first century.",26
Kenneth Finnegan,2.0 out of 5 stars,Practical Computer Vision with SimpleCV: The Simple Way to Make Technology See,A little half baked,"I was looking forward to a book titled ""Practical Computer Vision."" When so many of the other texts drop into math so quickly, I wanted a more pragmatic approach to CV. I'm afraid this book may have swung a little too far in the opposite direction.

First of all, the fact that the release date got pushed back several times started to set off some alarm bells for me. There are still sentences in this book where the author seems to have a verb. Furthermore, there seem to be many issues with the figures in the book:
* It seems the author forgot to include image examples (or ran out of time making them) for one or two of the code snippets.
* The entire book suffers grossly from the fact that the author seemingly forgot that it was going to be printed in black and white; countless times he uses color to illustrate something. ""The points of interest have been highlighted in yellow."" It's all grey...
* Every figure between 8.10 and 8.14 are the exact same image. He refers to them as the various steps for edge detection, but seems to have forgotten to actually *DO* anything on the original image.

Overall, I was disappointed with this book. I was hoping for a practical introduction to how computer vision works, but instead got a practical introduction to how to use SimpleCV for computer vision. Any of the algorithms for computer vision I was interested in understanding were simply wrapped in magical SimpleCV function calls; a more apt title would have been ""Using SimpleCV (for Practical Computer Vision)."" That by itself would have been forgivable, but the fact that the book then ends up feeling like a rush job leaves me questioning what this book would really be good for.

If I had no clue how computer vision worked, and wanted to write a tinker-toy computer vision program like PhotoBooth, a new edition of this book might be interesting. As it is, I didn't find it useful, and kept checking to see if ""Draft Edition"" was printed on the spine and they had sent it to me by mistake.",26
G. Tomer,5.0 out of 5 stars,Alan Turing: The Enigma,We can learn and prevail,"Alan Turing: The Enigma The Centenary Edition Andrew Hodges is a scientist who wrote a triumph of love and genius: about a young man who's unique insight and unmeasured abilities found solutions that lead us to computers in 1936. But, there's more - Turing's solution found immediate approval from the great Kurt Godel. These talented young men tore mathematics from the breast of philosophy and threw it onto the floor of humanity's aspirations and dreams. The center of mathematics transferred from Germany to Princeton's Institute of Advanced Study; and when the pre-eminent Albert Einstein left Europe for the IAS, physics became an American prize.

As the Nazi political party became the German government, Turing was studying for his Ph.D. at Princeton with Alonzo Church and his two close associates, S.C. Kleene and J. Barkley Rosser. However, Turing realized the threat to England would culminate in war. Despite an offer to work with his childhood idol J. von Neumann, Turing returned to England in time to join ""Foreign Service"" at Bletchley Park. Hodges pace is a marathon: Turing was a marathon runner who nearly competed for his country in the 1949 Olympics. Writers who have continued the mythology of Turing's various ills and shortcomings must read the research efforts of Mr. Hodges. He presents Turing as he was known and witnessed by his friends, associates, detractors, and his competitors.

Anyone interested in knowing or understanding computer science, mathematics, and the actual history of the genius who created the foundations of the internet and modern computer theory should spend some time reading Hodges and his ponderous study of Alan Mathison Turing. The Enigma is written for serious believers in humanity and miracles - and the failure of the world to recognize real heroes. Without knowing Alan Turing, we cannot appreciate today's freedoms. Turing and Bletchley Park were evenly portrayed: as a collective, BP was the hope of a free world. BP was comprised by true-believers from England and the Commonwealth, the Middle East, Poland, and America. Over 80% were women and they played vital roles. A high percentage in BP relative to a low percentage in England's total population were Jewish. Read the book and learn from the best! When you analyze the actual devices of Engima and Lorenz created by German armed forces and scientists, it seems improbable that anyone could break the code.

Nearly all of the WWII codebreakers are gone. Yet, their dedication to prevail ultimately allowed the Allied forces to have a D-day, and previously helped the English and American forces in North Africa to defeat the great Rommel. Without the codebreakers, the war would have lasted another two years (by some estimates) and the death toll even higher. Turing's story is not unique, not as an Englishman, nor as a human. Every codebreaker in their huts had stories... What makes Turing different was his ability to continue toward solutions when others failed. Unfortunate for the world: England refused to honor him; and violated his rights when their government prosecuted him as a criminal. Turing's refusal to demean his humanity, or to yield under the forces of conformity, was magnificant - far greater than his genius. We have heard the apology: when his name is cleared of supposed wrongdoing, remains our burden. Only Andrew Hodges could possibly bring these thoughts any reality. Perhaps we can learn more about each other by listening to Hodges.",26
Kinga,5.0 out of 5 stars,Pattern Recognition and Machine Learning (Information Science and Statistics),Excellent text,"First of all, as some other reviewers have pointed out, the subtitle of the book should include the word 'Bayesian' in some form or the other. The reason this is important is because the Bayesian approach, although an important one, is not adapted across the board in machine learning, and consequently, an astonishing number of methods presented in the book (Bayesian versions of just about anything) are not mainstream. The recent Duda book gives a better idea of the mainstream in this sense, but because the field has evolved in such rapidity, it excludes massive recent developments in kernel methods and graphical models, which Bishop includes.

Pedagogically, however, this book is almost uniformly excellent. I didn't like the presentation on some of the material (the first few sections on linear classification are relatively poor), but in general, Bishop does an amazing job. If you want to learn the mathematical base of most machine learning methods in a practical and reasonably rigorous way, this book is for you. Pay attention in particular to the exercises, which are the best I've seen so far in such a text; involved, but not frustrating, and always aiming to further elucidate the concepts. If you want to really learn the material presented, you should, at the very least, solve all the exercises that appear in the sections of the text (about half of the total). I've gone through almost the entire text, and done just that, so I can say that it's not as daunting as it looks. To judge your level regarding this, solve the exercises for the first two chapters (the second, a sort of crash course on probability, is quite formidable). If you can do these, you should be fine. The author has solutions for a lot of them on his website, so you can go there and check if you get stuck on some.

As far as the Bayesian methods are concerned, they are usually a lot more mathematically involved than their counterparts, so solving the equations representing them can only give you more practice. Seeing the same material in a different light can never hurt you, and I learned some important statistical/mathematical concepts from the book that I'd never heard of, such as the Laplace and Evidence Approximations. Of course, if you're not interested, you can simply skip the method altogether.

From the preceding, it should be clear that the book is written for a certain kind of reader in mind. It is not for people who want a quick introduction to some method without the gory details behind its mathematical machinery. There is no pseudocode. The book assumes that once you get the math, the algorithm to implement the method should either become completely clear, or in the case of some more complicated methods (SVMs for example), you know where to head for details on an implementation. Therefore, the people who will benefit most from the book are those who will either be doing research in this area, or will be implementing the methods in detail on lower level languages (such as C). I know that sounds offputting, but the good thing is that the level of the math required to understand the methods is quite low; basic probability, linear algebra and multivariable calculus. (Read the appendices in detail as well.) No knowledge is needed, for example, of measure-theoretic probability or function spaces (for kernel methods) etc. Therefore the book is accessible to most with a decent engineering background, who are willing to work through it. If you're one of the people who the book is aimed at, you should seriously consider getting it.

Edited to Add:
I've changed my rating from 4 stars to 5. Even now, 4-5 years later, there is simply no good substitute for this book.",25
E. PROKOPOW,5.0 out of 5 stars,Accelerated Spanish: Learn fluent Spanish with a proven accelerated learning system,"Learn what Spanish you need, not just a list you memorize","You took a trip to a Spanish-speaking country (or maybe to a Spanish-speaking neighborhood closer to home). You wandered thru or near a park playground or a busy swimming pool or beach, close enough to overhear conversations. And then you felt the frustration of not being able to follow the conversation in Spanish of 3- and 4-year-old kids! Accelerated Spanish's focus on frequently-used words over rote vocabulary lists by function (""and now here is a list things you find in a classroom! oh boy!) is a remarkably different way to approach language learning, e.g., think about how many times you will need to use the noun ""backpack"" or ""chalkboard"" over the expression for ""to him"" or ""I used to"" or ""she was going"". (Answer: none). You'll really appreciate the emphasis on pronouns, extremely commonly used verbs and all their tenses, including subjunctive. Timothy even addresses techniques to ""unlearn"" certain information that you were probably taught incorrectly (as was I). You'll retain more, and more rapidly, than you ever thought you could too.",25
Peter McCluskey,5.0 out of 5 stars,"The Age of Em: Work, Love, and Life when Robots Rule the Earth","Ambitious questions, thoughtful and sometimes satisfying answers","This book analyzes a possible future era when software emulations of humans (ems) dominate the world economy. It is too conservative to tackle longer-term prospects for eras when more unusual intelligent beings may dominate the world.

Hanson repeatedly tackles questions that scare away mainstream academics, and gives relatively ordinary answers (guided as much as possible by relatively standard, but often obscure, parts of the academic literature).

Hanson's scenario relies on a few moderately controversial assumptions. The assumptions which I find most uncertain are related to human-level intelligence being hard to understand (because it requires complex systems), enough so that ems will experience many subjective centuries before artificial intelligence is built from scratch. For similar reasons, ems are opaque enough that it will be quite a while before they can be re-engineered to be dramatically different.

Hanson is willing to allow that ems can be tweaked somewhat quickly to produce moderate enhancements (at most doubling IQ) before reaching diminishing returns. He gives somewhat plausible reasons for believing this will only have small effects on his analysis. But few skeptics will be convinced.

Some will focus on potential trillions of dollars worth of benefits that higher IQs might produce, but that wealth would not much change Hanson's analysis.

Others will prefer an inside view analysis which focuses on the chance that higher IQs will better enable us to handle risks of superintelligent software. Hanson's analysis implies we should treat that as an unlikely scenario, but doesn't say what we should do about modest probabilities of huge risks.

Another way that Hanson's assumptions could be partly wrong is if tweaking the intelligence of emulated Bonobos produces super-human entities. That seems to only require small changes to his assumptions about how tweakable human-like brains are. But such a scenario is likely harder to analyze than Hanson's scenario, and it probably makes more sense to understand Hanson's scenario first.

Wages in this scenario are somewhat close to subsistence levels. Ems have some ability to restrain wage competition, but less than they want. Does that mean wages are 50% above subsistence levels, or 1%? Hanson hints at the former. The difference feels important to me. I'm concerned that sound-bite versions of book will obscure the difference.

Hanson claims that ""wealth per em will fall greatly"". It would be possible to construct a measure by which ems are less wealthy than humans are today. But I expect it will be at least as plausible to use a measure under which ems are rich compared to humans of today, but have high living expenses. I don't believe there's any objective unit of value that will falsify one of those perspectives [1].

The style is more like a reference book than a story or an attempt to persuade us of one big conclusion. Most chapters (except for a few at the start and end) can be read in any order. If the section on physics causes you to doubt whether the book matters, skip to chapter 12 (labor), and return to the physics section later.

The style is very concise. Hanson rarely repeats a point, so understanding him requires more careful attention than with most authors.

It's odd that the future of democracy gets less than twice as much space as the future of swearing. I'd have preferred that Hanson cut out a few of his less important predictions, to make room for occasional restatements of important ideas.

Many little-known results that are mentioned in the book are relevant to the present, such as: how the pitch of our voice affects how people perceive us, how vacations affect productivity, and how bacteria can affect fluid viscosity.

I was often tempted to say that Hanson sounds overconfident, but he is clearly better than most authors at admitting appropriate degrees of uncertainty. If he devoted much more space to caveats, I'd probably get annoyed at the repetition. So it's hard to say whether he could have done any better.

Even if we should expect a much less than 50% chance of Hanson's scenario becoming real, it seems quite valuable to think about how comfortable we should be with it and how we could improve on it.

[1] - The difference matters only in one paragraph, where Hanson discusses whether ems deserve charity more than do humans living today. Hanson sounds like he's claiming ems deserve our charity because they're poor. Most ems in this scenario are comfortable enough for this to seem wrong.

Hanson might also be hinting that our charity would be effective at increasing the number of happy ems, and that basic utilitarianism says that's preferable to what we can do by donating to today's poor. That argument deserves more respect and more detailed analysis.",25
quant@inside,5.0 out of 5 stars,Bayesian Reasoning and Machine Learning,One of the best text to learn machine learning,"I have read a similar book on Machine Learning, namely Pattern Recognition and Machine Learning (by Bishop). Before I read Barber's book, I considered Bishop's book to be the best in the Machine Learning (with bayesian focus). However, after reading this book, I can definitely say that it is better that Bishop's book in many sense. There are lots of examples in each chapter with matlab codes for many of them. Also, it covers more material that Bishop. Chapters on dynamic models and graphical models are particularly awesome. This book doesn't assume much background in probability (one master's level course on probability and statistics is probably more than enough). However, some chapters are advanced, and are mentioned so in the book.",25
Dennis B. Mulcare,1.0 out of 5 stars,The Sciences of the Artificial - 3rd Edition,"Glib, Presumptuous & Misinformed","Upon reading this book for the third time over a span of two decades, I decided to react to its content this time rather than to simply dismiss it as poorly informed and seriously flawed. That assessment derives largely from my fifty years of experience as an aerospace system designer, with an extensive record in development methods R&D. Furthermore, I am dismayed at the book??s trivialization of design and its naive understanding of engineering practice in general. Regrettably, the book thereupon proceeds along an even worse course via its fatuous prescriptions for a purported science of design and its automation.

Questions for Inquiring Minds: forty-five years after its initial publication, how many books can be found on Amazon that address ??design science? or the like, especially in the sense that Simon laboriously enunciated? Ok then, what actual impact has Simon??s version of design science in itself ever had on engineering or design practice? Did actual engineering practitioners or experienced designers in general ever regard this book as consequential or relevant?

Fundamentally, Simon construes design as amenable to casting as a science per se, rather than as an endeavor wherein many of the more challenging aspects are typically dealt with largely as an art. That design is informed or facilitated by science is vacuously true, not to mention irrelevant. Moreover, engineers/designers have developed much of that sort of science, because they are resourceful in finding better ways to fashion improved products. Disconcertingly, Simon??s thesis begins with the premise of design as problem solving, rather than one mainly of resolving problem situations by first systematically formulating problem statements. Furthermore, design problem discovery proceeds well beyond design per se ?? at least into development testing. The lesson: finalized well-formed problem statements exist only in textbooks or in classrooms.

To expand on the book??s critique in the context of the exigencies of the real world of design,

1. the only design-oriented engineering author cited by Simon is Clive Dym (p. 128)
- Dym otherwise states ??as grounds for serious study, the art of engineering has lain fallow...To recognize that there is an art to engineering design does not preclude design from being worthy of serious scientific study.? (p.185 of ??Engineering Design ?? A Synthesis of Views?)
2. the conceivability of a science of design (chapters 5 & 6 ) is dubious given the vital role of the practitioner art component typical of customary practice
- Turing Award recipient Frederick Brooks has written ??I believe a ??science of design?? to be impossible? (p. xii of ??The Design of Design ?? Essays from a Computer Scientist?)
3. that technical rationality inherent in the science of design can serve as a practical basis for design methodology (chapter 5 ) is widely discounted
- Donald Schon counsels ??Let us search, instead, for an epistemology of practice which some practitioners do bring to (design challenges)? (p. 49 of ??The Reflective Practitioner- How Professionals Think in Action?)
4. that design problems are givens readily available as design requirements (e.g., p. 115) for immediate search for design alternatives (p. 121) from which to select, is wholly unrealistic
- Donald Schon points out that ??with this emphasis on problem solving, we ignore problem setting...In real world practice, problems do not present themselves...as givens? (p.40)
5. even worse, Simon??s advocacy of a science-based methodology (Chapter 5 ) is questionable, especially as reliant upon an encompassing automated search/optimization process
- Christopher Alexander states ??the search for the image or criterion for success is going on at the same time as the search for a solution? (p. 197 of ??Notes on the Synthesis of Form?)
- Frederick Brooks observes that ??as one ponders the tradeoffs, there comes a new understanding of the whole design problem as an...interplay of factors (that yields) ...a change in the weightings of the desiderata? (p. 26)
6. the value of formal logic for development (p. 115 ) is neither uncommon nor a panacea, but its use may be misleading
- Christopher Alexander notes that ??however rational we should like to be...Logical methods, at best, rearrange the way in which our personal bias is to be introduced? (p.194)
7. as a response to Item 1 above, Ozgur Eris?? ??Effective Inquiry for Innovative Engineering Design? is a thoughtful, systematic, and admirable exploration of design practice
- Eris?? thesis claims ??the uniqueness of design thinking by identifying a specific class of questions that are characteristic of design situations.? (p. 1)

To elaborate on the fourth bullet above, in engineering development endeavors, there are typically three partly trial-and-error steps leading up to the codification of design requirements, or problem definition per se:

1, problem situation ?? exploration, bounding & characterization of the problem in context
2. problem setting ?? determination of the programmatic goals, strategies, resources, etc., for project definition/go-ahead
3. problem framing ?? delineation of the essential technical issues and implications to be addressed, along with reservations and success criteria
4. problem specification ?? particular requirements that the design effort is committed to satisfy and verify.

Upon the completion of Step 4, one then has a design problem statement in hand, albeit one subject to refinement as design proceeds. The good news is that much of the more problematic work has been accomplished at this point. Moreover, if a (hypothetical) design problem is reduced to algorithmic resolution, then there exists a relatively tractable design task to deal with, provided the algorithms?? (largely subjective) parameters remain fixed. After all, optimization algorithms per se are rather straightforward; it??s their subjective application that is highly problematic.

Although Simon had presented the notion previously, his characterization of bounded rationality here is both cogent and useful. Somewhat surprisingly though, he then attempts to overcome this phenomenon by articulating his automated design alternative via a generation-selection-optimization strategy. This technical rationality synthesis stands in complete disregard of the essential nature, context, and conduct of design. Simon??s design strategy is accordingly at best an idealization; but in my estimation, not at all a helpful or viable one. Nonetheless, bounded rationality is an important concept, and its clear explication and fruitful development may be found in Gerd Gigerenzer??s ??Bounded Rationality?. In acknowledging the realities of decision making as vital to matters besides design, Gigerenzer develops the companion notion of ??quasi-rationality?. As the term suggests, it obtains from an interplay of analysis and intuition, as characteristic of many human cognitive tasks. Quasi-rationality, moreover, is the basis on which designers naturally operate.

In sum, Simon??s design science and technical rationality are idealized notions resiliently contrary to successful design practice. Moreover, practical design automation itself has been introduced from at least the 1960s and applied ever more expansively. This has been done largely on the initiatives of engineering practitioners themselves. In contrast, Simon??s skewed and inordinate vision of design automation simply fails to apprehend the multifaceted nature of design and the flexible performance demanded of designers. Furthermore, Simon??s crucial expectations for operations research and artificial intelligence technologies have since this book was first published been quite notably compromised in terms of delivered results. In all then, what in tenuous principle might be done per this book??s vision, through expansive automation under ideal conditions, is unworthy of serious consideration, and especially so now in hindsight.

Even if Simon??s vision were realized, it would merely shift much of the presently perceived complexity would be shifted elsewhere in the development process, and the overall process implementation would be rendered even more complex and probably less responsive. (See Nicholas Rescher??s commentary on the inevitability of complexity escalation via the introduction of technology that appears in ??Complexity: A Philosophical Overview.?) Arguably, Simon??s proposal for design science automation will likely remain unworthy of consideration, if only because of the staggering complexity concentration, flexibility/fragility issues, and development cost/time entailed in its workable implementation for real-world deployment.",25
Dr. Lee D. Carlson,3.0 out of 5 stars,The Artilect War: Cosmists Vs. Terrans: A Bitter Controversy Concerning Whether Humanity Should Build Godlike Massively Intelligent Machines,Farfetched,"If one examines the history of research into artificial intelligence (AI), one will see it to be one of periods of incredible optimism as well as periods of extreme pessimism. Funding for research into AI, both private and public, is partly responsible for this. But the researchers themselves bear a certain measure of responsibility for the wild swings that have marked the history of AI. It seems that as soon as something is invented that appears promising or ""intelligent"" it is shortly thereafter abandoned as being ""trivial"" or uninteresting. Researchers always seem willing to go along with this unfortunately, even though they have indeed made significant progress in certain areas. Once an algorithm or reasoning pattern is understood, its status as `intelligent' is taken away and it is thereafter viewed as `just another part of the programming toolbox'. There is strong evidence, coming mostly from the commercial realm, that truly intelligent machines exist and are saving and making companies hundreds of millions of dollars in their deployment in the field. This intelligence is however not noticed or recognized as such. It is viewed merely as software that is `running' on the machines, complex yes, but not really different than `ordinary' software that has been used for decades now. If this pattern continues, then no matter how intelligent machines get they will not be viewed as being so. Their human users will therefore not be intimidated by or even impressed by them. They will become accepted just like any other piece of technology, usually taken for granted, although at times becoming an annoyance due to their need for repair and adjustment (this need becoming more critical as their complexity increases).

When this book is read with this in mind its main thesis, namely that there will sometime in the relatively near future be a controversy over the building of `massively' intelligent machines, completely dissolves. The author believes that sometime in the second half of the twenty-first century, humanity will divide itself into two camps. One of these, called the `Cosmists', will advocate the building of what the author calls `artilects', which are ""massively"" intelligent machines. The other camp, called the `Terrans', is strongly opposed to the building of these types of machines. The tension between these two groups will become so extreme the author argues, that it will result in a full-scale war between them, resulting in the deaths of millions of people.

In the book the author details his reasons for believing that this will happen, and he even discusses his own anxieties on the possibility of massively intelligent machines. The author is a noted expert in machine intelligence, especially in the fields of evolutionary computing and evolvable hardware. Therefore when a researcher like the author makes the claims he does it motivates the reader to examine his arguments in more detail. It is apparent when reading the book that these arguments have been carefully thought out, even though at times, because of the Cosmist-Terran terminology, the reading sometimes appears sophomoric or science-fictional in quality.

The claims made in this book would have more credibility if progress in artificial intelligence could be modeled by large discrete jumps. Central to its claim is that there will arrive a time at which both `Cosmists' and `Terrans' agree that superintelligent machines can be realized or manufactured. The apprehension felt by the Terrans will motivate them to try and suppress this realization, this behavior putting them squarely against the Cosmists. This conflict will escalate into full-scale war, fought with highly advanced and destructive technology.

But progress in AI is basically a smooth function of time, and there has been progress, despite the extreme skepticism of many individuals (most of these, again, being AI researchers themselves). Like any other field, some of the ideas in AI have not been fruitful, and have fallen by the wayside. Advances in AI have been steady, and the advances, as well as its applications are rapidly accelerating. The use of intelligent machines has become routine, so routine in fact that it is not really noticed. One can expect this trend to continue, and researchers twenty years from now will no doubt think that real intelligence has not yet been achieved. The bar will then get raised again. All the while the machines are performing useful functions and will exist in complete symbiosis with the humans around them. However, there will still be anxiety about the future arrival of superintelligent machines. It may take a while, probably till the end of the twenty-first century, for this anxiety to alleviate. Historians of technology in the first year of the twenty-second century will no doubt look back at this one and be perplexed as to why AI progress was not really part of the consciousness of those who were involved in it. These same historians will also feel another emotion when they study the developments of twenty-first century technology, including artificial intelligence:

Astonishment",25
N/A,5.0 out of 5 stars,Conceptual Spaces: The Geometry of Thought (MIT Press),"FYI, the long Table of Contents","1 Dimensions 1.1 The Problem of Modeling Representations 1.2 Conceptual Spaces as a Framework for Representations 1.3 Quality Dimensions 1.4 Phenomenal and Scientific Interpretations of Dimensions 1.5 Three Sensory Examples: Color, Sound, and Taste 1.6 Some Mathematical Notions 1.7 How Dimensions Are Identified 1.8 Integral and Separable Dimensions 1.9 On the Origins of Quality Dimensions 1.10 Conclusion
2 Symbolic, Conceptual, and Subconceptual Representations 2.1 An Analogy for the Three Kinds of Representations 2.2 Symbolic Representations 2.3 Subconceptual Representations 2.4 Conceptual Representations 2.5 Connections to Neuroscience 2.6 Comparisons 2.7 The Jungle of Representations
3 Properties 3.1 Program 3.2 Properties in Intensional Semantics 3.3 Criticism of the Traditional View of Properties 3.4 Criteria for Natural Regions of Conceptual Spaces 3.5 Natural Properties 3.6 Reconsidering the Problems 3.7 The Relativism of Conceptual Spaces 3.8 Connections to Prototype Theory 3.9 Voronoi Tessellations of a Space 3.10 Higher Level Properties and Relations 3.11 Conclusion
4 Concepts 4.1 Concepts versus Properties 4.2 Modeling Concepts 4.3 The Role of Similarity in Concept Formation 4.4 Combining Concepts 4.5 Learning Concepts 4.6 Nonmonotonic Aspects of Concepts 4.7 Concept Dynamics and Nonmonotonic Reasoning 4.8 Objects as Special Kinds of Concepts 4.9 Four Geometric Categorization Models 4.10 The Shell Space 4.11 Experiments
5 Semantics 5.1 What Is a Semantics? 5.2 Six Tenets of Cognitive Semantics 5.3 Analysis of Some Aspects of Lexical Semantics 5.4 An Analysis of Metaphors 5.5 The Learnability Question 5.6 Communicating Referents 5.7 Can Meanings Be in the Head? 5.8 Conclusion: The Semantic Program
6 Induction 6.1 Three Levels of Induction 6.2 The Symbolic Level 6.3 The Conceptual Level 6.4 The Role of Theoretical Concepts 6.5 The Subconceptual Level 6.6 Correlations between Domains 6.7 Conclusion: What Is Induction?
7 Computational Aspects 7.1 Computational Strategies on the Three Levels 7.2 Conceptual Spaces as Emergent Systems 7.3 Smolensky's Treatment of Connectionism 7.4 Not All Computation Is Done by Turing Machines 7.5 A System for Object Recognition 7.6 Conclusion
8 In Chase of Space 8.1 What Has Been Achieved? 8.2 Connections among Levels 8.3 Conclusion: The Need for a New Methodology
Notes References Illustration Credits Index",25
OregonCoast,4.0 out of 5 stars,Building Natural Language Generation Systems (Studies in Natural Language Processing),A worthy introduction to NLG (natural language generation),"Summary: Reiter and Dale provide a useful introduction to NLG.
Review: This book is probably the first of its kind. Although there has been considerable work in natural language summarization, research in producing natural language is in its infancy. The authors draw upon actual NLG systems to illustrate the techinical issues involved. They are careful to point out that NLG may not be the best solution for the reader's practical problems. For instance, human writers might produce better text, or mail-merge programs might do the job (albeit with lower quality) at a significantly lower price. A shortcoming -- perhaps a necessary one -- is that the authors hesitate to describe research and development trends for the past decade. The reason does not appear to be a shortage of the quality and quantity of NLG R&D, because the authors do analyze trends for the 1970's and the 1980's. Are the authors hesitant to criticize their contemporary colleagues? A blunt trends analysis would have been helpful, particularly for readers new to the field.",25
MGeek,1.0 out of 5 stars,Mathematical Statistics with Mathematica (Springer Texts in Statistics),Don't buy this book!,"I bought this book only to find that mathStatica on the bundled CD does not work with the current 5.0 version of Mathematica. The website wants $89 to upgrade the version to a ""new"" version that will work with 5.0. This upgrade costs more than the price of the book! Seems like a classic bait & switch....",25
John Harpur,2.0 out of 5 stars,What Is Thought? (MIT Press),Interesting but replete with hasty argumentation,"The main thesis of this book, asserted repetitively, is that the mind is a computer program. Once this is borne in mind, pardon the alliteration, most of the book is reduced to an argument in its favour, rather than an investigation into its credibility. The book often reaches for blunt assertions to support its positions and only afterwards begins a slight retracing of steps. For example, we are told that inductive bias and learning algorithms are coded into the genome. It is obvious, bit of speculation on DNA, evolution and algorithms and out comes the result!

In his observance of Occam's Razor, the author confuses the appeal of the simplest explanatory hypothesis with the belief that he has found such. The discussion of neural networks leaves aside recurrent networks, which are probably more biologically plausible than competitors.

Likewise the idea that the brain essentially 'runs' compressed programs due to evolutionary endowments is unconvincing and philosophically leaky.

I don't want to be over critical of the book as it has brought together many interesting strands of work, but it just has not woven them into anything interesting. There is little new here, whether from modularity or evolutionary programming constraints on neural activity. A lot of it is speculative and several of the key themes are discordant due to under analysis of their assumptions.

Several of the elaborations verge on the frivolous. For example, there is a particularly woolly argument linking the learning of Scheme to ""what goes on in constructing our understanding of the world"" (p. 222). Likewsie in discussing awareness and consciousness, the author relies on the use of 'main' in C to metaphorically explain how information might come together in the brain (p. 413-415). All kinds of reification fallacies come to mind, leaving aside the thinnes of the argument.

The bottom line is that the book pursues a strong cognitivist program (the brain is a computer) without convincingly examining various sides of the argument. I was certainly no wiser off at the end of it.",25
Josh Davis,5.0 out of 5 stars,An Introduction to Statistical Learning: with Applications in R (Springer Texts in Statistics),"Future Classic, hopefully?","This book was used in my graduate level Machine Learning class (with certain readings/problems from the authors other more challenging book, The Elements of Statistical Learning).

I loved the class and loved the book. I thought the applications with R made it far more accessible and made it easier to learn. While I totally love the theoretical underpinnings, sometimes they aren't the best to learn right away and applying the ideas make it easier to grasp.

Rob Tibs & Trevor Hastie also had an online course offered through Stanford's EdX that ran the same time I was taking the course. It had videos of Trevor and Rob explaining the concepts in the order they were presented in the book. The course also included exercises and quizzes. The best part of the online course was that Rob & Trevor were absolutely hilarious. I loved their commentary and their personalities clashed in the most humorous way possible; it is very easy to see that they love what they do and love each other's company.

I'd totally recommend this book. Keep an eye out for the next offering on Stanford's online course web page; it makes it a lot more enjoyable.",24
M. Strombach,2.0 out of 5 stars,Design Patterns: Elements of Reusable Object-Oriented Software,Kindle edition diagrams unreadable,"This isn't a review about the content of the book itself; that definitely deserves 5 stars, it's absolutely a classic and is essentially required reading for anyone who takes developing software seriously.

The two stars I gave this book applies only to the Kindle edition. Specifically, whatever scanning was done to digitize this book butchered the diagrams. They are very low resolution and the text on them is nearly impossible to read. This is a big problem as the diagrams are very helpful when working through the written content. It is very nice to be able to search, highlight, annotate, and access your book from anywhere, but in my opinion essentially losing the diagrams is not a reasonable tradeoff. There are also some OCR errors sprinkled around. Nothing that makes the text confusing, just some 'i's for 'l's that I've noticed, but it just makes this version even more disappointing. This is one of the most popular software engineering texts of all time, what's the with the totally amateur conversion? Even running it though spellcheck would have found some of these errors; I can't imagine an excuse for it.",24
bbread,5.0 out of 5 stars,"Fundamentals of Machine Learning for Predictive Data Analytics: Algorithms, Worked Examples, and Case Studies (MIT Press)",A future Classic. This book rigorously and clearly defines ...,"A future Classic. This book rigorously and clearly defines the key terms in Machine Learning. You will also find explanations of the core concepts of machine learning algorithms and enough math and images to consolidate your understanding. I encourage people to read this book before reading ""An Introduction to Statistical Learning"". Highly recommended",24
Scott Piper,1.0 out of 5 stars,The Singularity Is Near: When Humans Transcend Biology,Age of Spiritual Machines was Kurzweil's best,"""The Age of Spiritual Machines"" (Kurzweil's previous book) I thought was a great optimistic book about the future. ""The Singularity is Near"" is too optimistic. It just lists niche technologies that Kurzweil thinks will change the world, even if the technologies aren't technically sound. I stopped reading when Kurzweil discussed a perpetual motion machine which he believed could and will exist.",24
calvinnme,4.0 out of 5 stars,Multiple View Geometry in Computer Vision,Good on the explanations of the theory,"This book is very complete and rigorous in its explanations of the theory. However, I just think I like the approach in An Invitation to 3-D Vision a bit better. This book is better illustrated than that one and is more careful in its explanations, but this book just seems more focused on providing complete proofs than giving you a feel for how you would approach a real problem. Even the exercises are more along the lines of proofs. I like how An Invitation to 3-D Vision ends the book with a complete example. In all fairness, though, this book does have quite a bit of Matlab code on its website.

The book begins with some background material on 2D and 3D geometry. Then the author explains single-view geometry and how cameras map an image in 3D space to an image. Two-view geometry is next, with the author describing the epipolar geometry of two cameras ahd projective reconstruction from resulting image map correspondences. Part three of the book extends ideas to three cameras and the resulting trifocal geometry. The final section of the book takes the algorithms of the book to N views. Thus this book has a simple and straightforward structure that belies the complexity of the material.

If you are really researching this subject you should probably have this book for explanation, illustrations, and rigor, and the Invitation book for enlightenment through a good example-based approach. You should also have Introductory Techniques for 3-D Computer Vision as a text on the individual pieces of algorithms involved in 3D vision. And don't even think about getting into this subject unless you already have a firm foundation in linear algebra, image processing, and computer vision in general as found in Computer Vision, which is my favorite introductory computer vision text.",24
Marina,1.0 out of 5 stars,Bayesian Reasoning and Machine Learning,"Very vague, inconsistent; circular definitions","It appears, the author has very vague ideas about what he is writing about. Here is just one example: definition of Markov network (page 59). ""For a set of variables ... Markov network is defined as product of potentials on subsets of variables ..."". So, Markov network is a function? Why is it called ""network""? Below he writes: ""Graphically this is represented by an undirected graph G with subsets ... being the maximal cliques in G"". The definition has nothing to do with the graph. How is this represented by a graph? The function is defined as product of potentials on some ""subsets"", why these ""subsets"" are represented as cliques graphically?

I could bring many more examples of such vague and contradictory definitions. Since the definitions are such a mess, he can not say anything definite about these objects.

Trying to read some more, I stuck in the next chapter, 5., section 5.1.1. ""Variable elimination in a Markov chain and message passing"". ""To develop this idea, consider the four-variable Markov chain (Markov chains will be discussed in more depth in Section 23.1)"". So, to understand chapter 5, read chapter 23, to understand chapter 23, read all the chapters before it. Good luck with it.

It appears, nobody (including the author and editors) ever tried to read this book.",24
Robert Jones,4.0 out of 5 stars,"The Emotion Machine: Commonsense Thinking, Artificial Intelligence, and the Future of the Human Mind",A Review of Minsky's THE EMOTION MACHINE,"Anyone working on cognitive systems will want

this book in their library. In reviewing THE EMOTION

MACHINE there are two lines of criticism that seem

important. Firstly, with the behaviorists I would

argue that introspection is both frequently inaccurate

and unscientific. Secondly, and more significantly,

most of Minsky's theories have not been developed to

the level of detail needed in order to formulate

actual algorithms. (To be fair there is Riecken's

""M system"" (in SOFTWARE AGENTS, J. M. Bradshaw, Ed.,

MIT Press, 1997) and Singh's thesis (EM-ONE, PhD

thesis, MIT, June 2005) which are at least a start in

that direction.)

On the positive side I am in general agreement

with Minsky that thought can be decomposed into

subroutines like:

remembering (search)

generalization

comparison

explanation

deduction

organization

induction

classification

concept formation

image manipulation

feature detection

analogy

compression

simulation

value assessment

My list appears in Asa H: A hierarchical architecture

for software agents (Transactions of the Kansas

Academy of Science, vol. 109, No. 3/4, 2006). Minsky

calls these ""ways to think"" and a partial list

appears on pages 226-228 of THE EMOTION MACHINE.

My own Asa H software uses exactly these mechanisms

but my architecture is not nearly as complex as

what Minsky is looking for.",24
Robert S. Newman,5.0 out of 5 stars,"Modern Multivariate Statistical Techniques: Regression, Classification, and Manifold Learning (Springer Texts in Statistics)",A great step forward in the way we look at multivariate data,"This book surprised me. I was expecting a book filled with a discussion of mostly traditional multivariate techniques supplemented by a few chapters of more recent developments. Instead, I found a completely new and refreshing approach to statistics and data exploration that framed the classical regression approach to most issues as a special, limiting case of a broader view of data exploration and analysis.

Sections on random vectors and matrices, nonparametric density estimation, tree methods, ANI, support vector machines, random forests, bagging and boosting, latent variables, manifold learning, and other topics are discussed and explored in adequate depth for an introductory text. The book assumes you know matrix algebra and have had some exposure to probability distributions, and common multivariate methods, but it extends the discussion in areas that are usually only covered in separate advanced texts and research papers.

The book is a little light on Bayesian methods but some compromises had to be made considering the bulk of the range of new material discussed. I especially liked the broad array of examples from genetics, medicine, physics, and other application areas and the nice color graphs where needed. The references to Matlab, R, S-Plus and other standard math packages was much appreciated although I would have liked Mathematica to have been included as well.

Overall, this is a wonderful survey of a wide range of multivariate techniques and methods. I hope it gets incorporated in college grad and undergrad courses.",24
Michael Yasumoto,2.0 out of 5 stars,Discrete Mathematics (5th Edition),Comparison of the top 3 Discrete Math Texts,"I have read ""Discrete Mathematics"" by Epp, Rosen and Ross which are the three most common discrete math texts that I encounter at university.

Of these three, I would rate Epp's book as my favorite because it has the clearest explanations and is so easy to read that you can't help but feel like you understand all of the content completely. The only failing that Epp's book might have is that it is not as thorough in its coverage of the material as some of the more technical books. I would say that it covers about 90% of the material and leaves out some of the more obscure topics.

Rosen's book would be the most thorough, covering every topic in meticulous detail and offering a jumping point for other texts in cryptography and number theory. Although this book is more complete than Epp's, it is also less readable and requires more effort to get through. Ideally you would use Epp's book to learn the material and then go to Rosen's book for a technical reference.

For those of you who are considering Ross's book, I have one thing to say and that is don't. Although I have read this book and done a lot of the problems in the first 3/4 of the text, this book is neither clear in its explanations like Epp nor is it as complete as Rosen's book. If you are assigned this book for a course, my suggestion would be to buy Epp's book and photocopy the Ross homework problems from a friend's textbook.

Take the advice of someone who has read all three books. If you have to buy just one, then get the Epp book. It is better to understand 90% of the material completely rather than 100% of the material partially.",24
Zac,3.0 out of 5 stars,"The Elements of Statistical Learning: Data Mining, Inference, and Prediction (Springer Series in Statistics)","An overview of statistical learning methods, but not deep and not convincing","The authors of this book are certainly no nobodies in this area. However, this does not imply that they are able to write good books about statistical learning theory covering a broad range of methods.

In my opinion, the major problem of this book is, that it does not fascinate the reader. The opposite is almost true. One reviewer wrote, it is no book for beginners. Well, that is not my point. My point is, e.g., a chapter or section starts and the introduction provided to this topic under consideration is almost completely missing. Moreover, the explanations given in the main text are just not good. Sorry, it makes not much sense to collect and present a lot of deep results of scientific articles in statistical learning theory without the necessary explanations. One should not forget, each section corresponds roughly to one or even more articles. One would expect from the authors to provide a precise summary of the main points in an appealing way. Negative report! This is really sad, because, the colored illustrations provided in the book are just great.

Certainly, no bad book, because it provides definetely a quite good overview, but sadly not good to read and the explanations are not insightful.",24
M. Henri De Feraudy,5.0 out of 5 stars,Not Exactly: In Praise of Vagueness,A very readable introduction to the literature,"This is a particularly well written introduction to a certain part of the philosophical literature on vagueness.
The author refutes the idea that vagueness is a fault and presents a certain number of different approaches to the problem
explaining the advantages and disadvantages of each.
You can read this book in bits.
I have training in formal logic, so my view is perhaps a little biased, but all in all I have rarely seen a book by a philosopher in which the author bends over
backwards trying to explain subtle concepts and succeeds like this one.
My only niggle is the chapter on Artificial Intelligence which in my opinion spends just a little too much time (for my liking) introducing the subject before
getting into the approaches to vagueness. I was expecting to see Dempster-Shafer theory discussed and didn't find it.

Not only will you read about vagueness, but you should be better prepared to read works on analytic philosophy, in particular a good crash course on formal logic is given, but I'm not the best judge as to how clear that is, as I know much of that. I'm also glad to see he talks about the work of the great Hans Kamp who does very original and useful work in logic.

This is a fun book on a subject which is disquieting. It might well challenge some of your basic views on reasoning. I have a good friend to whom I read parts of this over the phone, it's that well written.
It's interesting that the author is not just a philosopher by training but also works in a computer science department of a university. This might explain why the book is clear: he has a goal of making software deal with vagueness.",24
Husam Abu-Haimed,2.0 out of 5 stars,Decision Procedures: An Algorithmic Point of View (Texts in Theoretical Computer Science. An EATCS Series),Disappointing,"I am very familiar with the field of decision procedures, but I bought this book to use it as a quick reference and a refresher in certain areas. However, when I read the book I was very disappointed. The only good thing about the book is the table of contents and the list of references. Many important results and theorems are missing. No explanations or derivations of any of the presented results are provided.

I was hoping that this book would be a good introduction (or reference) to the field of decision procedures, but unfortunately, going directly to the research papers is a much better investment of your time (and money).

The following references provide an excellent coverage of the field:

1. ""Constraint Processing"", by Rina Dechter. This is an excellent reference on Constraint Solving, which is similar to decision procedures, but focuses more on finite-domain problems.
2. ""Decision Procedures for Bit-Vectors, Arrays and Integers"", Ph.D. Thesis by Vijay Ganesh, 2007.
3. ""Searching for Truth: Techniques for Satisfiability of Boolean Formulas"", Ph.D. Thesis by Lintao Zhang, 2003.
4. ""Efficient Algorithms for Clause-Learning SAT Solvers"", M.Sc. Thesis by Lawrence Ryan, 2003.",24
Jeremy Kun,1.0 out of 5 stars,Machine Learning: An Algorithmic Perspective (Chapman & Hall/Crc Machine Learning & Pattern Recognition),Look elsewhere for a serious treatment,"In short: the content is worse than the corresponding Wikipedia articles, and his writing style is condescending.

Almost every chapter has less detail than the Wikipedia articles (and suspiciously similar prose), and Marsland doctors up the content with childish references to Goldilocks and the things you *obviously* didn't retain from high school. On every page Marsland babies the reader, fluffing the writing with constant reiterations of simple facts concerning perpendicular lines and counting methods. If you have any attention span at all, you'll find this book should be a hundred pages shorter.

Finally, and worst of all, his mathematical arguments are sloppy and his code contains errors. He asserts an elementary fact is true by saying that there is no reason to believe otherwise. At points he defines variables by closed-from quantities, but then in the python code he implements the same variables as summations.

The blurb on the back of the book claims Marsland provides complete information and adequate levels of rigor. After reading the book I can only interpret that as ""high school"" rigor. This book is clearly geared toward math-phobic computer scientists or people in other fields. I purchased the book because it has a high rating here on Amazon, but at least for me (a frequent hobbyist in programming with some mathematical know-how), a book like Forsyth is far more appropriate, despite its awful ratings.

This book may have its place, but if you have any desire for a rigorous treatment, try something else.",24
Amazon Customer,3.0 out of 5 stars,Python Machine Learning,"Nice Effort, But Divided Priorities Trip Up This Title","Context for this review: I have over 20 years professional experience in inferential statistics / machine learning.

This book is an introduction to machine learning via the Python programming language.

Good:
- Unlike some other machine learning titles, this one includes explanation of alternative error functions.
- Mention of a variety of libraries beyond the popular few, such as Theanos and Keras.
- Some exploration of GPU computing, with enough detail to permit the reader to experiment with this.

Bad:
- The machine learning coverage is broad but shallow. This is too ambitious for a single book (given that half of the book is on Python)?
- Coverage of data sampling (from the statistical universe) is non-existent.
- The index is inadequate.
- Instructions for installation of Python math/machine learning libraries were meager.

Note:
Despite other Amazon reviews, I found the formatting to be fine, and the diagrams to be perfectly suitable. If there were issues in these departments, I suspect they've been ironed out.

Bottom line: This book tries to serve two masters: It proposes to teach machine learning, then implementation of the same within Python. My long experience with such books is that they provide a luke-warm version of each (at best). This title continues that pattern.",23
Burress Family,5.0 out of 5 stars,Amazon Echo: Master Your Amazon Echo; User Guide and Manual,Excellent and easy to read.,We received an Echo Tap as a gift. We found this book to be a great extension of the instructions to set it up. As a result we are more able to fully u derstand all of Alexa's capabilities and have a quick reference on how to change settings to customize Alexa to our various household members and a way for our daughter to access her account when she's visiting g.,23
Christi Sullivan,5.0 out of 5 stars,Amazon Echo: Master Your Amazon Echo; User Guide and Manual,Five Stars,Was very informative and a great price.,23
Josh Carlson,5.0 out of 5 stars,Amazon Echo: Master Your Amazon Echo; User Guide and Manual,get a head start on your Alexa,"This book is a great guide for understanding the ways on how to use your Amazon Echo. This is a made-easy book for beginners that find it hard to begin with the use of Amazon Echo. With the help of this book, we'll easily get acquainted with the proper usage of our very own Alexa. This is a great user guide and manual. It helps a lot and makes the tasks easy. This is a bestseller for me.",23
Dr. Lee D. Carlson,1.0 out of 5 stars,Our Final Invention: Artificial Intelligence and the End of the Human Era,Won't do,"Anyone who has indoor plants has no doubt run into the problem of proper lighting, with the need sometimes to use artificial lighting. There are several ways in which this might be done, depending on the imagination of the plant lover: 1. One method is to put the plant under a lamp, which is then turned on and off by the plant lover. 2. For those who do not want to remember to turn the lamp on and off, there are devices on the market whose timing can be set by the user to turn a lamp on and off. The actual time that the lamp is on can be set in these devices, according to recommendations given by a plant expert of botanist.

3. Suppose now that this device was modified so as to contain information about the lighting needs of the plant, an Aphelandra squarrosa for example, and that the device was able to turn on and off and vary its lighting intensity based on the judgements of a plant expert. Suppose also that the device is able to compare the efficacy of its ""light curve"" on the health of the Aphelandra with others grown under light controlled by a device of the same kind. The actual comparison is done under the instigation of the plant lover, and the device can then change its light curve based on the results of the comparison.

4. Suppose that the device is further modified so that it can make the comparison itself, namely it judges whether the difference in light curves on the health of the plants is significant and then alters its own light curve appropriately. Its judgements are taken independent of the plant lover or plant expert, and are based on historical or experimental data it has access to.

5. As a further modification to the device, suppose it can now formulate a set of hypotheses that explain the effects of this type of artificial light generation on Aphelandra squarrosa. The device generates these hypotheses and formulates theories based on the instigation of the plant lover. For example, the plant lover may want to know how the health of the Aphelandra would be affected by changing the lighting conditions, without having to do the testing herself. The device can also formulate light requirements for plants other than Aphelandra squarrosa.

6. Suppose a further modification gives a device that can use the information on light curves of plants to understand the effects of light on other physical entities. The device can find common elements of behavior in the response of plants to light and the response of these other entities to light and formulate a set of hypotheses based on these elements. The device attempts to formulate these hypotheses based on the instigation of an interested human party. A typical plant lover would probably not want this kind of information, but a scientist or botanist might. The device would probably be too impractical to a typical plant lover and its additional ability therefore useless for general home use.

7. The device is further modified so that it is curious about the effects of light on entities, whether these entities are plants or something else. It tries to formulate theories on its own, independent of any external interested party. Such a device might be able to formulate procedures, based on genetic engineering, for altering the biochemistry of Aphelandra squarrosa, so as to make it more resilient as a houseplant, possibly needing less light or a radically different light curve.

8. The device is modified so as to be able to self-manage itself, such as its power requirements. In addition, it can send a set of instructions to a manufacturing facility that will manufacture copies of itself, or it might recommend its own design be altered and then manufactured, with recommendations being based on designs it generated.

It might be fair to say that these eight types of devices are very different, qualitatively speaking. The first type of device is incapable of solving problems but is more of a simple switch. The second type of device represents a machine that can find answers to domain-specific problems but does not compare these answers to any standards. Machines of this type do not attempt to check their answers or correct them. The third device represents machines that find answers to domain-specific problems and check their answers to these problems according to standards that are given to the machine from an external source or standard. The fourth device represents a machine that is able to check its answer to domain-specific problems and make judgments as to the quality of these answers, and do so independently of any external standards.

The fifth type of device represents machines that are able to judge the quality of their answers to domain-specific problems and then propose theories or explanations that subsume these problems, whereas the sixth type of device is able to solve problems having their origin in more than one domain, but their attempt takes place only under the instigation of an external inquirer. The seventh type of device expresses curiosity and creativity, can solve problems independently without any external instigations, and can develop theories of explanations around these problems. Finally, the eighth type of device represents machines that can self-manage and self-replicate,and have all the abilities of machines of the seventh type.

In analogy with human reasoning one might argue that as one goes from the first type to the last the intelligence increases. But if one insisted upon a quantitative measure of just how much ""smarter"" the last type of device is than the first, then this would be difficult, since no such measure has yet been devised in the field of artificial/machine intelligence.

And the lack of such a measure is the predominant reason why the thesis of this book is problematic and needs to be rejected. There are many places in the book where the the author speaks of ""super intelligent"" machines as being a thousand or a trillions of times more intelligent than humans, but no where in the book is there any discussion of how this is to be determined. The author does refer to machines taking IQ tests, and the reader is evidently supposed to surmise that it is the use of these tests that will enable one to determine the time when a machine ""could match and then surpass human intelligence."" No where in the book though is an example given of a machine, either existing or projected into the future, that has taken one or more IQ tests and therefore shown to be ""intelligent"" to the degree to which these types of tests measure intelligence (if indeed they do). This is also an indication of the great need for the field of artificial intelligence for a rigorous ""theory of intelligence"" that would allow researchers and engineers to assess more quantitatively the difference between what is called AGI (artificial general intelligence), and domain-specific intelligence.

Again, qualitatively speaking, one could argue that there are many machines today that exhibit domain-specific intelligence, such as those able to play chess and backgammon, perform financial analysis and trading, regulate and troubleshoot communication networks, and find interesting patterns in genome data. These are just a few examples, and apparently the author wants to base his case for what he believes will be ""super intelligent"" machines on the proliferation of these types of machines in everyday life, as indeed they are. It is true that are lives are dependent on the output of these machines, such as credit scores, financial trading, medical diagnostics, etc. It is quite a stretch though to argue that this massive proliferation of domains-specific reasoning machines will result in machines that can reason over many domains (AGI) without substantial re-writing of their ""brains"". The author is clearly fearful that this will occur, but he has given no absolutely no hint on how this is do be done.

Instead, the author relies on the opinions of experts who work in the field of artificial intelligence, and also gives figures on the funding levels of research in AGI. If one checks the reality of this funding, there are certain instances where one can verify the figures, but to say as the author does that ""billions"" are being spent on bringing about human-level intelligence in machines. In addition, opinions of experts are valuable in assessing their comfort level on advances in artificial intelligence, but if one is to build a sound case for the ""intelligence explosion"" that the author claims will happen, one will definitely need to offer a more quantitative case. The Vinge/Kurzweil conception of the ""law of accelerating returns"" and the associated concept of a technological ""singularity"" is with each passing year looking to be more of a sophisticated marketing campaign rather than sound science, and reliance on these conceptions is not bringing about a theory of machine intelligence that is practical and sound.

There are also a few other difficulties in the claim that super-intelligent machines are destined to be our ""final invention"", mostly coming from basic physics and the manner in which scientific research and results are obtained. There are thermodynamic considerations and energy requirements that need to be addressed if such machines are to operate creatively in bringing about new scientific knowledge and practical products. A ""super-intelligent"" machine engaged in scientific research will need to conduct actual experiments, this being essential to science rather than just thoughtful musings, and this will require space, instrumentation, and a substantial amount of energy. These kinds of machines will also be subject to the ordinary laws of thermodynamics, and will have to deal with the heat they generate when such an ""intelligent explosion"" occurs.

One might ignore all of these considerations and take the author's case as one that is more of a warning, just like some scientists had sounded off during the development of nuclear weapons. But to argue that super-intelligent machines are the biggest threat to our existence is to ignore the fact that it is the dumbest entity in the world today that has that privilege, namely the ordinary biological virus.",23
Trevor Burnham,5.0 out of 5 stars,The Annotated Turing: A Guided Tour Through Alan Turing's Historic Paper on Computability and the Turing Machine,Rich and surprisingly accessible,"Don't let the title fool you: This isn't simply Alan Turing's groundbreaking paper ""On Computable Numbers, with an Application to the Entscheidungsproblem"" with a handful of footnotes thrown in. While the paper is contained here in its entirety, there is, on average, about a paragraph of explanation for each line of Turing's prose. And before that, there is an extensive introduction to important concepts, starting with the distinctions between rational, irrational, algebraic, transcendental, and computable numbers--all explained in terms that any intelligent undergraduate should be able to understand. No mathematical background is assumed beyond algebra.

The Annotated Turing exceeds even the best undergraduate textbooks in explaining these concepts clearly yet concisely, and in doing so sets up the historical context that Turing worked in. When there is an interesting story to tell about Hilbert or Russell, he tells it. (Russell's life was, after all, sufficiently fascinating to be the subject of a recent comic book, Logicomix.) Those with a more extensive mathematical background will want to skim the early sections, but shouldn't skip them entirely.

What Douglas Hofstadter's G??del, Escher, Bach did for G??del's Incompleteness Theorem--a crucial discovery that was poorly understood outside of the domain of professional mathematicians--Petzold's book does for Turing's universal computer. If you have any interest whatsoever in the theory of computing, make this the first book you read.",23
Todd B.,3.0 out of 5 stars,"Data Mining: Practical Machine Learning Tools and Techniques, Third Edition (Morgan Kaufmann Series in Data Management Systems)","Good Content, Poor Electronic Format","I was really looking forward to the new edition of this book, but I've found that the Kindle version has unreadable tables and figures that are too small to make out. Many of the equations are almost completely illegible. I should have purchased the hardcopy.

The content, on the other hand, is very well written and accessible. Great book; terrible Kindle edition.

Note: I have a first-edition Kindle, which could account for some of my problems, and the Windows desktop version works great. It's just too bad that I have to run a Windows virtual machine just to see equations from a book I purchased.",23
Andrew Petrarca,5.0 out of 5 stars,Turtle Geometry: The Computer as a Medium for Exploring,My favorite geometry textbook,"I discovered this little gem of a book while exploring the stacks in the library when I was attending a local junior college back in the 80's. The author uses Logo's turtle graphics as a way of exploring the properties of geometric space. From very simple beginnings drawing regular polygons and other simple shapes, the book gradually works its way to more and more complicated scenarios. After exploring the properties of ordinary turtle graphics, turtle graphics are tried on the surfaces of spheres and cubes, then on more complicated surfaces. Little by little, concepts of non-Euclidean geometry are introduced, until the final chapters in which the turtle is used to demonstrate the geometric nature of gravity in Einstein's general theory of relativity.
I strongly recommend this book to anyone with interests in computer programming, geometry and physics. The unusual approach this book takes to the understanding of curved space is deceptively simple and surprisingly powerful.",23
Peter Andrews,5.0 out of 5 stars,Blondie24: Playing at the Edge of AI (The Morgan Kaufmann Series in Artificial Intelligence),Well written and intelligent. AI as it should be.,"I once took an introductory AI course (Brown '84, Professor Eugene Charniak) and was immediately turned off when, during the first lecture, the professor said that we would not cover learning. To talk about intelligence without learning seemed misguided. Blondie24 shows the power of learning in an organic, evolutionary way.
David Fogel gives a broad overview of the origins of the main approaches in classical AI. He explains how many approaches fell into a seductive trap of top down planning. His own approach uses evolution as a powerful tool for learning. Learning from the experience of life on earth, he proves that selecting simply on whether his chess program wins, loses, or draws over multiple games is sufficient to allow considerable learning. This is a powerful lesson that should be applicable across any discipline -- not simply checkers.
David writes simply and clearly and with respect even for the AI pioneers whose approaches he disagrees with.
Blondie24 has inspired me to read more on this subject. It is thought provoking -- I now want to start doing my own experiments in evolutionary programming to explore the ideas further.
P.S. I found that ""Creation : Life and How to Make It"" by Steve Grand to be an excellent follow up read to Blondie24.",23
Ken L,5.0 out of 5 stars,Blondie24: Playing at the Edge of AI (The Morgan Kaufmann Series in Artificial Intelligence),"Fascinating insight into ""Real"" AI","This book is a must-read for anyone even remotely interested in Artificial Intelligence. Blondie24 is the story of how real machine learning created an expert checkers playing program. Instead of the traditional method of hand-coding human expertise about a game, Fogel set out from the start to have his program learn to play checkers without any human coaching except for the basic rules of the game. Starting from nothing but randomness, different checker playing program candidates competed with each other in a ""survival of the fittest"" tournament, evolving better players over time. The end result was an expert-level checkers-player.
As Dr. Fogel eloquently points out, the most impressive thing about Blondie24 is not the high level of play it achieved but the methodology used to get there. Computer programs that can teach themselves to solve problems!
A very readable book on a fascinating topic.",23
Frank J. Regan,2.0 out of 5 stars,Mastering MATLAB 7,evaluation of Mastering MATLAB 7,"I have been a user of MATLAB for maybe ten years and have purchaed many third party books on MATLAB over that time. I found the text Mastering MATLAB 7 to be at best only fair. It might have some value (and there are other books with more value) as a review of specific features of MATLAB, but when it covers new territory it is a poor or at best a fair choice. For example the section on differential equations (Chapter 25) is little more than a rehash of the MATLAB help menue which is to say it could have been copied out of the MATLAB users manual. The value of a third party book (as opposed to the users manual) is that it should be a tutorial and a ""fill in the blanks"" that not present in the manufacturers literature. I had been trying to stop a six state integration when one of the states goes to zero; I find the material in said chapter worthless. If you buy this book looking for a tutorial you will find it usually poor and at best only fair. The book is a great disappointment to me.",23
A. Perrier,2.0 out of 5 stars,"The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Second Edition (Springer Series in Statistics)",A frustrating experience,"I was happy to discover that I was not the only one struggling with this book.
I have a PhD in Math and more particularly stochastic processes and everytime I open this book I can't quite understand what the content is.
I've read other Machine Learning books with the same level of math and abstraction and did not encounter this difficulty. 'Boosting' by Schapire and Freund for instance.
The flow of the text is hard to follow. A lot of Jargon is used assuming the reader is already familiar with the notions exposed.
I think I will end up making sense of the text only after I've been working in the field for many years.",22
Michael Prall,5.0 out of 5 stars,Amazon Echo: Master Your Amazon Echo; User Guide and Manual,Love it. Very usefull,Love it!!! Very useful book.,22
Milan G Hejtmanek,1.0 out of 5 stars,Machine Learning: A Probabilistic Perspective (Adaptive Computation and Machine Learning series),Kindle version is still the first printing,"As of February 2014, the kindle version has not been updated in the slightest, unlike the hardcover edition, now in its 4th printing, with many errors corrected. Amazon cleverly hides this fact from would-be purchasers, by giving only the hardcover in preview.",22
anonymous,1.0 out of 5 stars,Make Your Own Neural Network,"Self published, low quality, and very little content for the price","People purchasing this should be aware that it is self published. As far as I can tell, the positive reviews must all be the author's friends/family, or fake accounts for padding. The book is 210 pages long, but most pages have only 2 or 3 paragraphs and oversized graphics when the content even fills the entire page. It can be read cover to cover in less than an hour. Quality of the paper and ink is very low.

I don't have anything against self publishing in general. I've purchased self published books before and appreciated them. But in this case, combine the price, lack of content, low quality, and fake reviews, and I'm a little annoyed I was taken in by it. Luckily Amazon is very good about returns.",22
the1dabread,3.0 out of 5 stars,Programming Game AI By Example (Wordware Game Developers Library),Wish i could spend more time on it...,"Likes:
- How the author only deals with AI game programming and doesn't put in a lot of fluff
- The broad range of topics the book covers
- The use of actual 2D examples and an actual game ""Raven""

Dislikes:
- Use of ""helper"" files that have no explanation in the book (some are explained in previous chapters but the author should have included an appendix to list and explain all the files in the common directory)
- The code explanation is shallow when you consider the fact that the author neglects to tell you about the, many and crucial, other files that are needed to run the program.
- The actual code that can be downloaded from the web site needs a lot of tweaking before it even works (you should just be able to unzip it and run it).
- Chapter 3 and how the author only includes the source code for a final all encompassing program instead of smaller easier to understand projects.
- If you don't know Win32GDI then learn because the book uses it extensively to output to the screen, and that can interfere with understanding the actual meat of the program.

Summary:
If you are going to buy this book make sure you have a lot of time on your hands to look through the source code, tweak it, and pull it apart. The book itself just doesn't give enough explanation to allow a person to create their own version of the concepts without digging through the source code. Overall I would recommend the book to people with an intermediate knowledge of C++ and have very good 2D math skills. This book is a fine overview of major topics in game AI but is sorely lacking (add another 100 pgs of quality explanation on topics). It would probably be necessary to buy other books that are more specific in their focus.",22
Brookemeister,5.0 out of 5 stars,"Artificial Intelligence for Humans, Volume 1: Fundamental Algorithms",A good primer for AI,"I've wanted to better understand artificial intelligence for a long time. This book has opened the door for me. It requires a little mathematical aptitude, but little else, as the author starts with basic concepts and gradually builds on them. I like the examples and illustrations. They helped me digest and build my understanding one step at a time.

I've been in contact with the author and found out that, with self-publishing, you can pretty immediately turn around reader feedback and make incremental improvements to the book. Since I bought the book last month, a number of improvements have already been made.",22
Mark P. McDonald,3.0 out of 5 stars,On Intelligence,"The mechanics of your mind, but not on the top of my list","On intelligence is a good book and an engineer's discussion of how the brain works, processes information and experiences the world. For people wanting to understand how ""wet ware"" works then this is on the reading list.

The first two chapters are a waste of paper as they discuss Jeff Hawkins personal interest in the subject area -- so skip them. The remaining chapters are a good discussion of the physical properties and processes of the brain. Unfortunately these are presented as forgone conclusions and the final word in brain science, something that Hawkins admits is still really incomplete. Also Hawkins presents the material as if he invented it all, something that detracts from the power of the message.

The discussion is repetitive in places and surprisingly conservative in its outlook -- for example only humans have language, only humans are intelligent. That was a surprise that as the book seems to be fairly open on other issues.

The notion that the neocortex can basically learn anything and has few preconceived notions or hard wiring will provide ample ammunition for behavioralists and those who believe that behavior is learned and not part of nature.

In summary, I found myself skimming much of the discussion on particular ways things work as I can always go back and read it again. This makes for a good book, one that I am glad that I have read, but one that I would not recommend going out of my way to read.",22
Native of Neptune,4.0 out of 5 stars,The Lambda Calculus. Its Syntax and Semantics (Studies in Logic),The ultimate full treatment of untyped lambda calculus,"INTRODUCTION
This review was restarted on Thu 15Aug13 during actual reading of this book.

I am somehow quite motivated to learn lambda calculus, since it is so historically important and also closely related to functional programming languages. Plus it is interesting for its own sake.

THIS BOOK VS. OTHER BOOKS ON LAMBDA CALCULUS
Other textbooks on the subject, of which I own several, never get around to helping us learn what lambda expressions are actually telling us. Those expressions remain pure gobbledegook. I am well into reading chapter 2 of this reprinted famous 1984 edition by Henk Barendregt and the fog is already starting to clear. In many places, the author didn't write a lot of descriptive prose, but when he did, there always seemed to be a great insight in it. So be aware of that good bang for the buck.

Another thing I like about the approach here is that combinators mostly flow out of lambda calculus instead of being a fully separate subject of equal status to lambda as in the other good standard text by Hindley and Seldin, which I read into chapter 10 in fall of 2011. Lambda-Calculus and Combinators: An Introduction ((Historically, lambda calculus and combinatory logic WERE invented and developed separately, starting in the 1930s. Lambda by Alonzo Church and his illustrious students at Princeton / combinatory by Haskell Curry and colleagues, some of them during his sojourns in Holland and Gottingen.)) By the way, Haskell Curry is still noteworthy, as the Haskell functional programming language is named after him, and there is another computation method referred to as 'currying', again after his last name.
_________________________________________________________________
READING THIS BOOK

PART I AND READING PLANS
Finished great chapter 2 on conversion on Sun 18Aug13 / barely started chapter 3 on reduction. Chapter 3 is as well-written and clear as chapter 2 was. Finished short and great chapter 4 about theories on Tue 3Sep13. Chapter 5 on lambda models is the last one in Part I, is over 30 pages long, and is fundamentally more difficult than any of chapters 1-4, so since I don't plan to read the Part V chapters of 18-21, I am skipping chapter 5 to start Part II with chapter 6 on classic lambda calculus. I did read the survey of Part V at end of chap5 on Thu 5Sep13 afternoon, however. I hope to continue understanding this book at least thru chapter 9 of its 21 chapters.

PART II-CONVERSION
Chapter 6 on classic lambda is a gem of mainstream lambda calculus including a little bit of abstraction. Finished chap 6 on Fri 13Sep13. On Sun 15Sep13 afternoon, I well started short chapter 7 on combinators. Rather unusual, and stripped down to a tedious definition/theorem/proof bare bones approach. By section 7.2 though more clear and helpful writing returned to moderate extent. Did push thru the last 5 pages of chapter 7 on Wed 18Sep13 afternoon. Chapter 8 on more of classical lambda calculus soon, as I am a bit focussed on finishing final chapter IV of The Foundations of Mathematics (Logic). Enthusiastically got started on terrific chapter 8 on Wed 25Sep13 evening, so more later. Sections 8.1 and 8.2 were well written and quite interesting. Section 8.3 though is one of those fully Definition/Theorem/Proof (DTP) shuffles, a student-unfriendly type of writing. Difficult section 8.4, not just DTP all read, completing chapter 8 on Tue 8Oct13 evening. Chapter 9 on lambda-I calculus is completely DTP and the proofs tend to be getting longer, so my reading of this book unfortunately ended at end of chapter 8.
____________________________________________________________________
MISCELLANEOUS DETAILS
It really is great to be able to purchase this thorough and legendary book for a reasonable College Publications price, and I have found that CP makes rather durable paperbacks, i.e., more durable than similarly priced Dover books.

Since atypically for books on the CP roster, the Amazon page for this book is somewhat open in their 'Look Inside' utility, I shall not type in a version of the complicated table of contents as I often do in my reviews. Please check that 'look inside' for the full TOC. There are five 'Parts' of this book, each containing at least two chapters. Chapters 2-5 in part I introduce the main subjects of parts II thru V, and they each end with a small survey of the corresponding main Roman numeraled 'part' of the book.

Here is the list of the five parts: I Towards the Theory-1 (chaps 1-5) / II Conversion-129 (chaps 6-10) / III Reduction-273 (chaps 11-15) / IV Theories-409 (chaps 16-17) / V Models-467 (chaps 18-21) / Appendices-557 (A-C) / Full set of references and of indices.
______________________________________________________________________
THE NEW BOOK
On Thu 19Sep13 late afternoon, I received the new 2013 Lambda Calculus with Types (Perspectives in Logic) from Amazon. I am a member of the Association for Symbolic Logic (ASL), the co-publisher of this 850 page volume. Barendregt, Dekkers, and Statman are the main authors, but quite a few other experts also contributed. It combines familiar notation from the present book with some nice type tables similar to those in Benjamin Pierce's great 2002 type theory book, quite a bit of which I have read. The Amazon 'Look Inside' utility for the new book is notably open for large examination of it.",22
S. Jasin,1.0 out of 5 stars,"The Elements of Statistical Learning: Data Mining, Inference, and Prediction (Springer Series in Statistics)",Not the best textbook for a class,"I used this book for my stats course at Stanford. While I do enjoy reading parts of the book, I have to say that I am rather dissappointed with the presentation in the book.

1. This book assumes that you already have some background and quite a bit of familiarity with the subject

2. While it contains many topics, most materials are only ""presented"" rather than ""clearly explained"". And so, while it may be good as a reference book, at least for me, this definitely shouldn't be your main resource when first studying the subject.

3. Definitely the authors are expert on the field and I just hope they would come up with a much better revision of the book

4. One nice feature of the book ... it contains pretty picture! Unfortunately, just like the old saying, ""a picture contains a thousand words"". Thats exactly what happens here. Some of the pictures are hard to understand.

It may or may not be fair to give this book 1 star (I might update my rating in the future). But the simple truth is that I am not impressed when I first read the book. It surely falls below my expectation from such a highly acclaimed book.",22
tacfire,5.0 out of 5 stars,"Decoding the Universe: How the New Science of Information Is Explaining Everything in the Cosmos, from Our Brains to Black Holes",Great Read...!,"Great Book, But...!

Quantum mechanics made fun and easy! I guess all those ""Physics for Dummies,"" books paid off `cause Seife really makes it all understandable!

However...! I was thoroughly vexed by Seife painfully contradicting himself regarding the first law of thermodynamics and the Big Bang.

Page 31, after stating very clearly that energy cannot be created or destroyed, he footnotes (4) ...""But all the energy (including Einstein's mass-energy) currently in our universe was created with the big bang, and that amount hasn't changed since the universe's birth.""

Note the ""was created,"" in the passive voice.

So, if mass-energy can't be created or destroyed, how ""was"" it created and by whom/what?

All through his book ""Zero,"" Seife seems to deride the West for avoiding zero out of fear of nothingness, the void, infinity-G-d. That fear strangled mathematical and scientific advancements for a millennium. Yet here he makes an assertion with the similar fear-induced tone.

Here's the brutal heresy that Seife dares not state:

Why is there ""something"" rather than ""nothing?""

Perhaps because ""nothing"" is a concept with no physical reality. Perhaps because the amount of mass and energy are the ""entropic reality"" for our universe.

By simply applying the First Law of Thermodynamics that states that matter and energy cannot be created or destroyed, our universe has always existed in some form, with the exact same amount of energy and matter. The Big Bang explains our universe's current viewable configuration.

Sadly, Seife dares not state this obvious axiom, perhaps fearing that he is entering the No G-d domain!

Look in mirror wild-man! It isn't just the ""Dark Ages"" Europeans that feared knowledge!

Other than that..READ THIS BOOK!!!",22
Gene Leynes,4.0 out of 5 stars,Data Analysis and Graphics Using R: An Example-Based Approach (Cambridge Series in Statistical and Probabilistic Mathematics),limited review...,"I found this book to be quite useful for learning R, and for pointing out the pitfalls for new users. It's especially good to know that there is a website associated with the book that will allow you to download the code used in the book.

There are several good free R resources out there, but in the end I think you get what you pay for. In this case it was nice to have a hard-bound reference with an index and appendix that I could highlight and dog-ear.

I mostly used it as a book for learning R, and not as a stats book. I did notice that there were many good examples of common statistical applications, such as t-stat tests, residual plotting, and the like. In other words, I feel like I got my money's worth by just using a few chapters and the appendix.",22
R.B.,5.0 out of 5 stars,Mindware: An Introduction to the Philosophy of Cognitive Science,Great Overview of Cognitive Science,"This book was recommended to me by a cognitive scientist researcher at my university as the single best thing I could read to obtain an up-to-date overview of what's going on in cognitive science. The book lived up to this promise. I found it an excellent, scientifically and philosophically informed, treatment of this topic.",22
bravhat1234,3.0 out of 5 stars,Alan Turing: The Enigma,A Frustrating read,"Alan Turing: The Enigma by Andrew Hodges covers a fascinating and important subject in the life of Alan Turing, but I would not recommend it to a math layman like myself. Much of the book outlines the history of mathematical and scientific ideas of the first half of the 20th century, Alan's included of course, as well as describing the machines that he helped design and build. This makes for extremely rough reading, especially since the book is over 500 pages. I commend Hodges for the large amount of research that went into this book especially since Alan was so secretive.",22
BAYANG,5.0 out of 5 stars,Practical Optimization Methods: With Mathematica?? Applications,My Optimisation Companion,"Practical Optimization Methods - M.Asghar Bhatti

This is my favorite optimisation book. I recommend it to anyone interested in the application of optimisation techniques, in particular for those in industry. This book has been a constant companion in my optimisation adventure and unlike other books; it has helped me firmly establish a solid foundation and understanding on the various optimisation techniques and the theories behind them. Believe me, I can even read those books which I have shelved in the past because they were complicated with too many cryptic mathematical statements. They don't scare me anymore.

Bhatti wisely used Mathematica as the teaching platform and the accompanying OptimizationToolbox software allows one to brush aside the cryptic mathematical statements. The reader can now concentrate on the concepts, relegating the mathematics manipulations to Mathematica and the functions of the OptimisationToolbox. What I like about this book is that it also shows how the Taylor Series, the Quadratic Form and convexity requirements are put into practice to create an iterative scheme to solve a system of non-linear equations. The OptimisationToolbox and the internal Mathematica functions seamlessly pace the reader through the mathematical preliminaries. By the end of Chapter 3, the reader should now be a good shape to go to the more serious stuffs.

Chapter 4 deals with the subject of optimality conditions starting first with the optimality conditions for unconstrained optimisation problems. These conditions, albeit slightly more involved in computation, are essentially the same as the optimality conditions for single variable functions of the high school days. The ""slightly involved"" computations are those of the Grad (1st Order and Necessary Condition) and the Hessian (2nd Order and Necessary). Mathematica graphics are put to great effect to help visualize the meaning of these conditions.

The additive property of constraints, which was dealt with in graphic detail, extends the earlier ideas behind the optimality conditions for an unconstrained optimisation to that for constrained optimisation problems.

The introduction to Chapter 5 gives an excellent overview of issues in solving unconstrained problems. Basically, all solution schemes covered in this chapter involve two steps. The first step is a simple iterative scheme, which requires a direction and a step length. The second step is a termination condition, taken as when the gradient of objective function, which should be zero at the optimal point, is sufficiently close to within a specified tolerance to zero.

The process of computing the step length in for a particular search direction is known as the line search. The line search methods (including Mathematica algorithms) covered include analytical line search, equal interval search, section search, the Golden Section search, the Quadratic Interpolation Method and the Approximate Line Search based on Armijo's rule.

As for the search direction, one obvious choice would be along the direction of greatest negative change - the Steepest Descent Method. The performance of this method can suffer badly as it zigzag search scheme slows down to a crawl as it approaches the optimal point. One improvement would be to retain some potion of the previous search direction, so the resultant search pattern is not successively perpendicular to each other but somewhere in between. This approach of adding some potion of the previous direction is known as the Conjugate Gradient Method. The two ""some previous direction potion"" schemes covered and included as Mathematica functions are the Fletcher-Reeves and the Polak-Ribiere schemes. Other numerical methods covered include the Modified Newton and the Quais-Newton Methods. One drawback of latter approach is the computation of the Hessian Matrix at each iteration step. The Quasi-Newton Methods do not require the computation of the Hessian Matrix. Instead they use some inverse Hessian update methods. Two such methods covered are the DFP (Davidon, Fletcher, and Powel) Update and the BFGS (Broyden, Fletcher, Goldfarb, and Shannon) Update. Don't be intimidated by all these jargons, Mathematica functions including graphic functions are provided to provide a step-by-step explanation and presentations of the various concepts are provided.

The section on Linear Programming is extensive, in comparison to other chapters. I was tempted to skim over this LP section because the technique is well known and there are many industry standard LP algorithms on the market so why spend too much time on it. However, my curiosity got the better of me and I must confess that the combination of the accompanying OptimisationToolbox and Mathematica Graphics makes the revision on Linear Programming entertaining and interesting. The section started with an overview of issues involved in solving an underdetermined system of linear equations; going over the Gauss-Jordan, LU decomposition and introduction of slack variables to convert the LP problem into its standard form. The simplex algorithm is introduced in three styles: Simplex Tableau, Basic Simplex and Revised Simplex. The first two simplex styles, as Mathematica functions by the way, are intended to show the sequence of steps of the simplex algorithm. For large problems, however, the above LP methods may take a long time and researchers have developed better search methods such as the interior point method. The interior point method, as its name implies, starts from an interior feasible point and takes appropriate steps alone descent directions towards the optimal point.

Chapters 8 & 9 adequately covered the subject of quadratic programming and constrained nonlinear problems. However, they concentrated only on local optimisation techniques. Inclusion of global optimisation methods such as Simulated Annealing (SA), Genetic Algorithms (GA), Discrete Gradient Methods (DGM), Hooke-Jeeves, Nelder and Mead, and Powell methods would have made the book a complete guide to practical optimisation.

My favorite Optimisation Book - Clear and Useful",22
dolphone,2.0 out of 5 stars,"Superintelligence: Paths, Dangers, Strategies",No depth,"The most interesting thing about this book is how Bostrom managed to write so much while saying so little. Seriously, there is very little depth. He presents an idea out of nowhere, says a little about it, and then says [more research needs to be done]. He does this throughout the entire book. I give it two stars because, while extremely diluted, it does present an interesting idea every now and then.",21
D. Fountain,5.0 out of 5 stars,Amazon Echo: Master Your Amazon Echo; User Guide and Manual,A Great Find,I love Alexa. She answers many questions. I'm looking forward to having her read books to me.,21
W. James Dittmar,2.0 out of 5 stars,How to Create a Mind: The Secret of Human Thought Revealed,Arrogant and vague,"I am shocked at the high reviews for this book. There are a number of issues that make this book not even worth reading:

1. Kurzweil manages to somehow brag about his career on just about every page of the book. ""back in year xxxx, I was the first one to do this"".

2. Chapters 1-5 summarize hierarchal hidden markov models. He presents very little experimental evidence to suggest that this type of algorithm is employed by the brain besides his back of the envelope calculations.

3. Chapters 6-10 offer a hazy and amateur philosophical whirlwind summary of some topics like consciousness, identity, and free will.

While I ultimately agree with many of the points that Kurzweil makes, it feels like this book was written in a very haphazard and vague way.",21
Nader,5.0 out of 5 stars,Make Your Own Neural Network,The book is FANTASTIC! It takes you step by step of what ...,"The book is FANTASTIC !

It takes you step by step of what a neural network is, demystifies everything there is about Neural Networks, provides hands on examples, explains the code line by line and provides the complete code in python which is a simple intuitive language to understand.

This is all you want to learn these mysterious entities called Neural Networks.

I wish I had this book years ago.

This book is NOT DRY ACADEMIC SLEEP INDUCING drivel by some insecure Professor with not the slightest inkling of the real world.

This book is HANDS ON, PRACTICAL, INTELLIGIBLE.",21
Unbroken,4.0 out of 5 stars,Concrete Mathematics: A Foundation for Computer Science (2nd Edition),A Path to Redemption for a CS State Schooler,"I originally bought this book as a source of remedial study following the end of my US state school CS undergrad experience (I completed a BS Computer Science in 2013, > 3.5 GPA), and as preparation for V1 & V4 of TAOCP. I use the word remedial here in the sense that I felt that I was missing a critical foundation in the mathematical analysis and derivation of algorithms, even after the course-work of that degree. I've done 3 chapters of it in full, and I will mention a number of things that other reviews haven't talked about. Due to the horrendous time commitment of this book, I strongly suspect this is because those reviewers haven't actually worked through it, and have instead chosen to skim and allow Knuth fanboyism, along with the desire for mutual association, to cloud their opinions. I'm revoking a star simply to balance those reviews out, and so that graduates in similar situations have an actual informed critical opinion of this book to find among the reviews.

Take-Aways (As of Ch 3):

There are many aspects of summations, integer functions, and proofing that: I never saw covered in my CS degree, are unforgettable, and can be immediately applied to most algorithm research. Those alone make this book worth every penny. Further, the problems posed by this book are more than just repeated mechanics, as I have seen in books like those mentioned below. Each problem is carefully chosen, thorough, and exposes multiple aspects of each topic. They really do weed out many faults that I wasn't really exposed to- as a small example: the importance of ensuring validity of n-1 and n-2 hypothesis & base cases during an induction proof.

The Bad:

Students educated through a contemporary CS track at most American uni's, I believe, (e.g. Rosen Discrete Math, Cormen Algorithms) will find this book both terrifyingly terse and frustratingly paced. In many cases, examples are given without derivation. In many cases, important points are made without obvious connection to previous topics. This is not without a solution however, and getting through this book is often an acquired technique of paper noting things as-you-go, as well as a learned hyper-literacy. The terseness is also a double-edged sword, as sometimes I found it useful as an extra opportunity to practice the taught methods to see if I could come to the same result. Further, the reader should be prepared to go back and review propositional logic & university calculus theorems (atleast FTC, definite vs indefinite integrals). For example, the description of sum by parts in the section on finite calculus assumes _much_ from the reader, and being able to use university calc. as a point of reference to get through that is helpful.

A lot of exercises are tersely explained in both problem and solution. Further, many solutions are totally left-field (having little to do with material in the book). This isn't necessarily bad, as even taking the wrong path to a solution is very educational. However, at some point the reader has to make a judgment as to how long to commit to a certain problem. Many terse problems & left-field solutions instill the wrong judgment: quitting too early.

Conclusion:

Attention to detail & extra work is necessary to overcome the terseness of this particular beast, but it's worth it. I recommend this book for developers confronted with algorithm optimization problems, as a well as for a different take on parts of discrete math, and definitely for students coming out of a US state school CS program, the last which this book complements very well. Having worked through some of V1 TAOCP, I would also say that the book is effective in expanding upon its math underpinnings (V1 at-least), and incidentally, does give one confidence to tackle Knuth's other works.",21
Joe V.,3.0 out of 5 stars,Amazon Echo: 2017 Edition - User Guide and Manual - Learn It Live It Love It,Basic Info,"Could have been better. Very basic information, at the end it mentions things it can do with Outlook, and other programs, but not how to set that up. Overall a good light read but lacking information for advanced use for the device.",21
Charles,1.0 out of 5 stars,"Data Mining: Practical Machine Learning Tools and Techniques, Third Edition (Morgan Kaufmann Series in Data Management Systems)",Avoid,"Reading some of these reviews I feel like I must have gotten another book. I really didn't think the book was worth the time or money investment.

My main issues were:
1. 50% of the book covers WEKA
- but who is really going to use WEKA over a product like R.
- the WEKA coverage is mind numbingly bad. Lists of algorithm names without explanations of those algorithms and no real practical advice or examples using the program.
2. The 50% of the book that covers general data mining is not really that good at all. It is meant to be an easily accessible overview without technical details but manages to be so breezy an overview as to be totally useless.
3. The ""Data Mining with Rattle and R"" (as a practical introduction) is so much better in almost every area that I can't understand why people are still recommending this book.",21
Eve Freeman,4.0 out of 5 stars,Understanding Machine Learning: From Theory to Algorithms,enjoying the book...,"First, let me just say I regret purchasing the kindle version, as it is difficult to read the math symbols on the kindle, and even somewhat difficult to read them on the kindle for mac app on a big screen. Zoomed in leaves the symbols the same size (it appears as though they're images), with the surrounding text large. Perhaps this is a problem on most math texts, but I was disappointed.

I'm enjoying the book. It reads like a textbook that one might find at a university, and has exercises and notes for the order you'd go through it while teaching a class. I find it well-written and for the most part, easy to digest--a bit heavy on the math for what I was looking for, but you can skim over it for the ideas.",21
Alberto Montebelli,5.0 out of 5 stars,Neural Networks and Learning Machines (3rd Edition),Neural Networks and Learning Machines (3rd Edition),"In general I find the reviews on Amazon.com very useful. Nevertheless, so far this book is collecting a relatively high number of the funniest comments, together with ratings that currently hide a lot of its real value. This third edition has much in common with the classic and more fairly rated ""S. Haykin, Neural Networks: A Comprehensive Foundation (2nd Edition)"", in particular for its highly technical/mathematical approach. Refer to that book and to its pretty exhaustive and often well written reviews.",21
Dr. Lee D. Carlson,4.0 out of 5 stars,"Out of Control: The New Biology of Machines, Social Systems, & the Economic World",Interesting and provocative,"The ideas in this book may be thought by some to be radical or far-fetched, but to those readers familiar with the behavior of complex dynamical systems, they seem quite natural. The book emphasizes the theoretical aspects of complex systems, but some natural examples of them are discussed. The author, in spite of his choice of title for the book, is not threatened by the consequences of artifically creating these systems. After all, we live and have evolved in a universe that is even more complex than the author describes. The fact that we humans can now speed up the process of creation of these systems should be a source of wonder instead of fear.
What makes this book valuable reading is that the author emphasizes the collective behavior of dynamical systems. Too often the reductionist trend in Western science obscures how the system works together, how its many parts collectively induce an emergent behavior not at all apparent in the systems ""equations of motion"".
Since the book is written for a popular audience, the approach is qualitative and allegorical. This purely descriptive approach does however allow a more general overview of complex dynamical systems im many different areas. The author gives a fascinating discussion of swarm systems and their advantages and disadvantages. One of the disadvantages according to the author is that they are ""nonunderstandable""; but here he is mistaken, for complex systems can be understood, although such an understanding takes some effort anc computational horsepower. Also, in his discussion of network behavior the author asserts that it is ""counterintuitive"" and quotes ""Braess's paradox"" as proof of this. Dietrich Braess discovered that adding routes to an already congested network will slow it down. There are examples of this, but it is not a hard-and-fast rule, as network engineers who employ load balancing can attest to. Adding time-dependent paths can work to reduce congestion, this time-dependence not addressed in Braess's formulation of the paradox.
Some more interesting discussions in the book are allegorical, but they serve to encourage ""thinking out of the box"":1. The effects of isolation and boredom on the human mind: the need for the physical body to temper unruly constructions of the mind. 2. The chameleon riddle: what color will a chameleon take on if put in front of a mirror? 3.The Prisoner's dilemna. This has got to be the most widely used tool for encouraging cooperation, in spite of its simplicity and impracticality. Computer simulation of the Prisoner's dilemna with 1000 players has revealed phenomena familiar in evolutionary studies, such as parasitism, spontaneously emerging symbiosis, and long-term stable coexistence between species. 4. Physical systems as computational processes; this is the most radical of the ideas in the book, but the author does not expound upon it in any great detail though. 5. The Biosphere experiment; I only read brief news reports of this while it was going on, so it was interesting to read here a detailed account of it. 6. The need for industry to adopt ""biological"" methodologies: complexity is more efficient, less wasteful, and more robust. 7. Network economics: The ""network company"" of the 21st century will be distributed (no single location), decentralized, collaborative (outsourcing to competitors!), and adaptive. This chapter is the most practical of all those in the book. 8. The role of encryption in a digital economy, particularly ""encryption-metering"" and digital cash. 9. The importance of simulation in defense and industry in the 21st century: simulate before you build, simulate before you buy, and simulate before you fight. 10. The evolution machine and its resultant creation of sex; the consequent discussion of genetic/evolutionary programming. The differences between 'Lamarckian' and 'Darwinian"" evolutionary programs. 11. Postdarwinism: why have no new species been detected naturally or even in computer simulations? The central thesis of Neodarwinism is that only the environment can select mutations, but not induce or direct them.
Since this book was published in 1994, there have been many advances in the areas that the author discusses. Evolutionary programming has taken off, with many applications in finance, biology, network engineering, and large-scale circuit design. Swarm robots are currently under development, with deployment just years away. Computational/intelligent agents are now managing networks, with autonomous agents just around the corner.Encryption and smart-card technologies have mushroomed along with intelligent computer virus detection. Simulation is now thought of as a ""must-do"" in every phase of business and industry, and simulations are now thought of as sophisticated enough to model real-world situations without any experimental ""validation"". Indeed, technological advancement and its application is moving forward at a dizzying rate, and seemingly...out of control?",21
Anna Erishkigal,5.0 out of 5 stars,GIMP for Absolute Beginners,How-to ... from the beginning,"I knew very little about GIMP and it was difficult to teach myself. Surfing YouTube videos while simultaneously manipulating a picture (all on the same screen) got a bit tricky. This book takes you through the most basic steps, from downloading/opening GIMP onto your computer to how to use the toolbars to how to do some of the most common tasks. I'm no digital artist after reading this book, but I was able to upload images, manipulate and layer them, add graphics and special effects, and save it in a variety of formats so am happy with my investment.

UPDATE: 1/4/15 - still happy I bought this book, but it really needs a BETTER INDEX!!! I hunted through it many times to find a tutorial I vaguely remembered seeing and was ready to rip out my hair before I found the 'how to' tutorial I was looking for buried in with a bunch of longer lessons. Have had this happen with other manipulations, so, yes, it needs a better index at the end please on your next edition.",21
R. D Johnson,4.0 out of 5 stars,Real-Time C++: Efficient Object-Oriented and Template Microcontroller Programming,You'll love it and hate it at the same time,"If you're not an embedded programmer, move on; there's little here for you.

If, like me, you've had years of embedded programming experience in both C and C++ you will either love or hate this book. Or, like me, you may experience both emotions at the same time. Why? Because it contains equal parts of 'duh, everyone knows that' and 'wow that is clever' exposition and code. It covers old ground like 'replace multiply with shift and add for efficiency' (which isn't even necessarily true anymore on some modern microprocessors) and totally new ground like using lambda expressions for efficiency inside code loops. Like another reviewer states, it illustrates good coding technique, but does so using C++ features that are barely supported on desktop PCs at the time of this review much less embedded compilers or cross-compilers.

I finally settled on four stars because it excels at one task: shaking the complacency out of embedded C programmers who think state-of-the-art C++ and modern coding styles are not suitable for embedded 8 to 32 bit microprocessors. The author does a great job of showing how modern constructs such as templates, lambda expressions, placement new, atomics and the like make embedded code more maintainable without sacrificing performance. The coding style is modern, using namespaces and prefixes, and <stdint> instead of the home-grown portability defines common in embedded C code. The author covers ground many embedded programmers probably already know such as the purpose of main(), how to extract and read assembly listing, use linker map files, and C++ name de-mangling. However, those new to embedded programming may find such information useful. The real meat of the book, though, is its extensive explanation and use of templates, constexpr, lambdas, and other modern C++ techniques to move a lot of programming work to compile-time. It also does a good job of explaining how to write your own memory manager if necessary to make better use of the STL. The book finishes with some example code, including a fixed-point math class and a FIR filter implemented with the aid of templates.

Finally, I have to say this book is probably a little ahead of its time. The code and techniques in this book illustrate the future of embedded programming on the new ARM and AVR class of embedded processors. However, given the conservative nature of the embedded world--where a wrong instruction can blow up an expensive machine--it will be a while still before the tool chains are up-to-date enough and trusted enough to make use of many of the techniques in this book.",21
David Osborn,1.0 out of 5 stars,Getting Started with TensorFlow,The Writer Needs To Buy A Dictionary,This book is terrible. The editor should be fired. There are a ton of spelling and grammar errors. It was obviously rushed to print to cash in on the popularity of subject.,21
reniam,3.0 out of 5 stars,The LabVIEW Style Book,Good - needs editing,"I get the feeling the other reviews are written by the author and his friends. Some are just a little too glowing.

This book is good, but needs editing because it is very long winded; using twice as many words than necessary to get the point across (the author is always stressing efficiency). Many of the ""rules"" are subjective and should be called suggestions. For example, the author has a rule disabling ""Show dots at wire junctions"". I like the dots. The VI's are not included with the book. Some are available from the author's company site, but only after registration.

I recommend the book but, be prepared to spend the time required for reading.",21
J. Grattan,4.0 out of 5 stars,Red-Eared Sliders: From the Experts at Advanced Vivarium Systems,"Good, basic information","This is a good basic book about red-eared sliders. You will learn details about sex identification and varieties, environmental needs, diseases, feeding, and even breeding. The author does a good job of describing the types and sizes of enclosures needed, water filtration, basking and light needs, and temperature. The need to have an easy system of water cleaning is emphasized. There is some discussion about recognizing symtoms of sickness and how to solve the problem usually either through changes in the environment or diet. Even with a book such as this, caring for turtles would definitely be somewhat of a learn as you go endeavor. This book can get one started but careful observation and fine tuning is required.",21
Dave Mark,5.0 out of 5 stars,AI Game Programming Wisdom 3 (AI Game Programming Wisdom (W/CD)),"A fantastic ""a la carte"" tool kit","Being in the game development business, I am always on the lookout for new and different tricks, techniques and strategies. When most programmers go to the lectures, panels and roundtables at the Game Developers Conference, we are looking to pick up this same sort of material... we share ideas and approaches - but rarely get the chance to get down to the code details to make it easy for us to implement those ideas into our own work. This book makes that possible.
Along the lines of the other ""Gems"" series of books, this collection is filled with ACTUAL techniques and code chunks that are used by some of the top professionals in the industry. Just flipping through the list of the contributors to the book is like going around the room at one of the AI roundtables at the GDC... in fact, Steve Woodcock and Neil Kirby are 2 of the ""3 AI guys"" that RUN those roundtables! (The 3rd being Eric Dybsand who has contributed to the ""Gems"" series but not this title.)
Many books on game development are informative. This one is actually USEFULL. I have personally adopted Steve Rabin's source code from the section ""Implementing a State Machine Language"" into my own game and it has saved me many hours of development and improved the readability and understandability of my code for the rest of the team. Just that section alone has netted at least a 1000:1 return on the cost of this book. Other sections have given me a different approach on how to handle the economic strategy layer that I could have come upon myself... but was able to implement a lot quicker than if I had done it myself. It was definately worth the price.
Are any of these sections worth the purchase price for YOU? I suppose that depends on how much you value you your time. Once you equate the cost of the book to the man hours you save, it's a no brainer!",21
HS,1.0 out of 5 stars,Alan Turing: The Enigma,Low Paper Quality,No doubt this is a masterpiece in terms of contents. But I have to say the quality of the paper and print is really bad. Even hard to read. Bad experience.,21
Cecilia Marcano,5.0 out of 5 stars,"Beginning 3D Game Development with Unity 4: All-in-one, multi-platform game development (Technology in Action)",Great Book for a Great Game Building Tool,"I recommend buying this book for 3 reasons. First because how it is written. Second because the content and scope of the book. Third because of Unity 3D.

1) The book is really well written, it invites you to explore Unity and get familiar with the Interface and concepts, which is the only way you will really learn. The book does not read as programming book, it reads more like a book for learning an application, like reading a content creation software book. As other reviewer said, the author assumes nothing about previous knowledge or experience of the reader, so there is a lot of information and explanations to help you get the tasks done. At times this detail may seem too much for a seasoned developer, but for a beginner its perfect,
2) The book is targeted to beginners audience, and does a great job on that regard. You will learn by creating a Point and Click 3D Adventure, which may be not be your favorite genre, but it does not matter, this will serve very well the purpose of teaching.
3) Unity 3D is simply great, I kind of regret not learning it sooner. I have followed Unity from its creation, but back then I choose to learn XNA and develop for the PC and XBOX 360 Indie Games. But then the iOS games and Facebook games took over the game world. Suddenly it made no sense to learn platform specific languages or technologies. I tried to learn Unreal with the UDK, but found it kind of complex. My advice to anyone learning how to create video games is to learn Unity, because at the present moment the ability to deploy to iOS, Android, Mac OS, Linux, Wii U, and all the Microsoft's OS including Windows Phone; is simply mandatory if you really want any chance of success.",21
Doug Y'barbo,5.0 out of 5 stars,Machine Learning: An Algorithmic Perspective (Chapman & Hall/Crc Machine Learning & Pattern Recognition),Different than other 'textbooks' on ML,"I first saw this book on a colleague's bookshelf; i picked it up and briefly looked through it. The simple diagrams and the relative lack of equations (compared to e.g., Bishop) might suggest to you that it's a 'beginner' text--and by that i mean that the textbook is only an introduction to ML and doesn't teach you enough so that you can begin writing ML code to solve real classification/regression problems. That's what i though at first, and i was wrong. This is an introductory text, but only in the sense that it's accessible to more or less anyone, but this book's explanation/theory and the practical examples (in python) are brilliantly integrated--the explanation (often summarizing two or three pages of terse equations found in other textbooks, in a single paragraph) helped me grok the code, and the code reinforced the theory behind the algorithm.

I don't think there's another ML book like this--it's aimed right at the blind spot framed by applied math reference-type books such as Bishop on one end, and books like 'Programming Collective Intelligence' which are dense with working ML code, but light on theory.

I also like this book because the code is written in NumPy, rather than in the Python standard library code. NumPy is what you would use 'in the real world' to code an ML algorithm, and if you understand the matrix-driven syntax, then the code is far more concise (e.g., no triply nested recursive loops) than the same algorithms coded using just the Python standard library.

In sum, an excellent book.",21
Jeff Becker,3.0 out of 5 stars,What Is Thought? (MIT Press),What Is What Is Thought?,"Those who are not yet convinced that the brain is a computing mechanism, or who believe that mysticism is required to explain thought, will find quite a bit of value in this book. The book surveys numerous areas of Computer Science, AI, and even a bit of biology, in an attempt to build a case for the brain as a computing mechanism. The book also wades into evolution to try to explain how it came to be so. The scope of the book is ambitious.
Anyone with a background in AI or Cognitive Science will likely find ""What is Thought"" disappointing as it has little new to say. I fall into this category, and I find a number of aspects of this book unsatisfying.
This is a long book in which there is a short book struggling to get out. The author's main thesis, that the brain is a modular computing mechanism that is the result of evolution, is repeated numerous times at considerable length to the point of tedium. While the author shows his thesis to be consistent with numerous observations, it is never developed to any greater depth. In fact, one of the author's conclusions is that we may never understand the inner workings of the brains ""subroutines"" because, as a result of evolution, they are now so ""compressed"".
The author rarely defines his terms. Merely replacing the words ""compressed"" and ""compact"" by the word ""concise"" would enhance the clarity of this book considerably. The author also seems to be of the opinion that generalization, which is the result of ""compressed"" representations, is the essence of understanding. This view is inadequate for explaining our abilities to plan our own actions and predict the actions of other agents, for example.
Because of the informal, breezy style, the book comes across as an introduction for novices or a position paper rather than a scholarly work. While some may enjoy this style, I find it lacks a certain satisfying clarity and crispness needed for a convincing presentation of such an abstract topic.",21
Jeffrey Heaton,5.0 out of 5 stars,Deep Learning (Adaptive Computation and Machine Learning series),"Very good book, likely to be heavily cited in future ...","This will very likely become ""the textbook"" of choice for graduate level neural network classes looking for a broad mathematical foundation for deep learning. This is very important, as there have been a number of important technologies introduced that make classical neural networks into what we think of today as ""deep learning"". The book is divided into 3 highly effective thirds. The first third provides a mathematical background and can be skipped by those who already understand linear algebra, probability and calculus at a high enough level for the book. The 2nd third introduces what we think of in 2016 (and beyond) as deep learning. The final third introduces the most current research that might likely become part of the mainstream of deep learning. Those looking to implement current deep learning (and not research) can safely skip the last third. Skipping the middle would not make sense. Very good book, likely to be heavily cited in future academic work.",20
LH,1.0 out of 5 stars,Pattern Recognition and Machine Learning (Information Science and Statistics),Obfuscates things rather than explaining them,"As a professor who have taught machine learning at the graduate level, I found this book one of the worst ever written for machine learning.

Put simply, it obfuscates things rather than explaining them. It made machine learning look unnecessarily complicated, and yet ugly.

Extremely wordy, and lacks organization.

There is too much ""boring"" equations and not enough ""cool math"" (geometric intuitions). And while most people found it too ""theoretical"", I found it not solid in theory at all. Some important theoretical topics are left out, such as perceptron convergence proof (which can be explained very easily using geometric terms) and theory behind KKT conditions (which also can be explained geometrically).

Also there is an almost ""religious"" tendency towards Bayesian, and almost every chapter ends with Bayesian. While bayesian is very useful in some subfields of machine learning, it is not a universal magic across all machine learning.

Definitely not a textbook for beginners or a university-level class.",20
LanternRouge,5.0 out of 5 stars,"Fundamentals of Machine Learning for Predictive Data Analytics: Algorithms, Worked Examples, and Case Studies (MIT Press)",Much needed book for practioners,This book will teach you CRISP-DM workflow and how to think about analytics in a professional manner in addition to the core ML algorithms. The authors cover crucial practical information and work habits every data scientist should know. I do not know of any way to get this information other than making a lot of mistakes in the field. Well done! I encourage all my students to pick up a copy.,20
Ron & Joanne Lauer,5.0 out of 5 stars,Amazon Echo: Master Your Amazon Echo; User Guide and Manual,Excellent book,Excellent job describing echo's use and giving plenty of tips on how to get more out of it. Echo is a great priduct and with the IFTTT capability has endless uses,20
EJS,2.0 out of 5 stars,Introduction to the Theory of Computation,Not detailed enough,"Given the fact that this is considered one of the ""standard"" reference books, I was surprisingly unimpressed with this book.

There are a number of complaints I have about this book:
1. Its price is just obscene - the fact that they would charge that much for a book that a lot of people are forced to purchase is just wrong on the face of it.
2. The lousy price is especially irritating given what you get for it. Fact is, even at a much lower price this textbook would be a bad value. At a mere 480 pages, this is not an especially long textbook; not sure how the publisher can possibly justify charging an above-average price for a shorter-than-average textbook. There's really nothing I can think of that would justify this book's price tag; it's not like they add some fabulous feature (software package, etc.) that makes this book worth the extra money. I suppose it's more of a ""they charge it because they can"" type scenario.
3. Not only is it overpriced, it's not even particularly well written. Quite bluntly, the book's relatively short because it doesn't explain anything.

With regards to the third point, I completely agree with the other reviewer who commented that this book is written as if you already understood the material; this is exactly what he does. I had to consult other textbooks all the time in order to be able to solve the book's problems because I found the author's explanations inadequate. It's almost like the author had a minimum word count and he was struggling to meet it (""OK, just 10 more pages to go before I can release it"").

On the plus side, the problem sets are, for the most part, decently selected if you have decent reference material to help you with them (e.g. a different textbook, a good professor); if your professor's not that great and all you have is this book I pity you, the book is of some limited help in solving the problems I guess but you'll need a LOT more, especially if you're not already really familiar with this material.

I guess this book could be pretty helpful for review or reference if you already know the material, but overall it's not so great for learning the subject for the first time, especially if you're stuck using it as your primary learning source.",20
Amazon Customer,1.0 out of 5 stars,Make Your Own Neural Network,"Why do you advertise it under ""Kindle Edition"" when after ...","Why do you advertise it under ""Kindle Edition"" when after buying one has to find out that it is incompatible with Kindle? Can't even upload it to Kindle.",20
Matt Ginsberg,2.0 out of 5 stars,Natural Language Processing with Python: Analyzing Text with the Natural Language Toolkit,too scattershot to be really useful,"If you already know what's in this book, it's probably a great book. But if you don't, it's not.

I've been programming in C and C++ for around 15 years. I taught computer science at Stanford. I write crosswords for the New York Times. Neither programming nor language is new to me. But I found it very difficult (nigh on impossible) to learn anything from this book. I couldn't learn about NLTK effectively, and I couldn't learn about Python, either. I bought the book to learn both; imagine my disappointment!

In both cases, the reason is that the book is organized from a ""let's do this, let's do that"" perspective. If you want to do exactly what the authors did, that's great. But if you want to do something different, it's terrible. As a representative example, exercise 2.8.13 mentions, ""You can get all noun synsets using wn.all_synsets('n').""

That's great to know. But why is the only indication of a piece of useful functionality sitting inside an exercise? There needs to be a well thought-out layout: ""Here are all the pieces of NLTK. Here is what each piece does. Here is what the submethods are and how they work."" As it stands, if I want to do something new, I have to either write it myself or just guess as to whether it's functionality that NLTK provides.

The treatment of python is sadly similar. Python depends heavily on something called a ""list comprehension"". List comprehensions are used throughout the book. But their syntax, from a programming perspective, is never defined. Having read (and reread) much of this book, I can say with confidence that I still don't understand how they work. Given my programming background, I would think I would have a much better understanding having spent so much time trying to figure it out.

Again, there needs to be structure. ""This is what's in Python. This is what it all means, one piece at a time.""

You can find this book online for free; I read it that way the first time, got confused, and figured buying a paper copy would help. Sadly, it didn't.",20
Amazon Customer,1.0 out of 5 stars,On Intelligence,Naive and speculative,"Naive and speculative. The author is right criticizing neuroscience and AI, but the rest of the book is pure fiction without any arguments supporting it",20
TFK,2.0 out of 5 stars,The Most Human Human: What Artificial Intelligence Teaches Us About Being Alive,Starts Off Great. Lets You Down Hard.,"Not a fan of critiquing. I just like to share my experiences.

I can describe this book in two ways; one of them is the title of my review, the other is the title of another 2/5 review here on Amazon: ""Maddeningly Unfocused"".

The book starts off great, very appeasing to a geek like myself who's into some light reading. The book takes a nosedive once it gets heavy on pretentious philosophy, random (and frequent) musings, and page after page of content that makes you go ""wait, what does this have to do with anything?!""

Had the book continued the way it started, I would be its biggest fan. Unfortunately, that is not the case.

Still, some pages worth reading. 2/5",20
Aditya,3.0 out of 5 stars,Paradigms of Artificial Intelligence Programming: Case Studies in Common Lisp,A mediocre AI / LISP book with very well-written examples,"First, the good:

This book is a great read, both the code and non-code sections. Peter Norvig is clearly passionate about AI, and it comes through in his examples. His writing is clear and fun to read. His code examples are fantastic. When he begins a chapter by describing a problem, you think ""wow, that's going to take ages to get through."" Then you flip the page, and he's got all the code down on the next page. It's a real joy to see clear, concise, well-written code like this. This is probably what musicians feel when they listen to a Beethoven sonata.

The bad: the examples are historical (read: dated), and they don't teach you a whole lot about either AI or Lisp. If you know depth first search and regular expressions, you can breeze through the first 250 pages of this book: it won't show you anything besides some very well-written code (which, let me emphasize again, is really great to read). Unless you are using Lisp as your programming language (I'm using Haskell), section 3 (optimizing your Lisp code + Logic programming) will be hit and miss too.

So, to sum up:

If you want to learn Lisp, Norvig recommends Paul Graham's book.
If you want to learn AI, Norvig has written AI: A Modern Approach.

I spent five bucks on a used copy of this book, and felt like I got my money's worth. I would definitely not spend $80+ on it.",20
Amazon Customer,5.0 out of 5 stars,Neural Networks for Pattern Recognition (Advanced Texts in Econometrics),An excellent introduction to pattern recognition,"Do not be put off by the title: this book is more about pattern recognition than neural networks. Of course it covers neural networks, but the central aim of the book is to investigate statistical approaches to the problem of pattern recognition.
An excellent companion to ""Duda & Hart"".
As other reviewers have said: you will need a reasonable maths or stats background to get the most out of this book.",20
Richard Deveno,4.0 out of 5 stars,All of Nonparametric Statistics (Springer Texts in Statistics),10-to-1 Equation to Text Ratio,"My first thought upon receiving this slim volume went something along the lines of ""Oh my, all of non-parametric statistics is much, much smaller than I expected"". My other impressions are somewhat vague since (as the title of this review implies), this is not exactly a flip-through book for light reading. The content is dense ... like 100-year old ebony wood.

And after carefully examining the table of contents, I also noticed that the text has precious little to say about methods based on rank. So this is more or less a book on ""modern methods"". It's a very interesting selection of material - although I will probably never be able to read it.",20
Kang,1.0 out of 5 stars,All of Nonparametric Statistics (Springer Texts in Statistics),The Kindle edition is unreadable,"This is a great book and I was delighted to see a Kindle edition of it. However I found the Kindle edition defective shortly after purchasing it. There are serious typographical errors in the equations throughout the book, making it unreadable. The errors are not just minor formatting issues but severe ones such as mistyped letters, missing symbols and signs, which completely altered the meanings of the equations, making them incomprehensible. It is like the whole book was converted from the print edition using OCR without error checking. I was suprised the Kindle edition was put on market with such poor quality. I have returned the book for refund.",20
EJS,2.0 out of 5 stars,Introduction to the Theory of Computation,Not detailed enough,"Given the fact that this is considered one of the ""standard"" reference books, I was surprisingly unimpressed with this book.

There are a number of complaints I have about this book:
1. Its price is just obscene - the fact that they would charge that much for a book that a lot of people are forced to purchase is just wrong on the face of it.
2. The lousy price is especially irritating given what you get for it. Fact is, even at a much lower price this textbook would be a bad value. At a mere 480 pages, this is not an especially long textbook; not sure how the publisher can possibly justify charging an above-average price for a shorter-than-average textbook. There's really nothing I can think of that would justify this book's price tag; it's not like they add some fabulous feature (software package, etc.) that makes this book worth the extra money. I suppose it's more of a ""they charge it because they can"" type scenario.
3. Not only is it overpriced, it's not even particularly well written. Quite bluntly, the book's relatively short because it doesn't explain anything.

With regards to the third point, I completely agree with the other reviewer who commented that this book is written as if you already understood the material; this is exactly what he does. I had to consult other textbooks all the time in order to be able to solve the book's problems because I found the author's explanations inadequate. It's almost like the author had a minimum word count and he was struggling to meet it (""OK, just 10 more pages to go before I can release it"").

On the plus side, the problem sets are, for the most part, decently selected if you have decent reference material to help you with them (e.g. a different textbook, a good professor); if your professor's not that great and all you have is this book I pity you, the book is of some limited help in solving the problems I guess but you'll need a LOT more, especially if you're not already really familiar with this material.

I guess this book could be pretty helpful for review or reference if you already know the material, but overall it's not so great for learning the subject for the first time, especially if you're stuck using it as your primary learning source.",20
Coder,4.0 out of 5 stars,Linux+ Guide to Linux Certification (Test Preparation),"Very good overall, NO coverage of X configuration?","First, I have to say that I am not usually fond of computer books in the Thompson Course Technology series -- too many of them are NOT really written by knowledgeable people, and it shows in the errors and misguided opinions passed on to students and professors charged using these books.

So, I was pleasantly surprised at the content (of a Linux book in particular) by Thompson. Most of the information is relevant, useful, and introduces students to important skills and management practices when using Linux in a business environment.

I do have some issues with the orders of the chapters -- for example, file and folder permissions vs. users and groups chapters should be back-to-back, and there are a couple errors in laboratory exercises. For example, a couple of the exercises, done in order, are intended to demonstrate the effect of one user assuming another's UID. But the point to be demonstrated doesn't actually happen. New Linux users won't realize there was an error in the thought process of the text, and will think they ""just missed the point"" due to their own imagined ineptness. There are a few typos but they are minor -- if teachers (and even casual users Linux users) don't catch them outright, shame on them, they are so simple.

I actually have a *couple* of not-so-minor gripes, and struggled with whether to give the book 3 or 4 stars, but then it is so much better than other Linux books in some areas that I couldn't give it a 3.

My first big gripe is that the chapter on so-called ""X Configuration"" is *NOT* about *configuring* *X*! It is actually about *customizing* the *desktop*, using the desktop utilities, for personal use/preferences (the way you change your desktop properties in Windows). The topic of *X CONFIGURATION* -- one of the first tasks most new Linux users must learn, usually necessary since Linux is not OEM (preinstalled) on most computers -- is actually NOT COVERED AT ALL!

Along the same lines, the *obvious* flow of post-install activities in the book should include taking a Linux distro that boots non-GUI by default, an introduction to the format of an X configuration file, how to research your computer hardware, and how to edit the default X configuration file for all users per hardware requirements and to start the login manager and desktop of choice.

Even in network environments, this is a common task because X can be run as a network application, or for other reasons. Unlike Windows, the OS is more modular; the underlying kernel, the ""window server"" (X) and the ""desktop"" (GUI look-and-feel and utilities) are 3 very seperate things and allow freedom of choice.

My second gripe is there is no coverage of package installation! Very, very bad! How can you be certified in Linux without learning to install software on it? One or two chapters need to be added here, covering RPM and TGZ installs at a minimum. Users need background on what is done when software is installed on Linux, the most common ways in which software install locations and config tend to differ among distros, and the most popular package managers out there (brief contrast of strengths and weaknesses).

Ideally, students would actually perform both RPM and TGZ installs, would uninstall them afterwards, would use one or more command-line tools to update a package or two, would use a popular package manager to install a new package and look for updates, and would download source code manually and compile at least one package from scratch, just to get a feel for it. An example is OpenOffice.org, because it is easy to install (few steps needed), and new OO versions tend to change folder names and locataions, (students must deal with this and uninstall the old version and delete remnant folders to avoid confusion before installing the new, then edit desktop shortcuts to point to new executable in new location).

My third gripe is the use of an outdated OS, and one with such a poor installer. I think the author was thinking that Red Hat is popular with commercial enterprises (certainly) and so it would be a good choice. But Fedora Core 3??? C'mon, that's the stone age (at least in PC years)! Plus, this OS boots to a GUI (not a good for newbies to Linux sysadmin who need to learn to manually configure X). Most books will make a better choice of distro or at least customize their own ""release"" of the distro to match the purpose of the book.

Also, the menu-based installer on Fedora Core 3 is really crap. Though I am a seasoned Linux user who habitually changes partition schemes and multi-boot environments, the menu logic and layout/alignment of selections was so poor that I became confused and had to backtrack/start over several times during my install.

However, complaints aside, this is generally an excellent book. It gives some excellent lessons and examples on using the ""vi"" editor and using various text-manipulation, file-manipulation, and search tools. The vast majority of non-newbies in this book's audience will learn new tricks for example, grep, dmesg, cat, top. The chapter on boot loaders is excellent, contrasting the functionality of LILO and GRUB, and the optional parameters which can be used in their config files. While this book assumes no Linux knowledge at all on the part of the user, it is in some ways almost a ""power users"" cookbook. I learned much from this book and use it as a reference.

Some of this book's major strengths are the clarity of the writing, the usefulness of the lessons, and the extensive number of exercises which can be used both in a college course and on your own.

I strongly feel this text is overdue for a revision -- below are some recommendations summing the above points and adding some things that need less explanation:

1) X CONFIGURATION NEEDS A CHAPTER, and soon after install and intro to the file system. (Desktop customization should just be deleted because it's not an administration topic and anyone who's used any OS before can figure it out all by themselves.)

2)PACKAGE INSTALLATION, COMPILATION, AND UPDATING NEEDS A CHAPTER OR TWO.

3) CHAPTERS ON USERS/GROUPS AND FILE/FOLDER PERMISSIONS NEED TO BE CONSECUTIVE. (Chapter 11 is too late to be giving this info.)

4) THE BOOK NEEDS TO USE AN RPM/TGZ-COMPATIBLE DISTRO WITH A DECENT INSTALLER AND MORE APPROPRIATE CONFIG -- either switch distros or customize it for the book, and definitely use something newer. (Why not switch to kernel 2.6 while they're at it?)

5) IDEALLY, THE BOOK AND THE DISTRO WOULD INCLUDE TWO DESKTOPS. At least introduce students to two, even if the majority of the book will use one in particular. I don't even necessarily mean KDE vs. GNOME, could be one of those vs. a much more stripped-down desktop to really contrast. Assuming the text already taught basic X config, including login manager and desktop loading, now teach them the main benefit -- users can tweak their own config, and the first way to do so is choose a desktop other than the default for all users. Which brings us to #6...

6) GIVE A USEFUL EXAMPLE OF WHAT THE ""SKELETON DIRECTORY"" IS USED FOR, NOT JUST A VAGUE EXPLANATION. Have an exercise where users place a couple default folders and organizational document in here and a copy of the X config, create a new user, log in as that user and view the doc, customize X to start a different desktop, copy the edited config to the correct location, reboot, log in as that new user again -- tada! Skeleton directories are even useful on a home system, but they are mostly used in organizations with many users.",20
carol koss,5.0 out of 5 stars,Robotic Explorations: A Hands-On Introduction to Engineering,MIT 6.270 in book form,"I just finished participating in the MIT 6.270 Autonomous Robot Competition. This book really pulls together everything you need to understand how to build a robot from Lego parts, and interface it to the real world using a variety of sensors and actuators (aka motors). There is so much to be learned by actually BUILDING a robot - this is a great book to help you dig into your own project. You can order the same hardware and software used in the MIT class off the internet as well.",20
N/A,5.0 out of 5 stars,Blondie24: Playing at the Edge of AI (The Morgan Kaufmann Series in Artificial Intelligence),Very Worthwhile Book,"I'm about 3/4 of the way through this book and I am enjoying it immensely; so much so I wish I had saved it for vacation! I work in the field of A.I. so this book is of special interest to me, but I think it's one of this year's ""must-read"" popular science books. The book is written in a colloquial style, but manages to give both a good introduction to evolutionary artificial intelligence and computer game design -- science entertainment without the fluff! The first-hand view of the tension between scientific rigor and engineering excitement will be especially interesting to prospective young scientists (hint: rigor wins). I hope the publisher has an active campaign to market this book as a educational tool.
I met Larry Fogel in a business situation a number of years ago, and one of the things I remember most was his contagious enthusiasm for his work and research. David Fogel communicates the same enthusiasm in this book. Don't pass it by.",20
Epimachus,1.0 out of 5 stars,"G??del, Escher, Bach: An Eternal Golden Braid",Complete waste of time,"There's some bizarre cult following to this book I will never understand.

Although it does a nice job stroking both your and the authors' ego, this book is a waste of time for anyone even marginally mathematically inclined. Some 80% of the book is full of tired arguments whose conclusion you've probably already considered if you've graduated middle school. Another 5% is passable as a Playskool(TM) My First Logic Book. The remaining 15% is full of Hofstadter's pseudoscientific quackery.

If you want to actually learn something, just read a decent 160-page book on Godel's work (example: G??del's Proof) and never worry about pseudo-philosophical smart-Alec turtles again.",19
Oakpines,2.0 out of 5 stars,Amazon Echo: Master Your Amazon Echo; User Guide and Manual,"Old Information, not 2016","Much of the information has been obtained from the initial release of the Echo and is flat out wrong. The book states that there is a remote control included which is not true. In Chapter 3 the author states ""the Echo is sold on an invite only basis so you will have to request an invite at the site in order to purchase."" That was only when the Echo was first released, and has long been changed. This shows the author has not reviewed and updated information to that of 2016. To make the book appear longer than the competition, there is much repetition, plus pages of suggested questions to ask Alexa. Also numerous typing errors.",19
Donalbane,1.0 out of 5 stars,The Singularity Is Near: When Humans Transcend Biology,Refers to Kindle edition only,"I think this is a well-done and important book, but DON'T BUY IT IN KINDLE FORM. Kurzweil supports his observations with useful charts that, unfortunately, cannot be read on a (6"") Kindle. Furthermore, he has footnotes throughout, but the Kindle edition doesn't allow you to jump to the reference and return (as other Kindle books do). So the footnotes are practically useless on the Kindle.
But do buy the book in hardcopy and read it.",19
Luke A. Muehlhauser,5.0 out of 5 stars,Our Final Invention: Artificial Intelligence and the End of the Human Era,Engagingly written book about the most important issue of the 21st century,"Although ""Our Final Invention"" summarizes the last 15 years of academic research on risks from advanced AI, it reads more like a thrilling detective story.

I generally open new books and articles about AI risk with some trepidation. Usually, people who write about these issues for a popular audience show little familiarity with the scholarly literature on the subject. Instead, they cycle through a tired list of tropes from science fiction; for example, that robots will angrily rebel against their human masters. That idea makes for some exciting movies, but it's poor technological forecasting.

I was relieved, then, to see that Barrat has read the literature and interviewed the relevant experts.

My biggest complaint about ""Our Final Invention"" is that it may leave readers with a sense of hopelessness. After all, it looks like superintelligent machines will by default use all our resources to accomplish their goals, and we don't know how to give AIs the exact same goals we have, and we don't know how to make sure the AIs keep our goals as they modify their core algorithms to become smarter and smarter.

Staring into a future ruled by superintelligent machines, things look pretty bad for us humans, and I wish Barrat had spent more time explaining what we can do about it. The short answer, I think, is ""Figure out how to make sure the first self-improving intelligent machines will be human-friendly and will stay that way."" (This is called ""Friendly AI research."")

Of course, we can never be 100% certain that a machine we've carefully designed will be (and stay) ""friendly."" But we can improve our chances.

For actionable details, see my full review here: http://is.gd/dOwDID",19
Dr. Lee D. Carlson,2.0 out of 5 stars,Dark Pools: The Rise of the Machine Traders and the Rigging of the U.S. Stock Market,Too much hype; very little substance.,"This book, although entertaining and a ""page turner"" to a certain degree, does not give the reader any kind of insight into the technical or mathematical tools that were used to implement automated trading. It is one thing to interview the ""key players"" behind this automation and write interesting stories about them, but quite another to describe the trading strategies, algorithms, and artificial intelligence used in it. Putting together a book on the latter will require a high amount of preparation from the author, and the reader will have to have the same degree of such in order to appreciate it.

It is no doubt for proprietary reasons that these strategies are not revealed in the book, but one can still insist on some measure of discussion of them while still staying within legal constraints. Instead, most of the emphasis of the book is on personalities behind the drive toward automation, and readers will probably be hearing their names for the first time. The author makes every effort to dramatize their contributions, and in some cases build some kind of sinister context in which they worked. Anyone who has worked in the financial industry has been familiar with scandals and has had to make contact with individuals that are to a large degree highly eccentric and difficult to communicate with. But on the average things are fairly mundane in the everyday practice of finance, both in trading circles and in areas that emphasis financial analysis and modeling. To make this book interesting though the author feels the need to accent the eccentricities of what he thinks are the key players behind automated trading. Whether they really are or were is still very much an open question after finishing the book.

The use of artificial intelligence in finance is well known to those who follow the industry, but what is still really unknown is to what degree these techniques are responsible for the ""flash crash"" of 2010 and the ""financial crisis"" of 2008. The author presents no quantitative evidence for his assertions that they were, but instead is content with telling anecdotal stories and reporting snippets from headlines and politician's mouths in order to make his case. Readers will have to seek other books, research papers, and financial reports to gain a more realistic understanding of the effects of machine intelligence in financial trading. They will find out that trying to correlate events with innovations in technology is a highly nontrivial one, requiring huge amounts of time and data, and therefore not in the scope of the typical reader.",19
Matt Ginsberg,2.0 out of 5 stars,TensorFlow for Machine Intelligence: A Hands-On Introduction to Learning Algorithms,"Not yet ready, and not that close","I originally thought this was a good book. I no longer think that.

It's not a book yet. It will probably be a good book at some point, but that point is not now.

The first few chapters ""work"". I was able to work through them and everything came out just like it should have. With chapter 5, that completely stopped.

At a high level, what's going on for me is that the examples stopped being self-contained. They don't really tell you where to initialize tf sessions, where to initialize the variables, etc. They just give you code that is supposed to somehow work (but doesn't).

I've spent many hours trying to figure this out. From the point labeled ""convert images to TFRecords"" and forward, I just can't get anything to happen. I've tried typing everything into python and running it, both with a tensorflow session and without. I've tried running code I downloaded with jupyter and ipython. I just get a bunch of complaints about widgets being unavailable, kernels not existing, and notebooks not being trusted. I've installed a ton of stuff (ipython, jupyter, widgetsnbextension and ipywidgets, for starters) and nothing helps. I've looked at the various manual pages for tensorflow, and that doesn't help, either.

I suspect that if I already knew tensorflow, I would be able to stagger through this. But I don't (that's why I bought the book!), and this book truly isn't helping.",19
Tyler Hill,1.0 out of 5 stars,Foundations of Machine Learning (Adaptive Computation and Machine Learning series),Do not buy the Kindle Version... its unreadable,"I wish I could give 0 stars. This ""kindle book"" is completely unreadable. Sadly, the authors decided they could make a PDF version of the book, charge $40 and still call it a Kindle Book. Kindle books are legible on the mobile kindle apps. This book is not. Amazon shouldn't let them sell it as I just wasted $40 on something I can't even use. Now I must buy the paper version...",19
Emre Sevinc,5.0 out of 5 stars,"Semantic Web for the Working Ontologist, Second Edition: Effective Modeling in RDFS and OWL",Alternative title: The Most Gentle Introduction to the Semantic Web,"This is one of the best books I read on Semantic Web and its alternative title should be ""The Most Gentle Introduction to the Semantic Web"". Gentle indeed, but not in the sense of ""semantic web for dummies"".

One of the authors, Prof. James Hendler, is the co-author of *THE* article that introduced the concept of Semantic Web to the world (Scientific American Magazine, May 2001). Being an expert in a field and writing a top notch technical introduction that strikes a very good balance between utility and clarity do not necessarily go hand in hand, but in this particular case readers like me should consider themselves very lucky because this book is the perfect blend. Not only does it introduce and explain almost all of the concepts in a very clear and lively manner, but it is full of real-world examples. Being far from a dry technical introduction, the book shows ""why""s of Semantic Web with ""how""s of it.

At its current page count, it is only expected that the book avoids some implementation- and programming-related topics, but books such as A Developer's Guide to the Semantic Web can easily fill this gap. On the other hand, despite the abundance of books that jump into nitty gritty details of semantic web programming, the books that describe semantic modeling practices and kindly show the pitfalls of ontology design belong to a very rare species, and this fact alone is one of the reasons why I give five stars in this review.

One of the most original parts of the book is at the end: In a brief appendix, the authors give a list of the most frequently asked questions related to semantic web, modeling, ontology design, together with short answers and page number references for further explanations.

Creating a useful ontology for a real-world domain which can carry its weight and prove its utility in many different software applications is not something that can simply be mastered by reading this book, it takes lots of effort, trial and error. Nevertheless this book, in its updated second edition, is a very useful, thoughtful and elegant contribution to the growing literature of practical semantic web.",19
Dj??ni,5.0 out of 5 stars,Artificial Intelligence: The Basics,A great overview,"A great introduction to AI concepts, very easy to read.
After reading this book I bought several other more detailed books on AI.
I definitely recommend this book for anyone who wants an easy entry point into the world of AI.",19
Concerned small-D democrat,5.0 out of 5 stars,The End of Error: Unum Computing (Chapman & Hall/CRC Computational Science),This book is revolutionary,"This book is revolutionary. That is the only way to describe it. I have been a professional computer science researcher for almost 40 years, and only once or twice before have I seen a book that is destined to make such a profound change in the way we think about computation. It is hard to imagine that after 70 years or so of computer arithmetic that there is anything new to say about it, but this book reinvents the subject from the ground up, from the very notion of finite precision numbers to their bit-level representation, through the basic arithmetic operations, the calculation of elementary functions, all the way to the fundamental methods of numerical analysis, including completely new approaches to expression calculation, root finding, and the solution of differential equations. On every page from the beginning to the end of the book there are surprises that just astonished me, making me re-think material that I thought had been settled for decades.

The methods described in this book are profoundly different from all previous treatments of numerical methods. Unum arithmetic is an extension of floating point arithmetic, but mathematically much cleaner. It never does rounding, so there is no rounding error. It handles what in floating point arithmetic is called ""overflow"" and ""underflow"" in a far more natural and correct way that makes them normal rather than exceptional. It also handles exceptional values (NaN, +infinity, -infinity) cleanly and consistently. Those contributions alone would have been a profound contribution. But the book does much more.

One of the reasons I think the book is revolutionary is that unum-based numerical methods can effortlessly provide provable bounds on the error in numerical computation, something that is very rare for methods based on floating point calculations. And the bounds are generally as tight as possible (or as tight as you want them), rather than the useless or trivial bounds as often happens with floating point methods or even interval arithmetic methods.

Another reason I consider the book revolutionary is that many of the unum-based methods are cleanly parallelizable, even for problems that are normally considered to be unavoidably sequential. This was completely unexpected.

A third reason is that in most cases unum arithmetic uses fewer bits, and thus less power, storage, and bandwidth (the most precious resources in today??s computers) than the comparable floating point calculation. It hard to believe that we get this advantage in addition to all of the others, but it is amply demonstrated in the book. Doing efficient unum arithmetic takes more logic (e.g. transistors) than comparable floating point arithmetic does, but as the author points out, transistors are so cheap today that that hardly matters, especially when compared to the other benefits.

Some of the broader themes of the book are counterintuitive to people like me advanced conventional training, so that I have to re-think everything I ??knew? before. For example, the discussion of just what it means to ??solve? an equation numerically is extraordinarily thought provoking. Another example is the author??s extended discussion of how calculus is not the best inspiration for computational numerical methods, even for problems that would seem to absolutely require calculus-based thinking, such as the solution of ordinary differential equations.

Not only is the content of the book brilliant, but so is the presentation. The text is so well written, a mix of clarity, precision, and reader friendliness that it is a pure pleasure to read, rather then the dense struggle that mathematical textbooks usually require of the reader. But in addition, almost every page has full color graphics and diagrams that are completely compelling in their ability to clearly communicate the ideas. I cannot think of any technical book I have ever seen that is so beautifully illustrated all the way through.

I should add that I read the Kindle edition on an iPad, and for once Amazon did not screw up the presentation of a technical book, at least for this platform. It is beautifully produced, in full color and detail, and with all of the fonts and graphics reproduced perfectly.

Dr. Gustafson has also provided a Mathematica implementation of unums and of the many numerical methods discussed in the book. Let us hope that in the next few years there will be implementations in other languages, followed by hardware implementations. Over time there should be unum arithmetic units alongside of floating point arithmetic units on every CPU and GPU chip, and in the long run unums should replace floating point entirely. The case the author makes for this is overwhelming.

If you are at all interested in computer arithmetic or numerical methods, read this book. It is destined to be a classic.",19
John A. Bailo,1.0 out of 5 stars,"Making Things See: 3D vision with Kinect, Processing, Arduino, and MakerBot (Make: Books)",Not For Me,"I chose this book because I thought it would be a good mix of the abstract engineering aspects of 3-D visual processing and some hands on programming. Well, while it did give some basic overall knowledge about the innards of Kinect, it wasn't much more than I'd expect from a web page article at About.com. Then when it finally began the programming aspect, I got worried because it kept talking about ""hacking the Kinect"". Why would I want to hack something that has a full featured SDK and programming templates from Microsoft? The final kicker was that not only did it not intend to use the .net libraries and hence the c# skills that I wanted to apply to Kinect development, but the installation of the open source libraries required me to uninstall the official SDK! Boing! I send this book back for a refund and in the future will stick to boring old programming guides that utilize the guidelined API.",19
Smiley2,2.0 out of 5 stars,Alan Turing: The Enigma,Poor digital copy,"The digital version of this book is very poor. It is missing letters, has repeated paragraphs, etc, makes for more difficult reading. More quality control is needed!",19
Jose,5.0 out of 5 stars,"Beginning 3D Game Development with Unity 4: All-in-one, multi-platform game development (Technology in Action)",Excelent for getting started,"I have a background in programming, but never into game development, and even though this title is focused on people with no scripting knowledge, it was extremely useful to me.
It may be counter intuitive, but if you already have the programming background and no game development knowledge (or 3d graphics), then 99% of the book will be new stuff for you as the author will not to go too deep with scripting.

Besides the usage of the software, you get to learn a lot about 3d graphics and game design. Depending on who you are you may already know these things, but for those of you with no previous game development knowledge, its great for getting started. The title of the book after all is ""Beginning ..."" so dont expect complex things.

Feedback for your efforts is fast, and thats good.

I think this is a must have for getting started.",19
Dr. Lee D. Carlson,4.0 out of 5 stars,Blondie24: Playing at the Edge of AI (The Morgan Kaufmann Series in Artificial Intelligence),A very interesting and engaging story,"In this book the author gives a detailed story of his involvement in the development of the ""Blondie24"" checkers program, and the story is a very interesting one. The reader not familiar with certain research topics in artificial intelligence such as neural networks and evolutionary programming, will still be able to read the book since the author gives a good intuitive discussion of these topics. If the book inspires a young person to enter the field of artificial intelligence, it has served a noble purpose, even if the author did not intend this as the primary purpose of the book.
The author's main thesis is the value of using concepts of evolutionary programming to bring about the rise of intelligent machines. The author clearly believes that before ""HAL-like"" machines can be built, researchers must construct computer programs that can teach themselves how to solve problems without any help. Intelligent machines must be creative, and learn and adapt to new circumstances. Traditional research in artificial intelligence has been geared towards building machines that emulate human intelligence, and this will not do in the author's view. The research did not address the true definition and meaning of intelligence, but instead made the goal of creating machines that think and act like humans, whence the famous ""Turing test"" for machine intelligence. The author completely rejects this test and holds it responsible for bringing about the ""AI winter"" where no substantive progress was made. ""The key to creating truly creative computers"", he says, ""lies in mimicking nature's process of evolution.""
The author though was not comfortable with merely refuting arguments about the Turing test or other strategies for designing intelligent machines. He knows that such argument-counterargument activity will not result in sound approaches to artificial intelligence. Therefore, he sought to construct a working, viable alternative, which produces results that can be checked. Intelligence for the author is based on decision making, such as how to obtain resources, and how to respond to environmental changes by prioritizing goals. ""Intelligence is the property that allows living organisms to sense, react to, and learn from their environment in order to adapt their behavior to better promote their survival"", he says.
Hence, the author brings in the evolutionary paradigm to artificial intelligence, and to give credence to his view, he attempts to create a program that will learn the game of checkers and then play it well, at least from the standpoint of the checkers game rating system. The book is a very detailed overview of how he and his collaborators went about doing this, the most interesting strategy being the use of neural networks, the topology of which is not set beforehand, but is evolved according to a ""survival of the fittest"" process. The author, through diagrams, gives the reader a taste of the moves that were made as the program dealt with online checkers games.
The author even gives a dose of the criticism he received from referees when his results were submitted to professional journals, and this gives the book greater appeal from the standpoint of intellectual honesty. Certainly the author and those he worked with have achieved a great deal in the context of building intelligent machines. It remains to be seen whether evolutionary programming can be extended to situations that require even more creativity, such as that of generating new and interesting results in pure mathematics. This is the ultimate test in my view of machine intelligence. It is not immediately obvious how this is to be done in the evolutionary programming or indeed of any other paradigm in artificial intelligence.",19
Anne Markis,2.0 out of 5 stars,Learning scikit-learn: Machine Learning in Python,"Explains little, erroneous code","This book was a disappointment to me. I'm going to say that 80% of the code examples didn't compile if typed directly from the text - usually due to something dumb like an unmentioned import but still a bummer to spend time trying to figure it out. As far as the content, I learned very little: it seemed like it was merely an elongated version of their documentation online, only with more details and less meaning.",19
Dr. Lee D. Carlson,4.0 out of 5 stars,Universal Artificial Intelligence: Sequential Decisions Based On Algorithmic Probability,Very ambitious project.,"This book differs from most books on the theoretical formulations of artificial intelligence in that it attempts to give a more rigorous accounting of machine learning and to rank machines according to their intelligence. To accomplish this ranking, the author introduces a concept called `universal artificial intelligence,' which is constructed in the context of algorithmic information theory. In fact, the book could be considered to be a formulation of artificial intelligence from the standpoint of algorithmic information theory, and is strongly dependent on such notions as Kolmogorov complexity, the Solomonoff universal prior, Martin-Lof random sequences and Occam's razor. These are all straightforward mathematical concepts with which to work with, the only issue for researchers being their efficacy in giving a useful notion of machine intelligence.

The author begins the book with a ""short tour"" of what will be discussed in the book, and this serves as helpful motivation for the reader. The reader is expected to have a background in algorithmic information theory, but the author does give a brief review of it in chapter two. In addition, a background in sequential decision theory and control theory would allow a deeper appreciation of the author's approach. In chapter four, he even gives a dictionary that maps concepts in artificial intelligence to those in control theory. For example, an `agent' in AI is a `controller' in control theory, a `belief state' in AI is an `information state' in control theory, and `temporal difference learning' in AI is `dynamic programming' or `value/policy iteration' in control theory. Most interestingly, this mapping illustrates the idea that notions of learning, exploration, adaptation, that one views as ""intelligent"" can be given interpretations that one does not normally view as intelligent. The re-interpretation of `intelligent' concepts as `unintelligent' ones is typical in the history of AI and is no doubt responsible for the belief that machine intelligence has not yet been achieved.

The author's formulations are very dependent on the notion of Occam's razor with its emphasis on simple explanations. The measurement of complexity that is used in algorithmic information theory is that of Kolmogorov complexity, which one can use to measure the a prior plausibility of a particular string of symbols. The author though wants to use the `Solomonoff universal prior', which is defined as the probability that the output of a universal Turing machine starts with the string when presented with fair coin tosses on the input tape. As the author points out, this quantity is however not a probability measure, but only a `semimeasure', since it is not normalized to 1, but he shows how to bound it by expressions involving the Kolmogorov complexity.

The author also makes use of the agent model, but where now the agent is assumed to be acting in a probabilistic environment, with which it is undergoing a series of cycles. In the k-th cycle, the agent performs an action, which then results in a perception, and the (k+1)-th cycle then begins. The goal of the agent is to maximize future rewards, which are provided by the environment. The author then studies the case where the probability distribution of the environment is known, in order to motivate the notion of a `universal algorithmic agent (AIXI).' This type of agent does not attempt to learn the true probability distribution of the environment, but instead replaces it by a generalized universal prior that converges to it. This prior is a generalization of the Solomonoff universal prior and involves taking a weighted sum over all environments (programs) that give a certain output given the history of a particular sequence presented to it. The AIXI system is uniquely defined by the universal prior and the relation specifying its outputs. The author is careful to point out that the output relation is dependent on the lifespan or initial horizon of the agent. Other than this dependence the AIXI machine is a system that does not have any adjustable parameters.

The author's approach is very ambitious, for he attempts to define when an agent or machine could be considered to be `universally optimal.' Such a machine would be able to find the solution to any problem (with the assumption that it is indeed solvable) and be able to learn any task (with the assumption that it is learnable). The process or program by which the machine does this is `optimal' in the sense that no other program can solve or learn significantly faster than it can. The machine is `universal' in that it is independent of the true environment, and thus can function in any domain. This means that a universal optimal machine could perform financial time series prediction as well as discover and prove new results in mathematics, and do so better than any other machine. The notion of a universally optimal machine is useful in the author's view since it allows the construction of an `intelligence order relation' on the ""policies"" of a machine. A policy is thought of as a program that takes information and delivers it to the environment. A policy p is `more intelligent' than a policy p' if p delivers a higher expected reward than p'.

The author is aware that his constructions need justification from current practices in AI if they are to be useful. He therefore gives several examples dealing with game playing, sequence prediction, function minimization, and reinforcement and supervised learning as evidence of the power of his approach. These examples are all interesting in the abstract, but if his approach is to be fruitful in practice it is imperative that he give explicit recommendations on how to construct a policy that would allow a machine to be as universal and optimal (realistically) as he defines it (formally) in the book. Even more problematic though would be the awesome task of checking (proving) whether a policy is indeed universally optimal. This might be even more difficult than the actual construction of the policy itself.",19
Catherine,2.0 out of 5 stars,Python Machine Learning,Not recommended for beginners,"Personally, I would not recommend this book to beginners. Without some kind of background in Machine Learning, it is hard to follow all the methods and understand why the author wants to discuss these methods and how they should be used. The introductory chapter is mostly useless and does not provide much information on what Machine Learning is. It also bothers me how there are so many typos and some inconsistent notational usage. The codes are pretty helpful but at some point I got weary of reading about how to implement pre-written packages of the algorithms instead of actually implementing the algorithm (granted that the scikit-learn package is widely used in the ML community but it would help beginners to learn how to actually implement the algorithms instead of just blindly implementing the packages). I wish the author would also discuss more into details of the mathematical derivation and background as well as the motivations of some of the algorithms. This book should only be used only after taking an introductory course in ML (I highly recommend Machine Learning by Andrew Ng on Coursera). Otherwise, one can frequently get lost in between the discussion of various methods without knowing exactly how these methods were derived or why they are useful to know.",18
Alex,1.0 out of 5 stars,Design Patterns: Elements of Reusable Object-Oriented Software,Kindle Edition Diagrams Unreadable,"This one star review is strictly a review of the terrible kindle version. The images, figures, diagrams or basically anything that is not text is such low resolution that it is unreadable. The legibility of the diagrams is absolutely necessary for such a book to be useful. The diagrams in the kindle edition are not legible. Why even offer a kindle edition if it's this bad? Now I have to figure out how to get my $40 back and I still don't have the reference book that I need.",18
Mark,1.0 out of 5 stars,Amazon Echo: Master Your Amazon Echo; User Guide and Manual,Embarrassingly bad,"It's revealing that the 5-star reviews all sound like this book -- simpleminded, insincerely upbeat, way more enthusiastic than is justified, and just plain cringeworthy. The book is written with a tone you'd expect from a octagenarian who's still overwhelmed by the magic of, say, telephony or automobiles or indoor plumbing, but who's had a tad too much caffeine. The relentlessly happyfaced language is condescending to the point of being offensive. and there's enough of it on every page to make you cringe. To call this ""promotional"" material, as some here have, is an insult to promotional material.

About content: I held my nose & read more than halfway through before coming to *one* piece of information I didn't already know -- that you can apparently change the Echo's wake word to a third option (Simon), although that doesn't seem enabled on ours, so maybe it's coming or a regional thing. Nothing else in the entire book qualifies as instructions for the ""mastery"" implied in the title, and I'm frankly appalled at that misrepresentation.",18
K. P. Badertscher,2.0 out of 5 stars,The Singularity Is Near: When Humans Transcend Biology,"Too optimistic, too wacky, too wrong.","The full title of this book is ""The Singularity Is Near: When Humans Transcend Biology,"" and like its title, the book is verbose and very, very speculative. I know, I know. What should I expect from futurist Ray Kurzweil other than futuristic foo from the future? How about a book with a coherent structure? How about a book that doesn't repeat its fundamental premises multiple times in each chapter? Maybe a book that leaves out a few unsupported theoretical assumptions stated as foregone conclusions? Singularity has a few fascinating passages, some really interesting ideas, and a collection of delightfully eclectic quotes. Sadly, all the good stuff is surrounded by a repetitious screed with nearly as much substance in the footnotes as in the text.

Kurzweil starts off on the wrong foot with some wrong predictions for technological advances to appear ""by the end of the decade."" Given that the book was published in 2005, and as I write this it is 2011, we should be able to fact-check some of these predictions. ""We will have the requisite hardware to emulate human intelligence with supercomputers..."" Nope. ""Computers... will become essentially invisible: woven into our clothing, embedded in our furniture and environment..."" Nuh uh. Yes, lots of smart devices exist now, but wearable computing turned into the smartphone, and pervasive computing isn't all that pervasive. There's also a claim that the Web will become the ""worldwide mesh... once all of its linked devices become communicating web servers...."" The only real approximation of this is botnets, created with malware and harnessed by malcontents. While a few impressive networked computing projects currently exist, most folks still don't give up their CPU's background cycles to anything productive.

After a rocky start predicting the near future, how are we expected to follow along as Kurzweil turns us into plugged-in cyborgs with nanobot blood who can merge and reform our identities at will? One example: virtual reality. Over and over again we are reminded that we will soon be using fully immersive virtual reality. ""By early in the 2nd decade of this century"" we will have fully immersive 3D environments beamed into our eyeballs, and shortly thereafter we will be plugged in using devices that directly stimulate our sense centers in the brain. But who is going to build these environments? Are we doomed to socialize using virtual meeting places as bizarre as Second Life, furries and ambulatory vegetation and penises everywhere you look, only with more fidelity than we can currently imagine and plugged in to our brains? Who wants that?

There's a lot more way-out-there stuff I could bring up from the book, but that's really not its worst failing. The thing that bothered me most about it was the repetition. It's almost as though Kurzweil at some point abandoned a reasoned thesis for truth by repetition. He goes on and on again and again about how we will know the brain's inmost secrets, and how nanobots will solve ecological problems, and how superintelligent sentient machines will treat us wetware humans with respect and care. It's all very Pollyanna, and in some cases more than a little disturbing. Kurzweil's vision of the ultimate goal of humanity is a nanobot swarm with superintelligent AI flying at near the speed of light and colonizing wherever it lands without regard for existing life of any kind. If that's my future, I want out.",18
Gaji,2.0 out of 5 stars,The Singularity Is Near: When Humans Transcend Biology,Mind numbingly boring,"I'm an engineer and I could argue against this book's basic premise - that all progress is exponential and therefore, just around the corner we are about to upload our consciousness onto the great-grand-son of my laptop. The simple fact is that all progress is not exponential - the harder the problem, the slower the progress, if at all. Examples: the space program. Prolonging maximum life spans. Genetically engineering medicines. Curing the simple cold (or fighting viruses in general). Progress is sometimes linear. And sometimes, not at all. Just ask all those miserable folks that had the bad luck of living through the Middle Ages.

But never mind that - this book's biggest sin is not the theory it is trying to propagate but the way it does it: it is simply a very, very boring read. The author dives into minute details of the progress being made both in computer science and neuroscience to explain why we are oh-so-close but the story he tells is not compelling. It is organized like a laundry list (prepare to read a lot of bullet items) and it reads just like one. The author spends way too much time trying to quantify the amount of information in the brain for example, without stopping to discuss the impact of the complexity of this information - the fact that human DNA, information wise, fits on a 10 cent data CD, doesn't mean that anyone in any lab has a clue how to create the DNA of a new type of fly, let alone that of a human being. In getting lost in all the details, the author provides no vision of the forest itself and the big, big problems lurking there.

I expected a lot more and got thoroughly disappointed.",18
L. Blunden,5.0 out of 5 stars,Introduction to the Theory of Computation,Appeals to novice and expert,"I have a long experience with software development, but not much background in computation theory, just fascinating tidbits I have picked up here and there. So, this book for the first time deepens and organizes for me this hightly abstract and difficult topic.

Being a novice, I at first was afraid that the text of the book would be beyond my understanding. It was not. For sure, the proofs are difficult and may appeal to the person with a degree in computer science. But the copious diagrams, figures and tables are wonderful supplements to the understandable text. For the first time I really could grasp the subtleties of the finit automata, non-determinism, regular expressions, pushdown automata and other topics.

Certainly I can recommend this book to the beginner at computation theory, and even to the more advanced student who may want to review the topic.",18
catwings,4.0 out of 5 stars,Probabilistic Graphical Models: Principles and Techniques (Adaptive Computation and Machine Learning series),used for Coursera PGM course,I bought this book to use for the Coursera course on PGM taught by the author. It was essential to being able to follow the course. I would not say that it is an easy book to pick up and learn from. It was a good reference to use to get more details on the topics covered in the lectures.,18
Rafael Espericueta,5.0 out of 5 stars,Probabilistic Graphical Models: Principles and Techniques (Adaptive Computation and Machine Learning series),Free online Stanford course by one of this text's authors!,"Interestingly, one of the author's of this text is teaching a free online course on Probabilistic Graphical Models, starting in January 2012. I just signed up!

Google it and you'll find it...",18
Amazon Customer,5.0 out of 5 stars,Make Your Own Neural Network,Very readable introduction to neural networks,This is the most effective but gentle introduction to neural networks I've seen. No other authors of NN primers dare to delve into matrices as the basic math for understanding them but Mr. Rashid pulls it off beautifully. There are lots of very helpful diagrams to make the points clear.,18
Amazon Customer,1.0 out of 5 stars,Make Your Own Neural Network,One Star,Pages are missing and on page 74 it jumps to page 149 then to page 77.,18
Jacob Donkin,5.0 out of 5 stars,Our Final Invention: Artificial Intelligence and the End of the Human Era,"Gripping and Informative, a Must-read","As someone who struggles to finish books in their entirety, I found Our Final Invention by James Barrat highly readable, deeply informative, and utterly gripping. The book contains a powerful message: through competition, distrust, desire and curiosity, humans will inevitably create an artificial intelligence (AI) that rivals or surpasses our own. Thus, it is wise and necessary to invest now in mitigation efforts and potential safeguards -- increased research and advocacy for AI risk and, most importantly, producing friendly AI.

Barrat covers a lot of ground, but his main argument is summarized as follows: Currently, we humans regularly utilize narrow AI technology (technology capable of achieving specific, programmed goals through unassisted human computing -- Siri, Google search, IBM's Watson, etc). We are also experimenting with ""black box"" tools and techniques (programs where inputs and outputs are understood and measurable, but the processes in between aren't -- genetic algorithms/programming and software that writes better software) and artificial neural networking (ANN), as seen through efforts to reverse engineer the human brain. And, below the surface, there is an ongoing race between world powers (driven mainly by national security, defense, and international business interests) and guided by AI developers to develop and achieve artificial general intelligence (AGI) -- human-level artificial intelligence. The problem is that once AGI is achieved it will be very difficult to manage, and may very well result in the manifestation of artificial super intelligence (ASI) -- greater than human-level intelligence.

ASI could theoretically become thousands of times smarter than the smartest human being alive. It won't think like us, won't want to be ruled by us, and, most crucially, it won't want to be turned off. In fact, ASI would likely regard us as potential fuel for its quest to duplicate and improve itself exponentially in order to achieve its goals.

Throughout the book, Barrat refers to interesting psychological phenomena and concepts (such as the normalcy bias), while drawing on personal experiences, historic events, and interviews with computer programmers, inventors and philosophers, to tactfully illustrate how progress in AI development is dangerously rapid. Adequate checks and balances are not in place to deal with a non-ideal intelligence explosion or hard take-off (AGI quickly leading to ASI).

I highly recommend this book to anyone interested in learning about both human beings and the advancement of machines. I suspect that the prominence of AI, as a research field and topic for discussion, will only increase in time (it already has in recent years -- drones, smart technology, Wall Street high frequency trading (HFT), financial modeling), making Our Final Invention a valuable guide or stepping stone for anyone trying to understand our world and the path of the future.",18
albenali,1.0 out of 5 stars,Programming Collective Intelligence: Building Smart Web 2.0 Applications,"Outdates, Code no longer works","I would not recommend anyone buying this book. The examples are outdated, based on sites that don't even exist anymore. The list of errata is huge (and doesn't even include all the errata I found).

Finally, the the author references old versions of python libraries that no longer 'work as advertised', or that have changed so radically that the example code will not even run - you'll be spending hours just figuring out how to update the code to be compatible with newer versions of the libraries referenced in the book. That in itself is a frustrating experience.

My advice is, get another book for Python or ML if that's what you're looking for and don't waste your time with this one.",18
Riccardo Audano,4.0 out of 5 stars,Programming Game AI By Example (Wordware Game Developers Library),Give some life to your game agents!,"If you are intererested in coding intelligente agent that can move around, flock, swarm, hunt and flee or follow a basic sort of strategic behaviour this text is an excellent choice. It offers practical examples examples of all of the above in the context of a simple soccer game and a search & destroy game called raven. Don 't expect 3D and fancy graphics. All games and concepts are 2D and the graphics is rudimentary at best, but that serves the puropose of keeping teh complexity of the book to manageable levels and the focus on AI programming. There is ton of example code to study and play with, and the little theory in the book basically is just an explanation of the code that the author has written. I would have liked to see more space dedicated to theory, and clearer and more genral explanations instead of ""here is the code that.."" but oh well better too much practice than too much theory.. and after all the book title makes it clear that this is a hands-on kind of text.

Definitely a must have book for the aspiring AI programmer or hobbist. Code is C++ but you don' t need to be a C++ guru, knowing the basics will serve you fine. Only one warning: you won 't get much out of this book is you don't spent a lot of time tinkering with the code presented and trying to extend it.",18
Coert Visser,5.0 out of 5 stars,On Intelligence,Exciting new theory on intelligence,"We often routinely talk about intelligence and we attempt to measure it for for a variety of purposes. But do we know what it is? Jeff Hawkins is one of the first people to present a specific and comprehesensive theory of intelligence with a leading role for the human neocortex. Hawkins starts by stating that Human intelliigence is fundamentally different from what a computer does.

But isn't artifical intelligence (AI) a good metaphor for human intelligence? No, says Hawkins. In AI a computer is taught to solve problems beloning to a specific domain based on a large set of data and rules. In comparison to human intelligence AI systems are very limited. They are only good for the one thing they were designed for. Teaching an AI based system to perform a task like catching a ball is hard because it would require vast amounts of data and complicated algorithms to capture the complex features of the environment. A human would have little difficulty in solving such everyday problems much easier and quicker.

Ok, but aren't neural networks then a good approximation of human intelligence? Although they are indeed an improvement to AI and have made possible some very practical tools they are still very different to human intelligence. Not only are human brains structurally much more complicated, there are clear functional differences too. For instance, in a neural network information flows only one direction while in the human brain there is a constant flow of information in two directions.

Well, isn't the brain then like a parallel computer in which billions of cells are concurrently computing? Is parallel computing what makes human so fast in solving complex problems like catching a ball? No, says the author. He explains that a human being can perform significant tasks within much less time than a second. Neurons are so slow that in that fraction of a second they can only traverse a chain of 100 neurons long. Computers can do nothing useful in so few steps. How can a human accomplish it?

All right, human intelligence is different from what our computers do. What then is it? I'll try to summarize Hawkin's theory.

The neocortex constantly receives sequences of patterns of information, which it stores by creating so-called invariant representations (memories independent of details). These representations allow you to handle variations in the world automatically. For instance, you can still recognize your friends face although she is wearing a new hairstyle.

All memories are stored in the synaptic connections between neurons. Although there is a vast amount of information stored in the neocortex only a few things are atively remembered at one time. This is so because a system, called `autoassociative memory' takes care that only the particular part of the memory is activated which is relevant to the current situation (the patterns that are currently flowing in the brain). On the basis of these activated memory patterns predictions are made -without us being aware of it- about what will happen next. The incoming patterns are compared to and combined with the patterns provided by memory result in your perception of a situation. So, what you perceive is not only based on what your eyes, ears, etc tell you. In fact, theses senses give you fuzzy and partial information. Only when combined with the activated patterns from your memory, you get a consistent perception.

The hierarchical structure of the neocortex plays an important role in perception and learning. Low regions in the structure of the neocortex make low-level predictions (about concreet information like color, time, tone, etc) about what they expect to encounter next, while higher-level regions make higher-level predictions (about more abstract things. Understanding something means that the neocortex' prediction fits with the new sensory input. Whenever neocortex patterns and sensory patterns conflict, there is confusion and your attention is drawn to this error. The error is then sent up to higher neocortex regions to check if the situation can be understood on a higher level. In other words: are there patterns to be found somewhere else in the neocortex, which do fit to the current sensory input?

Learning roughly takes place as follows. During repetitive learning memories of the world first form in higher regions of the cortex but as your learn they are reformed in lower parts of the cortical hierarchy. So, well-learned patterns are represented low in the cortex while new information is sent to higher parts. Slowly but surely the neocortex builds in itself a representation of the world it encounters. Hawkins: ""The real world's nested structure is mirrored by the nested structure of your cortex.""

This model explains well the efficiency and great speed of the human brain while dealing with complex tasks of a familiar kind. The downside is that we are not seeing and hearing precisely what is happening. When someone is talking we by definition don't fully listen to what he says. Instead, we constantly predict what he will say next and as long as there seems to be a fit between prediction and incoming sensory information our attention remains rather low. Only when he will say something, which is actively conflicting with our prediction, we will pay attention.

The author takes his model one step further by saying that even the motor system is prediction driven. In other words, the human neocortex directs behavior to satisfy its predictions. Hawkins says that doing something is literally the start of how we do it. Remembering, predicting, perceiving and doing are all very intertwined.

I think this is a fascinating and stimulating book. Many questions about intelligence may remain unanswered but I believe this book to be a step forward in our quest to understand intelligence. The author predicts we can soon build intelligence in computersystems by using the principles of the neocortex. He is optimistic about what will happen once we succeed in this. He (reasonably convincing) argues these systems will be useful for humanity and not a threat.

Coert Visser, [...]",18
Pirkka Rannikko,4.0 out of 5 stars,Sketching User Experiences: Getting the Design Right and the Right Design (Interactive Technologies),On design and the designer,"I bought this book because it was recommended by Andy Rutledge in his
podcast ""Design View"". I knew it wouldn't be bad given the nature of
the podcast and the host but I really wasn't sure what to expect
either. With no expectations or biases I started reading and later
found out that it was the ideal way to experience this title.

If had expected a practical book with a more hands-on approach on user
interface design, I would have been disappointed. The book discusses
primarily on how we should do design rather than explaining how to
design any particular things. Bill Buxton also writes about the role
of the user experience design and the designer itself in today's
businesses. The best thing in the book is that the content is full of
interesting stories and rich examples of user experience design in
real life. The text moves from stories to theory to examples and back
again keeping the reader hooked even when the subject at hand might be
a bit too heavy to digest on the first reading. Everything is well
written and the author more than ""knows his stuff"". The examples come
with extraordinary pictures that are a great source for inspiration.
The book is also a good reference of other books about the subject.

If you are looking for a hands-on guide or a text-book to user
experience/ interface design this not your pick. Also it is not a book
for usability enthusiasts or engineers either. Sketching User
Experiences is a book for those designers and would-be designers who
want to get new ideas and perspective on their profession and the
design business itself.

At least I am sure that I'll be sketching more in the future than
before reading this book...",18
The Expert Selection,5.0 out of 5 stars,"Amazon Echo: The Ultimate Guide to Learn Amazon Echo In No Time (Amazon Echo, Alexa Skills Kit, smart devices, digital services, digital media) (Amazon Prime, internet device, guide) (Volume 6)",Perfect guide for amazon echo,Perfect guide for amazon echo! Teaches a lot and even though amazon echo itself does not come with a clear guide on how to use it: this book probably includes more than amazon itself would since it is an outside source! So I recommend this!,18
L. Blunden,5.0 out of 5 stars,Introduction to the Theory of Computation,Appeals to novice and expert,"I have a long experience with software development, but not much background in computation theory, just fascinating tidbits I have picked up here and there. So, this book for the first time deepens and organizes for me this hightly abstract and difficult topic.

Being a novice, I at first was afraid that the text of the book would be beyond my understanding. It was not. For sure, the proofs are difficult and may appeal to the person with a degree in computer science. But the copious diagrams, figures and tables are wonderful supplements to the understandable text. For the first time I really could grasp the subtleties of the finit automata, non-determinism, regular expressions, pushdown automata and other topics.

Certainly I can recommend this book to the beginner at computation theory, and even to the more advanced student who may want to review the topic.",18
TomZ,2.0 out of 5 stars,Real-Time C++: Efficient Object-Oriented and Template Microcontroller Programming,Didn't Like This Book,"I read a lot of software engineering books, and generally I'm pretty open to a lot of different ideas and viewpoints. But I really did not like this book. There were two things in general I did not like. First, I felt that the author has not really used C++ in real-time systems for a long time - his approach did not show much depth or insight compared to someone using it for the first time. I had expected to see a lot of new techniques, but I did not.

Second, the author uses a lot of C++11 features, which are not available yet in most (all?) commercial embedded systems compilers. This in itself is not a bad thing, but in this case it allowed the author to side-step some of the more tricky aspects of real-time programming with more widely available dialects of C++. For example, initialization of objects with constant data is a little tricky to do efficiently with today's compilers. The author avoided this topic entirely by advocating use of C++11-specific initialization features.",18
Grayson,1.0 out of 5 stars,Getting Started with TensorFlow,Mostly stuff you already know,"Should've listened to the other review -- this book was definitely rushed. A solid 15-20% of the book is an overview of python and programming in general, another 20-30% covering basic math in tensorflow, and another 30% or so on a high level overview on what machine learning is. Is anyone who would buy a book on TensorFlow in need of an overview of any of these topics? The remainder of the book is dedicated to walking through examples that are readily available through the existing free resources / docs. This book was a cash grab -- don't fall for it.",18
JOHN W BODNAR,3.0 out of 5 stars,Signals and Boundaries: Building Blocks for Complex Adaptive Systems (MIT Press),Hidden Order... and not much more.,"I really enjoyed reading Holland's ""Hidden Order: How Adaptation Builds Complexity"" when it was published two decades ago. Unfortunately, in ""Signals and Boundaries"" Holland did not add any significant points he did not make in that previous book. As a biologist, I ascribe this to the ""biology should be more like physics"" school of investigation on the evolution of complexity. When integrating physics and math with biology, the hypotheses you can examine depend on the sophistication of the inputs. Here Holland mixes some very sophisticated math concepts with concepts in ""biological information"" at the high-school level. With all the recent work in bioinformatics and systems biology, we should be able to do better.",18
Tim Josling,5.0 out of 5 stars,Fluid Concepts and Creative Analogies: Computer Models Of The Fundamental Mechanisms Of Thought,Wonderful but quite dry in parts,"This book is, as others have commented, different from DH's other more entertaining books.
It is a serious attempt to discuss the real issues and difficulties with AI research. There is a lot of quite dry material and in places it is repetitive.
It provides terrific insight into the problem of imitating human thinking at a deep level, and I found it very rewarding. It was also very interesting to follow the threads of how he went about doing research, and what he thought of other AI research.
His views of various flavours of AI research were very instructive and inightful I thought.
In summary a good book, but this is not (high quality) brain candy like Godel Escher Bach etc.",18
Len Edgerly,5.0 out of 5 stars,"Final Jeopardy: The Story of Watson, the Computer That Will Transform Our World",Rare to have this much fun reading a book AND to learn so much!,"Stephen Baker's account of the creation and teaching of IBM's Watson computer, preparing it for the climactic Jeopardy contest with the two top living human Jeopardy champions, is a delight to read AND a highly informative overview of artificial intelligence and the role computers will play in our lives from here on out. You get to know and appreciate the complex, talented characters of the story at IBM and in Hollywood. The growing sense of drama makes the book un-put-downable. Will IBM's engineers prepare Watson to figure out the pun-filled, playful and quirky categories of Jeopardy? Will the Hollywood execs agree to fair terms of engagement? And, most intriguingly, who will win the final showdown?

I love what Baker's publisher has done with the Kindle version of this book - making the first 11 chapters available well before the showdown Jeopardy match airs on Feb. 14-15-16. After the actual match took place, in great secrecy, Baker wrote the final chapter of his book, which will arrive as a Kindle download the day after the final match, when the hardcover will also be available, with all the chapters. This is a fantastic use of e-book technology, so bravo to Houghton Mifflin for such a clever and Kindle-friendly innovation.

[...]",18
Ana R.,5.0 out of 5 stars,Mastering MATLAB 7,MatLab programming,"I use this book everyday. It is easy to find what you need right away. Although, MatLab has demos that you can use to write programs or m-scripts, the book has features that are not in the demos that will make writing scripts much easier. It doesn't go into great detail with more difficult plots but allows for the those who just need 1-D, 2-D and simple 3-D plots to plot data points easily and fast. This is definitely the bible for first time users of MatLab.",18
Panos_Ptr,5.0 out of 5 stars,Python Machine Learning,Great Book.,"In my opinion this is a great book to get you up and running with machine learning. It manages to not only cover the basics but also talks about some of the more advanced topics.

There are a couple of things that I really liked about this book.

1. You learn a lot of things that you can't find online and that are APPLICABLE to the real world. Even if you just want to get into machine learning and use it but don't necessarily want to become a data scientist this is a great buy. Machine Learning can be really useful when put into good use. I for example, after reading the book, was able to quickly write up a python program to predict what time I would wake up based on what time I slept, what day it was etc. As well as having tons of fun playing with data from http://archive.ics.uci.edu/ml/ .

2. Although this book is focusing on python the math that you need to implement the algorithms are all there. What's great about that is that I was able to ""Translate"" most of the examples from the book to C++ code without much hustle. Not only that but the math behind these algorithms made a lot more sense after reading this book. So even if you don't necessarily want to use python but want to gain intuition over how these algorithms work this book will also come in handy.

3. This book isn't just about Machine Learning algorithms. It actually talks quite a bit about preparing and getting good data in general. Which is crucial for every data scientist since almost 80% of your job is getting good data. And another 20% finding a good model and training it.

Overall I would say that this book helped me and that I learnt a bunch of new things.

If the above didn't convince you (Along with other reviews) here are some small details that made the reading of this book a joyful experience.

- I felt that reading the book was actually really fun and motivating since at every chapter there were several examples of applying the theory taught. Which motivated me to move on and read more.

- Although this may not seem as important. I have to say that the font of the book as well as the tone of the writing made the reading of the book really comfortable and joyful. I didn't feel that I was getting tired and was easy for me to pick it up where I left off.

I have to say though that there where some typos here and there (I thing I found 2-3 in total as well as 2 pictures where swapped) but they were easy to spot so it wasn't that big of a problem.

Reasons why you shouldn't buy this book:
Unless you are a Machine Learning expert and you look into the deeper insights and more advanced stuff in Machine Learning you shouldn't be looking into buying this book since most of the stuff taught is already known to you. (Although I doubt that you would be looking through this reviews thinking whether to buy it or not in this case).

I have also included some pictures.

Great Book. Highly Recommend it!",17
S. Matthews,5.0 out of 5 stars,"The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Second Edition (Springer Series in Statistics)",my big brown book of statistic learning tools,"This is a quite interesting, and extremely useful book, but it is wearing to read in large chunks. The problem, if you want to call it that, is that it is essentially a 700 page catalogue of clever hacks in statistical learning. From a technical point of view it is well-ehough structured, but there is not the slightest trace of an overarching philosophy. And if you don't actually have a philosophical perspective in place before you start, the read you face might well be an even harder grind. Be warned.

Some of the reviews here complain that there is too much math. I don't think that is an issue. If you have decent intuitions in geometry, linear algebra, probability and information theory, then you should be able to cruise through and/or browse in a fairly relaxed way. If you don't have those intuitions, then you are attempting to read the wrong book.

There were a couple of things that I expected (things I happen to know a bit about), but that were missing. On the unsupervised learning side, the discussion of Gaussian mixture clustering was, I thought, a bit short and superficial, and did not bring out the combination of theoretical and practical power that the method offers. On the supervised learning side, I was surprised that a book that dedicates so much time to linear regression finds no room for a discussion of Gaussian process regression as far as I could see (the nearest point of approach is the use of Gaussian radial basis functions [oops: having written that, I immediately came across a brief discussion (S5.8.1) of, essentially, GP regression - though with no reference to standard literature]).",17
Wu Zheng,2.0 out of 5 stars,Pattern Recognition and Machine Learning (Information Science and Statistics),"disappointed, cover a lot but few is explained enough","Not easy for a student with no experience on Machine Learning before. It might be useful for those researchers who have seen a lot. Many ""straightfoward"" or ""easy to show"" questions are not easy for me at a first glance. Many discussions are left to numerous papers, which does not make problem more clear but more puzzled. Many many comments are made in a very high level without detailed explanation. Most exercises are only algebra and matrix theory, nothing to do with Algorithm. I have to read other books first.",17
Stacy Meyer,3.0 out of 5 stars,Amazon Echo: Master Your Amazon Echo; User Guide and Manual,Just read the manual.,"I was hoping I would learn something new above what is already in the manual for the device, but that's not the case. This is the manual just stretched out. I guess if you need the manual in easy to understand terms, them this is for you. If you're looking for something above the manual, then this isn't it.",17
Math Book Reviewer,2.0 out of 5 stars,Machine Learning: A Probabilistic Perspective (Adaptive Computation and Machine Learning series),"Bad for Students, Good for Experts","In a nutshell, the value of reading Murphy's Machine Learning highly depends on what you expect to get out of it.
------------------
As a graduate student who had read a descent number of papers in the field, I feel very conflicted about this textbook.
------------------
If you expect to teach yourself machine learning from this textbook, this is in my opinion almost surely *not* the textbook to get. (0/5 Stars)
-The content of the textbook is highly disorganized. Future chapters are constantly referenced in the text (as if you have already read them!). Perplexingly, meaningful explanations of concepts are often delayed by multiple chapters. (Ex. BIC is introduced in Ch.6 but a mathematical justification is provided only in Ch. 8 when the mathematical justification could have (and should have) been in Ch. 6).
-A number of topics are merely mentioned (like VC dimension) but not actually discussed at any reasonable length, making some sections of the textbook meaningless.
-I would instead recommend the related (but different) text Introduction to Statistical Learning with Applications in R as it is quite accessible.
-----------
However, if you are an instructor and wish to use this textbook as a supplement to a course or are a researcher then Murphy's Machine Learning is in my opinion could be a worthwhile purchase. (4/5 stars)
-The examples, references and illustrations give the textbook a particularly nice touch. (I particularly enjoyed the example of calculating the posterior probability of user ratings of two different items on Amazon).

In summary, if you are an instructor that wants their students to learn how to read challenging exposition to prepare them for reading research papers in the field or if you wish to use this as a reference, then this is a good choice. Otherwise, pass.",17
D. Kittrell,5.0 out of 5 stars,Grokking Algorithms: An illustrated guide for programmers and other curious people,Good introduction to the topic,"An excellent introductory text.. While it won't replace formal, traditional, approaches to the subject this is near perfect if you're looking for a quick overview covering key algorithms, Big-O notation and its implications for various approaches, low-math and minimal jargon, and a bit of fun. The illustrations and diagrams are hand-drawn and well-suited to the content style (as well as being clear and simple to follow). If you're looking for a formal introduction or an academic approach this isn't the book for you but it gets the job done as a solid introductory text. I try to keep up with books on a variety of CS/Dev subjects both for myself and to check out new texts for others; this one I'll be highly recommending.

Let's hope the author keeps this up with a ""Grokking"" series covering other CS/Dev topics.

BTW, the book includes an insert with a code for a free e-book version. I overlooked that on first reading; it's a nice addition if you want to add a portable electronic copy for quick reference.",17
???,5.0 out of 5 stars,Probabilistic Graphical Models: Principles and Techniques (Adaptive Computation and Machine Learning series),Milestone work!,"Gives you systematic view of the subject.
Every chapter is with clear explaination, up-to-date expamples and full algorithm implemention by pseudocodes.
A must have for computer scientist who want to enter this field.",17
Dr. Lee D. Carlson,5.0 out of 5 stars,Reinforcement Learning: An Introduction (Adaptive Computation and Machine Learning),An excellent introduction,"As a subfield of artificial intelligence, reinforcement learning has shown great success from both a theoretical and practical viewpoint. Taking the form of numerous applications in finance, network engineering, robot toys, and games, it is clear that his learning paradigm shows even greater promise for future developments. The authors summarize the foundations of reinforcement learning, some of this coming from their own work over the last decade.

The authors define reinforcement learning as learning how to map situations to actions so as to maximize a numerical reward. The machine that is indulging in reinforcement learning discovers on its own which actions will optimize the reward by trying out these actions. It is the ability of such a machine to learn from experience that distinguishes it from one that is indulging in supervised learning, for in the latter examples are needed to guide the machine to the proper concept or knowledge. The authors emphasize the ""exploration-exploitation"" tradeoffs that reinforcement-learning machines have to deal with as they interact with the environment.

For the authors, a reinforcement learning system consists of a `policy', a `reward function', a `value function', and a `model' of the environment. A policy is a mapping from the states of the environment that are perceived by the machine to the actions that are to be taken by the machine when in those states. The reward function maps each perceived state of the environment to a number (the reward). A value function specifies what is the good for the machine over the long run. A model, as the name implies, is a representation of the behavior of the environment. The authors emphasize that all of the reinforcement learning methods that are discussed in the book are concerned with the estimation of value functions, but they point out that other techniques are available for solving reinforcement learning problems, such as genetic algorithms and simulated annealing.

The authors use dynamic programming, Monte Carlo simulation, and temporal-difference learning to solve the reinforcement learning problem, but they emphasize that each of these methods will not give a free-lunch. An entire chapter is devoted to each of these methods however, giving the reader a good overview of the weaknesses and strengths of each of these approaches. The differences between them usual boil down to issues of performance rather than accuracy in the generated solutions. Temporal difference learning in fact is viewed in the book as a combination of Monte Carlo and dynamic programming techniques, and in the opinion of this reviewer, has resulted in some of the most impressive successes for applications based on reinforcement learning. One of these is TD-Gammon, developed to play backgammon, and which is also discussed in the book.

The authors emphasize that these three main strategies for solving reinforcement learning problems are not mutually exclusive. Instead each of them could be used simultaneously with the others, and they devote a few chapters in the book illustrating how this ""unified"" approach can be advantageous for reinforcement learning problems. They do this by using explicit algorithms and not just philosophical discussion. These discussions are very interesting and illustrate beautifully the idea that there is no ""free lunch"" in any of the different algorithms involved in reinforcement learning.

In the last chapter of the book the authors overview some of the more successful applications of reinforcement learning, one of them already mentioned. Another one discussed is the `acrobot', which is a two-link, underactuated robot, which models to some extent the motion of a gymnast on a high bar. The motion of the acrobot is to be controlled by swinging its tip above the first joint, with appropriate rewards given until this goal is reached. The authors use the `Sarsa' learning algorithm, developed earlier in the book, for solving this reinforcement learning problem. The acrobot is an example of the current intense interest in machine learning of physical motion and intelligent control theory.

Another example discussed in this chapter deals with the problem of elevator dispatching, which the authors include as an example of a problem that cannot be dealt with efficiently by dynamic programming. This problem is studied with Q-learning and via the use of a neural network trained by back propagation.

The authors also treat a problem of great importance in the cellular phone industry, namely that of dynamic channel allocation. This problem is formulated as a semi-Markov decision problem, and reinforcement learning techniques were used to minimize the probability of blocking a call. Reinforcement learning has become very important in the communications industry of late, as well as in queuing networks.",17
Amazon Customer,5.0 out of 5 stars,Neural Network Design (2nd Edition),Seems like an excellent book so far I tried about 10 ...,"Seems like an excellent book so far
I tried about 10 other books on Neural networks, and always got stuck after the first chapter.
This book, actually EXPLAINS stuff.
It explains the mathematics very nicely before it is used with Neural networks, and there are loads, and loads of worked examples.
As long as you go through the worked examples, you can learn the material.

The book refers a lot to Matlab, I dont think you need Matlab to understand the book, but will get more out of the book if you have Matlab.
I used Mathematica for symbolics, when studying the book, (I suppose I could have used Matlab instead,
but you will need some symbolic software)

A very excellent and readable book.
They also give it away for free on the internet, but I recommend getting the book, as saves hassle of printing stuff out, and you need a hard copy,
to write notes on.

A curious thing, an excellent textbook (in my opinion the best on the subject), and apparently they have a set of instructional videos to go
with it. Why don't they just post the instructional videos on youtube, then charge 100 bucks for the book. I would still consider the excellent value at that price. I think the goal of the book, is to prop up Matlab's position as number 1 piece of software for Neural networks.
But seriously, a book that helps you learn and study neural networks, and the ONLY book that I have come across so far, that seems to do a good job of explaining.
Good explanations, Many, many worked examples, well presented, a LINEAR learning curve.
(A lot of books seems to have an easy first chapter to sell the book, then go off the cliff, but this seems linear throughout)
So, lots of good points, would recommend, especially if you find, like me you got bogged down in other texts.",17
David Taylor,3.0 out of 5 stars,"Artificial Intelligence for Humans, Volume 1: Fundamental Algorithms",A Basic Introduction to Machine Learning,"This book claims to be an overview of artificial intelligence, but it??s not; it??s an overview of machine learning. It??s true that machine learning is a hot topic within AI just now, but it's hardly taken over the field, nor has it rendered all other methods obsolete. But, if you just want an informal introduction to the basic forms of machine learning, it's short and easy to read. The rubber never quite meets the road, but if all you need is the basic concepts, it's not a bad start.

It does, however, contain errors that really should have been caught prior to publication. In addition to the errors mentioned by another reviewer, the references to equations 10.2 through 10.4 are wrong, and the description of the logistic function shown in Figure 10.3 doesn??t match the function shown. The notation specifies the curve as going from 0 to , but it is drawn from 1 to 0, which is backward from what the author intended. Also, the curve is described in the text as a logit function, which the author seems to confuse with the logistic. They both has S shapes, but they are very different things with different roles to play in terms of how they bound their values. To put it graphically, the S of a logit is horizontal, with the tails extending up and down, not vertical with tails to the left and right as shown in the figure.",17
Paul Sztorc,5.0 out of 5 stars,"The Age of Em: Work, Love, and Life when Robots Rule the Earth",Raises the Standard for Futurist Writing,"This book is about the ""Em"", a virtual human mind with no physical body. Remember The Matrix (1999)? It's like that, but there's no hairless Keanu Reeves in a pink goo pod. Instead, Neo is just a file on a computer, in a server rack somewhere. If we need Neo to do two things at once, we can just copy him (just like movie-Neo copied all those guns). If we decide Neo is 'the best of the best' at something, we might copy him a trillion times, and erase his competitors. The copies are just as human as you or I.

The book is important for two reasons.

The first is that it directly concerns the welfare of trillions of future lives (who may suffer under slavery, total dictatorship, torture, and constant genocide, or who alternatively may live in a paradise of comfort, meaningful work, and total fulfillment). Small actions, taken early enough, could have a big impact on the Age of Em; this book gives us that head start.

Secondly, the book is important in its focus on values. Hanson demonstrates that values are a biological adaptation like any other (the bird's wings, or the fish's scales) and that nature and nurture conspire to ensure that animals end up with productive values. While you may value ""family"" or ""free time"", your decedents might be workaholics with no family at all (for reasons beyond their control). As a result, if EMs could meet their ancestors, they might be confused or disgusted.

In other words, this Age threatens to erase, from the world, everything that you believe is important.

This book is essentially an encyclopedia of predictions about the future. These predictions are derived using mainstream social science, and they are clear and concise.

This book is also an extremely *efficient* tour of psych research. Anyone who reads this book two or three times over would probably know as much, or more, as someone graduating with a Psych BA from a leading university. This is because Hanson cherry picks the highest-relevance items. It's also because, by stepping *outside* our Age, it is a little easier to see it for what it is (and, by comparing multiple Ages, one gets a sense of which features are Age-based [and, on what] and which are permanent).

The book is frustrating in that the factual predictions mostly take place in the next century. It's like watching someone hand in an exam, and waiting 100 years to see it get graded; no ""payoff"". And imagine, for a moment, that a hunter-gather sat down to write a book about the Next Era. Would he get it mostly right? Or, would it be so wrong, that reading it would be a waste of time? One can argue that we have more ""data on eras"" now, but, alternatively, the very power-laws these data seem to obey, could be used to argue precisely the opposite (ie, that the pre-X ""data"" aren't representative). The introduction notwithstanding, it is hard to see how the book's ideas affect anyone or anything in our reality. It's hard to get invested.

Correspondingly, my favorite section, ""Dreamtime"" had a higher (data & logic)/predictions ratio. It had nothing to do with EMs specifically, instead, Dreamtime simply reminded us of our place in the history of mankind. And it suggests that, of all the decisions that ever were made or will be made by anyone, only those of our Era will really matter. It's flattering and sobering, overwhelming and motivating. (And it is in the free Amazon preview section.)

I'm happy with my choice of Favorite Section, because I think a focus on ""whether or not Hanson's EM Era actually arrives"" is sorta missing the point. Instead, the point is that we should raise our game -- predictions about the future should be of approximately *this level* of breadth, detail, effort, and empirical corroboration.",17
Dmitri Kozlov,1.0 out of 5 stars,"Artificial Intelligence for Humans, Volume 3: Deep Learning and Neural Networks","Useless for deep understanding, not good for beginners either","The book describes few concepts. A beginner would expect to see a bigger picture rather than a seemingly random set of methods or models. A professional would look for detailed explanation of concepts.The book provides neither. Descriptions are shallow, formulas contain errors, pseudo code is often wrong. Some description would better be replaced with concise and clear formulas, some formulas require explanations. The book needs a proof editing. However, the bigger problem is how the author presents the material.
I'd recommend a much better book to start with: ""Neural Networks and Deep Learning"" by Michael Nielsen.",17
ARod,5.0 out of 5 stars,The Cathedral & the Bazaar: Musings on Linux and Open Source by an Accidental Revolutionary,Well done -- even better in print.,"Not being a highly-technically minded person myself but having been a spectator of the open source phenomenon for the last several years, I found this collection to be enjoyable as well as quite interesting and informative reading.
Having read the original essay online (go find the URL yourself), I enjoy the portability and ease of use to the eyes, that comes with the offline version.",17
Paolo,5.0 out of 5 stars,"Matrix Algebra: Theory, Computations, and Applications in Statistics (Springer Texts in Statistics)",Outstanding and Beautiful,"It deserves SIX stars. Very briefly:
I came across several books of matrix algebra. This is probably the most comprehensive, captivating and informative.
In case of doubts or needs of research about any issue on matrix algebra and methods for analyzing/computing multivariate structures, this is the place to go.
Nothing is missing.
It is not structured with definitions, lemmas, theorems, corollaries. It explains and clearly *proves* every concept in a talkative manner, extremely formal yet. When things gets complicated, it always refers to the proper paragraph for helping the reader to connect the dots.
Computational solutions are described in strict mathematical words (no pseudo code) step by step.
Overall, this is a wonderful piece work.",17
Dave Mccomb,5.0 out of 5 stars,Conceptual Spaces: The Geometry of Thought (MIT Press),A new model of thought,"Profound piece of work. I am not a cognitive scientist, and this book is a bit technical, but it is still within reach of the motivated lay person.
Gardenfors puts forward a a model to explain cognition that he calls ""conceptual spaces."" These conceptual spaces are at a level of abstraction in between the symbolic (used by AI types) and connectionist (Neural Nets). But what makes his conceptual spaces interesting and plausible is the position he takes that in this conceptual space, most reasoning is done by evaluating the analog of a distance between two aspects of a perception. Or, we find things to be similar if they are ""geometrically"" (measurably) closer on some limited number of dimensional scales.
This is easy to follow for things like colors, but he doesn't stop there. He goes on to describe how this explains a wide variety of perceptions, as well as how we form and reform categories and concepts, and shows how this informs semantics and the process of induction.
My only criticism is that some of the illustratios would have been more powerful in color.",17
Todd Ebert,5.0 out of 5 stars,Prolog Programming for Artificial Intelligence (4th Edition) (International Computer Science Series),An excellent book for learning prolog and AI,"Having just read a book on automated reasoning which covered topics in logic, such as unification and resolution, I was very pleased with the prolog programming language, in that it takes concepts from logic, and uses them in ways that can be applied to a number of interesting areas of AI, such as NLP, planning, and expert systems. I thought Bratko succeeded in making this connection with logic, without burdening the reader with notation and concepts that are really not needed for writing or understanding prolog programs.
The book also worked for me on the level of providing a good introduction to the syntax and sematics of the language. The first 200 pages succeed to this end.
Finally, the last 13 chapters can be summarized as representing an introduction to AI from a prolog perspective. On the positive side, he shows how to apply prolog to all of the modern, main streams of AI study. However, on the negative, the slant towards prolog in these chapters tends to oversimplify these disciplines.
My impression of the language is that it seems good as a prototying language, since it is declarative in nature, but from my experimentation (using SWI Prolog) I think I could write better implementations using c or java.
In closing, Bratko's book represents a very good place to start learning prolog and the world of AI.",17
Amazon Customer,3.0 out of 5 stars,Software Requirements 2,Less would be more,"I got a lot of good information out of this book, and I'm glad I bought it. The problem I have with it is the same problem I have with a lot of computer books. IT'S TOO LONG!!! There's way too much text in that book, and wading through it to get to the good stuff was tedious. The author did a good job of completely covering the topic, and he offers a lot of useful information about gathering, documenting and utilizing software requirements. Maybe for the next version, they'll get someone to edit the manuscript for extraneous content.",17
Dr. Lee D. Carlson,4.0 out of 5 stars,Modeling Brain Function: The World of Attractor Neural Networks,Of historical importance,"The study of the physics of the brain from the standpoint of dynamical systems was very popular during the 1980's. The theory of chaotic dynamical systems, and the accompanying concepts of strange attractors, horseshoe maps, and fractal basins of attraction was the subject of intense research at that time. It was inevitable perhaps that these theories would be applied to the understanding of the brain, given the dynamical nature of the neuronal synapse. This book, published in 1989, gives a good overview of what was known at the time. It could be read by anyone with a background in dynamical systems and some elementary knowledge of brain biology. The mathematics is also straightforward in that the author does not bring in any of the heavy tools from differential topology or measure theory, which is normally done in discussions of dynamical systems.

There are some points made in the book that must be understood by the reader because the author feels that they are needed to build a successful model of the brain. For example, he discusses the notion of an `input system', which is a system that, for each input, produces and output with the same ""status."" Cognitive discrimination must be used at the input level, if one is to avoid the use of the `homunculus' (the little external observer), for distinguishing between ""good"" and ""bad"" outputs. The major task in the author's view is to produce ""exceptional"" input-output relations, i.e. relations that correspond to intuitions about cognitive processes. A successful brain model, i.e. one that is able to incorporate memory, should be able to distinguish between stimuli that are familiar from those that are to be submitted to the brain for processing or learning. Thus the model must avoid the use of what the author calls `spontaneous computations', which require an external observer (the homunculus again) to interpret the relation between the input and the output. The author gives an example of a system that performs only spontaneous computations early on in the book. Hence the author proposes the use of artificial neural networks (ANNs) to avoid the occurrence of spontaneous computations. An ANN organizes stimuli in association classes represented by an attractor, and all the stimuli in a particular class are associated with the attractor to which they flow. The author feels that ANNs are more adept at respecting the requirement that for mental computations, which are essentially operations on temporal sequences of data, some record of the initial input sequence must be carried along on a parallel channel, in order to provide the outcome with specific ""meaning"" and a correspondence to the assigned task.

These considerations on the dependence of the processing on the initial input motivate the author to discuss the role of ergodicity in the dynamics of the neural systems of the brain. As the author shows, any generic system subjected to noise will be ergodic, so that eventually the system will access each of its possible states in a manner that is completely independent of the initial state. The author points out two ways in which ergodicity can be avoided: one is to assume that the network is noiseless, and thus only certain moves are allowed from each vertex; the other is to assume that `cooperative phenomena' is present. Since the first possibility is rather exceptional, the author chooses the second, and gives detailed discussion on how cooperative behavior can arise in ANNs. One interesting, and ubiquitous example that he discusses for cooperativity as an emergent property is the Ising model. Mathematically, the breaking of ergodicity involves the taking of the thermodynamic limit, and a necessary condition for emergence is this context is the asymptotic degeneracy of the eigenvalues. To illustrate how this is done, the author uses the solution of a master equation that characterizes the probabilities of making transitions from one state to another in the system.

In order to build a credible model of the neuronal processes of the brain, the author is aware that such a model has to be able to deal with input in the form of temporal sequences, and not just single patterns. He devotes an entire chapter to this in the book, motivating his discussion with the notion of a `central pattern generator' (CPG). The simplicity of CPGs is a concern and the author is aware that such simplicity does not exist in models of cognitive processes. Nevertheless the modeling of CPGs using neural networks can add credence to the program to model general brain processes in terms of neural networks, complex as they can be.

One of course must be able to deal with both the storage and the retrieval of temporal sequences. After discussing some of the early research dealing with these needs, the author then reviews a strategy for dealing with temporal sequences that involves the notion of a `quasi-attractor', which is a network state that acts like an attractor for a short period of time. Quasi-attractors are used to delay the transfer of information out of the attractor. Thus the transitions are governed by synapses that have a time delay. The influence of a pre-synaptic neuron through these synapses will arrive later than the influence coming through a `stabilizing' synapse. The latter type of synapse arises because of the `stabilizing' term in the network model that ensures that if the network is in a state that is identical to a stored pattern then the network will remain there. The author shows how the network can use these delayed transitions to deal with temporal sequences in a manner that is acceptable, i.e. in a way that the `cognition time' is of the order of magnitude of the delay. The author discusses an example dealing with the counting of chimes, in order to give credence to his constructions. In this example it is seen that the network resides in each of the quasi-attractors for a long enough time so as to allow the output neurons to identify the cognitive event.",17
Loves to Knit,3.0 out of 5 stars,Alan Turing: The Enigma,A book for the dedicated math fan,"""The Imitation Game"" was my favorite movie of 2014. I devoured the shows on PBS about cracking Enigma. I was glad to start reading this book. Soon I wasn't so glad. The writer, a mathematician, doesn't have the gift for narrative needed to bring Turing, and the group at Bletchley Park, to life.
The trivia included rather than pruned shows a lack of writing skill. For example, in early chapters about Turing's schooling, one reads nearly every note sent home by a schoolmaster. But a more major event (nailing Turing under floorboards) was glossed over in a sentence without a comment by the author as to impact, or primary source quote concerning the incident.
More troubling is the utter boring chapter on Bletchley Park. How can this chapter be boring? Yet it is. The explanation and sketches of how Turing's machine worked are unsatisfactory. I didn't learn anything from the authors (and I had several advanced math classes in college). I contrast this with biographies of physicists, contemporaries of Turing but written by writers (Richard Rhodes, for example): gripping books that manage to explain quantum theory or the workings of particle accelerators quite well.
Absolutely unsettling is the jarring way the author skips from topic to topic. On one page he note that Turing accepted his sexual orientation; on the next there is talk of suicide. Again, there is no comment by the author. Considering how Turing's life ended, one would expect more explication here. Related to this topic is the story of Turing and Bob Augenfeld, the young refugee Turing sponsored. Turing propositioning the minor Augenfeld would today be classed as sexual predation, yet the author glossed over it, noting that Augenfeld remained friends with Turing. An alternative explanation might be that Augenfeld hoped Turing would help get his mother out of Vienna, and did not seek to sever the relationship for this reason. This was in 1941.
In summary, this book was slow reading, even for someone interested in the man and the topic. I give it 3 stars because of the importance of the topic and the many contribution Turing made to mathematics and computer sciences.",17
Jill Meyer,5.0 out of 5 stars,Alan Turing: The Enigma,"Did he have to ""bite the apple""?","British author Andrew Hodges' biography, ""Alan Turing: The Enigma: The Book That Inspired the Film ""The Imitation Game"" (now that's a mouthful!) is going to appeal to a self-selected readership: history readers and math readers. I doubt anyone else is going to pick up this book and read it for the fun of it. So, I am pitching my review to those historians and mathematicians who will read this book.

Andrew Hodges does an excellent job in telling the story of Alan Turing and his ""times"". Beginning with his early life in England as one of two sons of an India Service official and his wife, his years in ""public school"", and his time at Kings College, Cambridge, Hodges is a very literate biographer. I can judge this part because I know a fair bit of history. What I cannot say with any certainty is if Hodges gets the math part correctly. I am a math-moron and I could sort of follow his writing. If the reader is good in math, he should have no problem in understanding what Alan Turing accomplished in both the World War 2 and after. As the master code breaker at Bletchley Park, Turing broke German cypher codes from their Enigma machine and was instrumental in helping save the North Atlantic allied shipping from German Uboats. He was also considered one of the fathers of computer science, working after the war until his suicide in 1954.

The ""death by poisoned apple"" in my review's title refers to the method of suicide Turing used. Alan Turing was a homosexual in a time when homosexuality was illegal. He pled guilty of ""gross indecency"" in a British court in 1952 and rather than serve time in jail, he chose to take ""hormonal"" treatment to reduce his libido. He found the treatments a life-altering and they, along with losing his government security clearance, may have contributed to his decision to commit suicide.

Alan Turing was treated very shabbily in life and in death, many honors were denied him. He and his contributions to computer science and mathematics began to be recognised in 1966 when the ""Turing Award"" was first awarded by the Association for Computer Machinery. Other honors - both by governmental and collegiate officials - have followed, as well as plays, movies, and biographies of Alan Turing.

Andrew Hodges' biography was originally issued in the 1990's. It is now being reissued as an adjunct to the movie, ""The Imitation Game"", starring Benedict Cumberbatch as Alan Turing and Kiera Knightly as fellow-code breaker, Joan Clarke. In the previews of the movie, Knightly is shown as the ""love interest"" of Cumberbatch. In reality, the two were engaged during their work at Bletchley but broke it off short of marriage. I'm curious to see how the movie handles Turing's homosexuality, but that's for another review. As for this biography, it is very, very well done.",17
Amazon Customer,3.0 out of 5 stars,Alan Turing: The Enigma,I am still mulling over the implications of how ignorance and bigotry caused by outdated social dogma unfairly ruin the lives of,"Difficult read because of technical material and structure that I found awkward to read. But that said, I found it to be very informative, interesting and thought provoking. I am still mulling over the implications of how ignorance and bigotry caused by outdated social dogma unfairly ruin the lives of good, honest and very capable people.",17
Schwallie,2.0 out of 5 stars,Building Machine Learning Systems with Python,Too Many Bugs in Code,"Unfortunately this book is basically a non-starter. I can't seem to get through any of it as the code doesn't work in most cases. I agree with a previous reviewer -- I could spend my time debugging and making it work, but that's not why I bought the book. I shouldn't have to jump through hurdles to read this.

I wish I could get a refund.",17
N/A,1.0 out of 5 stars,Mathematical Statistics with Mathematica (Springer Texts in Statistics),Please check compatibility with Mathematica 5.0,At the present time (Dec 2003) this software is not compatible with Mathematica 5.0 (check the mathstatica website) and the trial verison of Mathematica which comes with the book expires after 30 days.,17
vg,2.0 out of 5 stars,"Superintelligence: Paths, Dangers, Strategies",started well but dragged on,"Started on a clear note but as the chapters progressed the content appeared to be more of a rant than clear points. Had to skip too many paragraphs just to allow myself finish the book.

NOTE: This review and rating is based on ""my"" expectations from the book which was to glean a little insight or a novel approach on the ""paths"".",16
Rudy,5.0 out of 5 stars,Code: The Hidden Language of Computer Hardware and Software,Excellent Book To Understand Computers at the Basic Level,"I am a computer programmer by trade and sincerely wish I had this book 7 years back when I started formal education. During my 4+ years in the higher education system, and even after, I and my classmates (later colleagues) were taught how to program computers (in various languages) and many of the higher level ideas in programming (Data Structures, Algorithms, Program Structure, Etcetera, Etcetera, Etcetera) but we never really learned how the computers worked inside. Even to many trained programmers, or at least me:), these beige boxes can be something of a magical black box which we don't really understand at a fundamental beyond the point of it processing the instructions we give it in our chosen programming language. In school I recieved perhaps one single semester course that attempted to teach how these things worked inside, yet that course still skimmed on the inner workings, the teacher instead spent his time on how monitors drew pixels on the screen and how laser printers worked.....

Looking back on it, I would blame the ignorance of the inner workings of computers that some programmers have on the decline of having to learn Assembly language (starting in the early nineties?), the lowest level programming language sans actual Machine Code, where one would be forced to deal with the raw inner workings of a computer naturally. I myself hope to learn it one day after reading this book :D Instead, I was taught the C programming language and what we learned in school became only more abstract in regards to the actual hardware...

This is where this wonderful book came into play. Since I recieved it half-a-year ago, it must have been read/devoured by me a dozen times or more - it goes from teaching the make-up of various codes (morse, braille, etcetera) to showing how some simple to understand concepts can be combined until a working computer, calculator, etcetera, can be built....... it gives one a great foundation for learning what Computer Science is all about or gives a newer-generation Programmer, like me, much needed knowledge on how that beige box basically works, on a hardware level!

The best thing is that those computer analogies can be finally thrown out the window - we all heard them before - like how ""ram is like a table, or workspace. The bigger it is, the more things you can have ready and available at one time. The hard drive is like your drawers and cabinets. You can store more stuff there, but to use it, you have to take it out first and put it either on the table (RAM) or hold it in your hand (cache)."" Petzold also uses analogies when he introdues topics but quickly moves beyond them, giving his audiences real understanding of the subject - which is very welcoming since analogies tend to explain function well but break down quickly when one is determined to learn more about a topic.

It is probably one of the few computer books on my shelf that can't get outdated and that's good, because it still will be there in 20 years.",16
MA. Kindle Customer,1.0 out of 5 stars,Amazon Echo: Master Your Amazon Echo; User Guide and Manual,A waste of money,"A waste of $3! There is nothing included in this book that is helpful. Also, it is already dated. It does not even mention many of the current features of the Echo. Don't waste your money.",16
Clinton LT Stevenson,1.0 out of 5 stars,Amazon Echo: Master Your Amazon Echo; User Guide and Manual,"Unless, Waste of time and money","I love the echo device, but this book was a waste of money and time. It was absolutely useless. I purchased the device and I really enjoy it, that's why I thought to order a book to give me ideas to use Alexa more. However, it's a huge disappointment, this book lack depths and does not provide any useful or new information that the video provide. I feel like I wasted money with this purchase.
Future buyers, does not need this book.",16
Leonardo Forero,1.0 out of 5 stars,Make Your Own Neural Network,Not Kindle compatible,Is not Kindle compatible. It's basically a PDF,16
Dr. Christian B. Smart,5.0 out of 5 stars,Machine Learning with R - Second Edition,Excellent Introduction to both Machine Learning and R,"If you are new to both machine learning and R and want to learn both at the same time, I can't imagine there being a better book.

I needed to figure out how to implement nearest neighbors, decision trees, SVM, neural networks, and boosting on two data sets, in a short amount of time. I had no experience with R and my only prior experience with machine learning was neural networks. Using this book I was able to implement four algorithms in R. For each topic the book describes an application, the algorithm, provides code to implement the algorithm. You can download the data set from the publisher's website so you can try it out.",16
Mark on Amazon,2.0 out of 5 stars,Machine Learning: The New AI (The MIT Press Essential Knowledge series),No technical usefulness and odd style,"The writing wanders around, the analogies don't quite fit, and it has no technical usefulness. I found it annoying to wade through what seemed like jumbles of ideas lumped together in paragraphs. Simple ideas are drawn out over long stretches of text and the style of writing is just strange in places.",16
Darius Jahandarie,3.0 out of 5 stars,Concrete Mathematics: A Foundation for Computer Science (2nd Edition),Too concrete,"Perhaps I had it coming, but this book really means concrete, as in ""not abstract"", by ""concrete"".

The general format for the chapters is some initial, simple motivation, followed by the introduction of some new tool or transformation, then a couple problems to test out the new tool and flesh out some more details. Often the new tools use the old tools introduced earlier in the book (usually ""via magic"" -- it's often not structurally clear why the old tools are useful in definition of the new tools, they just use them out of nowhere).

Initially things went okay for me, but quickly the book just got incredibly overwhelming because it became difficult to keep track of everything that I had learned thus far, primarily due to the complete lack of abstraction. Maybe others are better at keeping a huge number of concepts in their working memory, but for me, I need some way to organize things, and this book did not provide that at all due to its pedagogically-ordered introduction of the concepts and no appendix or anything on how things fit together from a top-down point of view.

As a concrete example, when generating functions are introduced, they use formal power series, which aren't really introduced. At no point is it really mentioned that these power series that you are working with are not actually functions, but instead just objects which form a ring (there are ways of explaining or hinting out this without actually using the abstract algebra terminology, but none of them were taken). Instead, confusing comments are made regarding divergence, and what looks like illegal operations on functions are applied over and over with no real explanation of what's going on. A tiny bit of abstraction here would have gone a long way, I think.

Overall, I did certainly learn things, but I don't know how many of them I'll be able to remember. Your mileage may vary, but if you are someone who needs a little abstraction to keep things in order, this book can be a frustrating experience.",16
ShoppingGeek,1.0 out of 5 stars,"Speech and Language Processing, 2nd Edition","Not really an ""introduction""...","The dictionary defines ""introduction"" to a subject as ""an elementary treatise"", which this book most definitely is not. These authors never use a simple term where a more esoteric one exists, and if an esoteric one does not exists, they simply make one up.

The book is full of sentences like this: ""To advance the NP rule, the parser unifies the feature structure found under the nominal feature of Dag2 ['directed acyclic graphs'], with the feature structure found under the nominal feature of the NP's Dag1."" If you flip through the book, you see not only one sentence after another like that one, but page after page of complex looking formulae and diagrams. Elementary treatise? For who?

I have been working on a knowledge base for NLP for many years with no formal linguisitic or NLP schooling. I got this book both to see if my practical theories were sound, as well as hoping to find better methods of doing things. Sadly, I got virtually nothing out of this book. As another reviewer said: ""look elsewhere for practical solutions"".

In fact, NLP knowledge base (""KB"") design is not even MENTIONED in the 1000 pages, which is unbelievable when you consider that discussing methods of NLP without specifying a KB design is like planning a menu without knowing what food you have available.

What little they do say, indirectly, on the topic is just wrong, in my experience. For example, the book says: ""the idea of listing [in the KB] every noun and verb [form] can be quite inefficient"" with no explanation of why they consider it inefficient. From a processing speed and reliability viewpoint, it is actually MORE efficient and reliable to include all noun and verb forms (-s, -ed, -ing, etc.) in the KB and have them indexed for fast retrieval than it is to try to analyze each target word which is not in the KB to see if perhaps it is an unlisted noun or verb (or adjective or adverb) form.

Finally, the book has countless grammatical errors, making comprehending already difficult, jargon-filled text even more difficult. It's too bad they don't have an NLP which can catch such errors.

*Edit:
I just finished reading Natural Language Understanding (2nd Edition) by James Allen and it is a MUCH better introduction to NLP.",16
MJ,5.0 out of 5 stars,Programming Collective Intelligence: Building Smart Web 2.0 Applications,One of the BEST book I've read for last 10 years,"I bought lots of books on the field of machine learning, but it was hard to understand when it goes deeper with lots of mathmatics. Even though I understand the concept, I had no idea how to implement it.

After reading this book, all the theories that I've been struggling with became very clear. Toby did a great job to explain these tough topics with proper graphics and easy examples.

This book is one of the best book I've ever read for last 10 years (in several hundreds books).",16
Colourful,5.0 out of 5 stars,Amazon Echo: 2017 Edition - User Guide and Manual - Learn It Live It Love It,How you will get the best service from your Amazon Echo,"According to the Wikipedia, Echo is a voice command device with the ability to answer questions, control other smart devices, play music, and many more smart features. The author aims to get you unleash all the features by sharing technical knowledge as well as tips and strategies related to using the Amazon Echo. If you have an amazon Echo, just get this book and instruct your virtual assistant what you need to do.",16
VA,1.0 out of 5 stars,Foundations of Machine Learning (Adaptive Computation and Machine Learning series),Good as a reference when you already know Machine Learning and want the theory.,"If you are buying this to learn Machine Learning, look elsewhere. This is one of the most dry and unimaginative texts I have ever read. If you already know machine learning, it might make a good mathematical backing.

Very useful as a base for your monitor.",16
Paulo S. R. Diniz,5.0 out of 5 stars,Machine Learning: A Bayesian and Optimization Perspective (Net Developers),It is a great book!,"It is a great book!!! It covers a wide range of subjects related to machine leaning not found in other books. It is well written and includes detailed reference list in each subject matter. The book should be useful for practitioners, graduate students and academics. I am glad I bought it.",16
Demetra S.Gerontakis,5.0 out of 5 stars,"Amazon Echo: Dot:The Ultimate User Guide to Learn Amazon Dot In No Time (Amazon Echo 2016,user manual,web services,by amazon,Free books,Free ... Prime, smart devices, internet) (Volume 5)",A real treasure to have! A truly helping hand ...,"A real treasure to have! A truly helping hand for those Echo users out there. The steps couldn't be made any easier. As Amazon echo has rocketed more and more of us have purchased one or another device, the simple user guide will help even beginners to become expert in Amazon Echo devices!",16
David A. Caswell,1.0 out of 5 stars,Smart Machines: IBM's Watson and the Era of Cognitive Computing (Columbia Business School Publishing),Disappointing and simplistic...,"Very disappointing. This book reads like a primer on 'computers' for non-technical people circa 1985. It is simplistic and filled with speculative use cases of the most cliched kind - they even have a varient of the 'find an italian restaurant' use case in there. My guess is that this essentially intended as a kind of brochure for IBM services aimed at technically illiterate government procurement people. The only good thing I can say about this book is that the term 'cognitive computing' is a brilliant label for this new world of machine learning, big data and sensors/apps that is just beginning - all that stuff is obviously very real but you won't learn much about it here. I really wish Kelly and Hamm had been able to break through the IBM rah-rah and give us some real insight into how IBM is contributing to this new world. </rant>",16
Dr. Christian B. Smart,5.0 out of 5 stars,Machine Learning with R,Excellent Introduction to both Machine Learning and R,"If you are new to both machine learning and R and want to learn both at the same time, I can't imagine there being a better book.

I needed to figure out how to implement nearest neighbors, decision trees, SVM, neural networks, and boosting on two data sets, in a short amount of time. I had no experience with R and my only prior experience with machine learning was neural networks. Using this book I was able to implement four algorithms in R. For each topic the book describes an application, the algorithm, provides code to implement the algorithm. You can download the data set from the publisher's website so you can try it out.",16
Chris Kessel,5.0 out of 5 stars,Software Requirements 2,Great practical advice on requirements,"I'm somewhat of a software engineering/process geek. I find the process of creating a product more interesting than the actual code these days (though I like to code). Wiegers' book is THE bible, in my opinion, for eliciting and maintaining requirements.
He covers the issues involved in gathering requirements and keeping them up to date, often offering multiple ways to resolve issues. Wiegers, unlike many academic oriented books, fully acknowledges the political and cultural difficulties that arise when trying to institute a requirements program. Much of his advice is practical and he gives good pointers on the highst ROI practices, so you can inject a little at a time, rather than trying to change culture wholesale.
I'd give a 4.5 out of 5 if I could, due only to the ""Next Steps"" sections at the end of each chapter. The ""Next Steps"" are supposedly be small steps you can take to start using the advice Wiegers offers. Unfortunately, most of the steps start with ""Take a page/chapter from your current requirements document...."" I've worked at few companies that even have a requirements document, so I'm not sure how useful the ""Next Steps"" really are.
But, that complaint aside, this book is the best combination of reference information for techniques and advice on how to use them on the job.",16
Camber,2.0 out of 5 stars,"Decoding the Universe: How the New Science of Information Is Explaining Everything in the Cosmos, from Our Brains to Black Holes","Muddy Thinking, Fuzzy Writing","Count me with the other reviewers who gave this book 2 stars. I think their criticisms are generally on target, and the book is lacking on pretty much every level.

First of all, the book lacks clarity, with few of the concepts and arguments explained clearly. Part of the problem may be the avoidance of math, as is common in popular science books. However, as I labored to get through the book, my impression grew ever stronger that Seife actually doesn't understand the subject matter well enough himself, so the fuzziness seems to stem mainly from that. It's as though he has learned his science primarily from popular science books, rather than taking the time to learn the material rigorously. This subject evidently needs a serious scientist, not a journalist who happens to be interested in science.

Tied to this, I didn't care for Seife's writing style. As other reviewers noted, his writing has the quality of trying to oversell the ideas, and relies too much on silly metaphors, as though that could somehow substitute for clarity.

The book also largely lacks a necessary philosophical dimension. The concept of energy is quite abstract and underlies all of natural science (energy isn't tangible material ""stuff"" you can hold in your hand, but is rather more like a general capacity to cause change), and Seife doesn't seem to realize this. But then he goes further and asserts that information, which is even more abstract than energy, is ""physical,"" yet he offers no real discussion of how to interpret that claim. Instead, he just forces the information idea on many areas of science (thermodynamics, quantum theory, biology, cosmology, etc.), as though asserting a bunch of relatively vague connections is a substitute for clear definitions and careful scientific reasoning.

Having said all of this, let me note that I actually do think that the thesis regarding the fundamental role of information is plausible, perhaps even probable -- Seife writes as though he came up with the idea, even though it's by no means original to him. The problem is simply that Seife proves unable to properly explore this thesis, and he certainly fails to adequately make the case for it in this book.

With this book having turned out a bust, despite the thesis being plausible, the question is what to try next. I know of two other popular books on this subject, Information: The New Language of Science by Hans Christian von Baeyer and The Bit and the Pendulum: From Quantum Computing to M Theory-The New Physics of Information by Tom Siegfried, but the reviews for these books raise the concern that they might not be much better than Seife's book. Another book, apparently written at a much higher level and published by Springer Verlag, is Information and Its Role in Nature (The Frontiers Collection) by Juan Roederer, and I think that one looks more promising.

But getting back to Seife's book, I'd recommend skipping it entirely. I found it to be an insult to the reader's intelligence, and a waste of the reader's time. My time has already been wasted, but yours doesn't have to be also ...",16
Turtleman,5.0 out of 5 stars,Concise Computer Vision: An Introduction into Theory and Algorithms (Undergraduate Topics in Computer Science),probably the only textbook in the market for intro-level computer vision,"I took a computer vision class using Szeliski's book,
I was NOT satisfied to the book, so I searched around to find another textbook for learning & reference.
There are some other books in computer vision.

Szeliski...........: A literature review, NOT a textbook.
Forsyth & Ponce: A famous mess. Don't buy it.
Prince.............: Great book. geared toward recognition.
Davies............: Great book. geared toward image processing
Shapiro...........: Used to be Excellent intro-level book. Too outdated now.

Finally, I found this book.
This is probably the only textbook available in the market.
The topics are carefully selected, so that the book covers all essential topics in equally balanced manner.
The explanation is very clear in most parts.
Excellent intro-level book for learning & reference.

------------------------------------------
P.S. changed my review on Prince's and Davies' book.",16
Dr. Lee D. Carlson,5.0 out of 5 stars,The Age of Intelligent Machines,An incredible book,"I read this book only recently, having read the author's two most recent books ""The Age of Spiritual Machines"" and his book ""Kurzweil vs The Critics of Strong AI"". Both are excellent books, and reflect the author's extreme optimism about the future of artificial intelligence. He is definitely one of the best apologists for AI, and documents well its living history. Reading this book after the recent ones gives an interesting comparison between what was real in AI then and what is real now. Indeed, the AI landscape has changed dramatically, and there were a few companies specializing in AI in business at the time of publication of this book, that are not around any longer. But for every company that has failed, there have been many more to take their place. Their character as companies has changed, due in part to the rise of the Internet. In fact, it is network engineering that has resulted in many of the applications of AI in the last 5 years, and those applications of course are not mentioned in this book, due to its date of publication.
The author begins the book with a discussion of what he calls ""The Second Industrial Revolution"", which, he claims, is now in progress, and is based on the rise of thinking machines. These machines will extend and leverage human mental abilities, he says, challenging the human uniqueness in this regard. He expresses caution over the idea of making our military defenses controlled by intelligent machines, at the same time expressing his confidence that machine intelligence will indeed be sophisticated enough for this to happen. This revolution is here he says, will be more radical than the first one, but cannot be stopped, and he encourages therefore the constructive use of its technology. Thus is the author's motivation to write this book: to give the reader an overview of what was possible in AI at the time, and encourage the benevolent use of it.
The author not only discusses the technology of AI, but also attempts to give the reader insight into just what AI is. This entails a discussion of philosophy, since philosophical debate dominated AI in its early years. Such debates are still common, but due to the frequent vituperation involved in them (which the author recognizes and mentions in the book), not much is to be gained from these. Time is better spent on actually trying to build thinking machines, and not engaging in conversations that lead nowhere. Since this book appeared, many philosophers have left their ""arm chairs"" and have joined in the practical research in artificial intelligence. This trend will no doubt continue in this century, thus giving rise to the ""industrial philosopher"".
A fairly detailed history of the field of artificial intelligence is given in the book, with several articles written by some of the more recognized individuals in the field. All of these are interesting reading, and shed light on the different attitudes and prejudices regarding AI. For readers who are new to AI, this will be welcomed, as well as the many discussions on the mathematical foundations of AI and its intersection with cognitive science.
The author refrains from including any mathematical notation or equations in the book, and this has its advantages and disadvantages. It allows a more general readership but sacrifices some of the clarity of thought that mathematics allows. The author does give a good discussion of pattern recognition though, especially edge detection. His discussion on this topic is interesting in that it brings up his demarcation between ""logical"" and ""parallel"" thinking. Logical thinking is referred to as ""sequential"" and ""conscious"", with a resulting limitation in computational ability. It is to be distinguished from parallel thinking which can process multiple levels of abstraction, and can occur without conscious direction. Pattern recognition is in his view an example of the latter, and he justifies this view in the book in some detail. More evidence for his view from laboratory experiments is needed however. Pattern recognition algorithms and technologies have exhibited considerable advance since this book was published.
There have been many advances in AI since the time of publication, due in large measure to the rise of the Internet. Most of these advances have been breathtaking, such as in computer chess, games with imperfect information, Bayesian networks, financial engineering, network intelligence, literary creativity, automatic theorem proving, to name just a few. The author discusses his projections for the future of AI in the book, and it is interesting to compare them with what really came about within the decade later. There is no doubt that more exciting developments are on the way, and the optimism expressed by the author in all of his writings is also characteristic of all who are responsible for these developments. The machines, getting more intelligent with every decade that passes in the 21st century, will bear the signature of these individuals: a tell-tale sign and proof of the genius of the human species.",16
Dr. Lee D. Carlson,5.0 out of 5 stars,"Commonsense Reasoning, Second Edition: An Event Calculus Based Approach",A clear overview of the subject,"Occupying the time of many researchers over four decades, the goal of developing a machine that can reason in many different domains is finally reaching fruition. Progress in machine intelligence up until the last few years has been limited to abilities in a single domain, such as chess, checkers, backgammon, medical diagnostics, network management, and so on. Many researchers have held that the only way to eliminate this domain-specificity is to enable commonsense reasoning in machines. Humans of course can think in many domains. A chess master for example can also be a good writer or a good network engineer, and this is the case since any common elements in chess, writing, or network engineering can be recognized and exploited by humans. The integration and automation of commonsense reasoning in machines is challenging, but in this book an approach is outlined that has shown promise. The book of course is targeted to specialists and students in artificial intelligence, but it could also be accessible to cognitive psychologists, linguists, mathematicians, and others who are interested in the subject matter. The book is not only a theoretical discussion, for it discusses and points to practical tools that can be downloaded and used by the reader to illustrate the main issues in the book.

As the author defines it in the first paragraph of the book, commonsense reasoning as a process that takes information about a particular scenario and then makes inferences about other aspects of this scenario based on general knowledge of how the world operates. He discusses the main issues that arise in commonsense reasoning, such as the need for representing commonsense knowledge, the ability to reason about events, some of which may be concurrent or nondeterministic, and how to deal with space. Of particular importance in this discussion is the `commonsense law of inertia', which essentially makes the ""intuitive"" point that things will say the same unless they are affected by an event. However, this law is ""violated"" in many cases, the author discussing a few of these, and so a system for commonsense reasoning must be able to `release' certain `fluents' from this law.

Central to the book is the construction of the `event calculus', which is a system for representing commonsense knowledge and for implementing three types of reasoning abilities, namely `temporal projection', `abduction', and `postdiction.' The fundamental notion of course is the `event', which is an action taking place in the world. Also fundamental is the notion of a `fluent' that represents a property in the world that varies with time. All knowledge is represented declaratively in the event calculus, in order that it can be implemented in the logic programming paradigm, and it is based on a `many-sorted' extension of first-order predicate logic. Also central to the event calculus is the `timepoint' which represents an instant in time. The `discrete event calculus' is a version of the event calculus where the timepoint is restricted to the integers. Both of these systems are axiomatized early on in the book. Of particular interest and very important to commonsense reasoning is the notion of nonmonotonic reasoning and the accompanying notion of circumscription. That commonsense reasoning must be at times nonmonotonic is obvious, since certain premises held at one time may have to be altered when new information presents itself at a later time.

The event calculus is a particular formalization of commonsense reasoning, and for this to work over more than one domain it is necessary to describe formally the notion of a domain. The author calls this a `domain description' and he endeavors to make it as flexible or ""elaboration tolerant"" throughout the book in order that the event calculus is able to handle novel situations as they arise.

The extensive discussions and characterization of the event calculus throughout the book, as well as the examples and extensive references that are given, give the reader a solid understanding of it. Many of the concepts in the event calculus are similar to ones that are found in the other systems of artificial thought. One of these is the `triggering' of events, which is used in discrete event simulation for example, and where an event occurs if a particular condition becomes true. Events whose occurrence depends on something happening are of course very common in the real world, and any effective implementation of commonsense reasoning will have to deal with them. The challenge is to design a system that does not require all the pre-conditions be put in by hand. The axioms for triggering, along with the reasoning patterns that are used by the machine (prediction, abduction, and postdiction), should be sufficient for dealing with events that are contingent on other actions taking place. If they had to be anticipated individually, the number of statements to this effect would proliferate beyond measure, making the commonsense reasoning system extremely brittle and useless. In addition, and the author discusses this in some detail, repeated triggering must be suppressed. This is accomplished by incorporating additional trigger and effect axioms in the system.

The most interesting issue discussed in the book concerns the implementation of the mental states of `agents' in the system of commonsense reasoning. It is in this discussion that the author first introduces the concept of an agent, which he defines as an entity that engages in purposeful actions in the world. An agent can have beliefs, which can be true or false; goals, which the agent wants to be true; and plans, which are a collection of actions that the agent performs in order to reach a goal. The author formalizes these notions he gives examples. But it is when he discusses emotions that things get very complicated, for he introduces 78 axioms that he believes are needed for implementing the Ortony-Clore-Collins emotion theory. He does not discuss whether or not these axioms are independent, and from a simplicity standpoint the implementation would be more believable if the number of axioms were a lot less than the ones that are required in the book.",16
Inquiring Reader,4.0 out of 5 stars,Alan Turing: The Enigma,Too many digressions and diversions at the beginning!,"I am upgrading my review from *** to **** as I plow through the book. The book is quite good, but quite detailed or technical. Not for a general reader.

It is quite good to see the role that Turing played during WW II and how effective he was. He was also very ineffective at times because he was clueless about social clues and unwilling/unable to understand military/war hierarchies. Still a fascinating and detailed, detailed, and more detailed book.

My original review:

Digression after digression, especially at the beginning of the book. Do I really need to know what letters Turing sent to a friend's mother or how she replied? Quite distracting. Too many digressions about historical figures, too. There is too much of that in the first 15% or so of the book.

Once the book gets into Turing's post-graduate work and his work to create computers, that kind detail is very useful -- and relevant.

I ordered this book as a Kindle book, because there were too many complaints about the small font in the print copies. It's easy to read on a Kindle app.",16
Catherine A Young,3.0 out of 5 stars,Alan Turing: The Enigma,"Not an easy read, and a long book","This book is a difficult read. I have a science background, and technology does not slow me down, but I found the writing at some times inscrutable. Not an easy read, and a long book.",16
Amanda S. Mills,4.0 out of 5 stars,Alan Turing: The Enigma,and very fine detail of the time and society in which Alan ...,"I got through ??The Enigma? only recently. When I say I ??got through? I mean it. Being 540 pages of very small print, it was conquered over weeks.

It was worth it.

Turing was a fascinating person with a very rich story which Hodge??s provides in the form of anecdotes from family and colleagues, letters written by Turing, and very fine detail of the time and society in which Alan lived.

Alan??s childhood, in particular tugged at my heart strings, being familiar enough to my own experiences, and traits I see in my eldest son, I felt it easy to put myself in his shoes.

(Alan Turing was not, that we will ever know, autistic. It is important to NOT jump to that conclusion. Yet he was, most certainly, different.)

I found it parts amusing, and parts heart wrenching. I also found myself angry that we didn??t learn about this man in school.

My only criticism of the book is that often times the book departs away from Alan??s story into long tangents about the development of math theories, and highly technical descriptions concerning cryptology (cryptography and cryptoanalysis as well). As a person born the 1970??s, I appreciated the historical explanation of the significance of cryptology to the war, and the attention to the intricacy of Mr. Turing??s projects. YET, I often felt lost, uninterested or confused while reading the long discussions of different theories. I think much of the book was written for people with backgrounds in maths and cryptology, not the average reader.

I hear that the movie ""The Imitation Game"" (screenplay based on this book) has been criticized for not enough explanation or being simplistic. I understand the desire to not bore or hopelessly confuse the audience. The important part is Mr. Turing as a person, which I hope they get right. If early reviews mean anything, it seems they have.

I will hold on to this book, and recommend others read it, skipping past the overly technical parts if need be. You may also need a magnifying glass.",16
D. Dalal,5.0 out of 5 stars,"The MATHEMATICA ?? Book, Version 4",For the generally curious - Mathematica!,"I have been a Mathematica user for many years, back when you could get it for just the MAC, and a big fan of Steven Wolfram.
If you are like me, you're just a bit curious to see what the 4,832th digit for Pi is, using N[Pi,4832]. Or what a Contour graph looks like, right! Well, this book will definately show you how to do it! This latest hardcover book, which includes reference for version 4.1 of Mathematica, is a add-on of the same(only smaller) book on version 3.0 of Mathematica. There are much more examples specific to version 4.x and also the book is a few hundred pages more than the v3 book. If you have the v3.0 book and dont use the v4.x software, there really is no need to get this book, unless you're really curious about what v4.x offers and like to lug around a 6 pound book! The graphics are very vivid, sharp and basically the same ones in v3.0. Due to some of the new graphing features in v4.x, there are samples of these as well. Overall, a great software reference to one of the best software packages ever made!",16
Thomas Wikman,5.0 out of 5 stars,C4.5: Programs for Machine Learning (Morgan Kaufmann Series in Machine Learning),Invaluable for serious users of See5 or C5.0,"Despite its age this classic is invaluable to any serious user of See5 (Windows) or C5.0 (UNIX). C4.5 (See5/C5) is a linear classifier system that is often used for machine learning, or as a data mining tool for discovering patterns in databases. The classifiers can be in the form of either decision trees or rule sets. Just like ID3 it employs a ""divide and conquer"" strategy and uses entropy (information content) to compute its gain ratio (the split criteria).

C5.0 and See5 are built on C4.5, which is open source and free. However, since C5.0 and See5 are commercial products the code and the internals of the See5/C5 algorithms are not public. This is why this book is still so valuable. The first half of the book explains how C4.5 works, and describes its features, for example, partitioning, pruning, and windowing in detail. The book also discusses how C4.5 should be used, and potential problems with over-fit and non-representative data. The second half of the book gives a complete listing of the source code; 8,800 lines of C-code.

C5.0 is faster and more accurate than C4.5 and has features like cross validation, variable misclassification costs, and boost, which are features that C4.5 does not have. However, since minor misuse of See5 could have cost our company tens of millions of dollars it was important that we knew as much as possible about what we were doing, which is why this book was so valuable.

The reasons we did not use, for example, neural networks were:
(1) We had a lot of nominal data (in addition to numeric data)
(2) We had unknown attributes
(3) Our data sets were typically not very large and still we had a lot of attributes
(4) Unlike neural networks, decision trees and rule sets are human readable, possible to comprehend, and can be modified manually if necessary. Since we had problems with non-representative data but understood these problems as well as our system quite well, it was sometimes advantageous for us to modify the decision trees.

If you are in a similar situation I recommend See5/C5 as well as this book.",16
Thomas Wikman,5.0 out of 5 stars,C4.5: Programs for Machine Learning (Morgan Kaufmann Series in Machine Learning),Invaluable for serious users of See5 or C5.0,"Despite its age this classic is invaluable to any serious user of See5 (Windows) or C5.0 (UNIX). C4.5 (See5/C5) is a linear classifier system that is often used for machine learning, or as a data mining tool for discovering patterns in databases. The classifiers can be in the form of either decision trees or rule sets. Just like ID3 it employs a ""divide and conquer"" strategy and uses entropy (information content) to compute its gain ratio (the split criteria).

C5.0 and See5 are built on C4.5, which is open source and free. However, since C5.0 and See5 are commercial products the code and the internals of the See5/C5 algorithms are not public. This is why this book is still so valuable. The first half of the book explains how C4.5 works, and describes its features, for example, partitioning, pruning, and windowing in detail. The book also discusses how C4.5 should be used, and potential problems with over-fit and non-representative data. The second half of the book gives a complete listing of the source code; 8,800 lines of C-code.

C5.0 is faster and more accurate than C4.5 and has features like cross validation, variable misclassification costs, and boost, which are features that C4.5 does not have. However, since minor misuse of See5 could have cost our company tens of millions of dollars it was important that we knew as much as possible about what we were doing, which is why this book was so valuable.

The reasons we did not use, for example, neural networks were:
(1) We had a lot of nominal data (in addition to numeric data)
(2) We had unknown attributes
(3) Our data sets were typically not very large and still we had a lot of attributes
(4) Unlike neural networks, decision trees and rule sets are human readable, possible to comprehend, and can be modified manually if necessary. Since we had problems with non-representative data but understood these problems as well as our system quite well, it was sometimes advantageous for us to modify the decision trees.

If you are in a similar situation I recommend See5/C5 as well as this book.",16
Pedro A. Ortega,4.0 out of 5 stars,Universal Artificial Intelligence: Sequential Decisions Based On Algorithmic Probability,A gem under a pile of unnecessary mathematical obfuscation,"This is probably the most rigorous attempt to formalize AI. The book succeeds in presenting the state-of-the-art AI theory from a technical point of view, but neglects intuition, and is difficult to read for the novice and thus inaccessible to a wider audience.

The main idea of the book in combining classical control theory concepts with Bayesian inference and algorithmic information theory. The author avoids to struggle with anthropocentric aspects of intelligence (which are subject to a fierce debate) by defining intelligent agents as utility maximizing-systems. The core ideas are, in a nutshell (informally):

1) Goal: Build a system with an I/O stream interfaced with an environment, where inputs are observations and outputs are actions, that optimizes some cumulative reward function over the observations. Two ingredients are necessary: model the a priori unknown environment and solve for the reward-maximizing actions.

2) Model: This is a probability distribution over future observations conditioned on the past (actions and observations). Instead of using any particular domain-specific model, the author uses a weighted mixture over ""all"" models. By ""all models"", the set of all mechanically calculable models is meant, i.e. the set of all algorithmically approximable probabilistic models.

3) Policy: Given the model, all possible futures can be simulated (up to a predefined horizon) by trying out all possible interaction paths. Essentially, a huge decision tree is constructed. Having this information, it is ""easy"" to solve for the best policy. Just pick at each step the action that promises the highest expected future rewards. These are calculated recursively using Bellman's optimality equations.

Why does this work in theory? If the environment is equal to one of the models in the mixture (or ""close enough""), then the mixture model converges to the true environment. The model is updated step by step using Bayes' rule. Since the model becomes more accurate, the policy based on it converges to the optimum. Algorithmic information theory is the main tool to derive the mathematical results.

Does it work in practice? Unfortunately, the presented solution cannot be implemented in practice, because the mixture model is incomputable. Even worse, there is currently no principled way to downscale his approach (and make it practical), since we don't know how to simplify (a) the mixture model and (b) the computation of the policy. The author makes these points very clear in his book. IMHO these are the main challenges for future AI research.

The PROs: This is the first time I see a unified, formal and mathematically sound presentation of artificial intelligence. The proposed theoretical solution provides invaluable insight about the nature of learning and acting - hidden even in very subtle details in his approach and in his equations. Whereas you might feel that classical AI or commonplace Machine Learning theory looks like a patchwork of interesting concepts and methods, here (almost) everything fits nicely together into a coherent and elegant solution. Once you have studied and understood this book (which took years in my case), it is very difficult to go back to the traditional approaches of AI.

The CONTRAs: However, there are some downsides to this book. Hutter is a brilliant mathematician and sharp thinker. Unfortunately his writing style is very formal and many times he neglects intuition. The book introduces difficult notation (although some of it pays off in the long run) that ends up obfuscating simple ideas. The mathematical style of the book is difficult to digest.

To summarize, this books represents a giant leap in the theory of AI. If you have advanced mathematical training and enough patience to study it, then this book is for you. For the more practically-oriented researcher who wants to learn about Universal AI, I recommend reading Shane Legg's ""Machine Super Intelligence"".",16
Stephen E. Robbins,2.0 out of 5 stars,"Superintelligence: Paths, Dangers, Strategies",Super Unmotivated,"For all its detail on various issues and lengthy thought-explorations on possible scenarios re the future with super intelligent AIs, this work is a heavy structure floating upon a puff of air. For a reader with some knowledge of the many subjects the book is implicitly dealing with but failing to engage, there is a crucial failure to motivate its extensive considerations - this makes it very hard to read with any interest past a certain point.

Bostrom initially lays out the many accomplishments of AI. There is the games dimension - chess, checkers, jeopardy and many more - for which an AI is now the champion player - though in all these, he notes, the achievement is via very specific algorithms good only for that game, i.e., with little application to a general intelligence. He notes AI's main paths or approaches to intelligence, their strengths, weaknesses and tradeoffs: 1) The neural network/connectionist approach, 2) the evolutionary algorithms, 3) and the symbolic manipulation approach (GOFAI) which chronologically preceded, and yielded things like theorem provers, problem solving programs like GPS, ""conversation"" programs like ELIZA, expert systems, etc. He leaves implicit that these three paths lead to a giant black hole from which no exit is seen, for as he notes, standing in the distance on the other side are two huge, untaken hills: common sense knowledge and true language comprehension. These, he notes, are utterly essential to human equivalent intelligence, but AI has no current strategy to take these hills as Bostrom again leaves implicit, nor is there any current indication the three main paths will yield one, in fact there is the opposite indication. Elsewhere, Hofstadter (Surfaces and Essences: Analogy as the Fuel and Fire of Thinking), in his extensive tome showing that analogy is foundational to thought and language, and while eviscerating current AI language achievements, is obviously doubtful that computers (as currently conceived) can deal with this (analogy, thus language) at all.

But after taking us to the edge of this black hole, Bostrom turns 90 degrees, ignoring the two hills, and now discusses very general methods by which AI will achieve human equivalence. In this, it is safe to say, his hopes primarily fall on whole brain emulation (WBE). But his description of this approach, while seemingly detailed, fails utterly to describe its true difficulties; WBE is an untaken Everest. I suggest the recent, The Future of the Brain: Essays by the World's Leading Neuroscientists and perhaps view my (5 star) review thereof. The authors, Marcus and Freeman, are neuroscience guys discussing the massive difficulties which the huge projects embarking on brain mapping actually face, for example: We face a 85 billion neuron brain with roughly 1000 types of neurons, the functions of none of which we understand. We do not know basic facts such as how memory (our experience) is stored. We are quite certain that the brain is NOT using what we understand currently as ""computation,"" but we do not know what this other form is (Marcus ridicules current connectionism). We face data from neural recordings that will be so massive, it will be in zeta-bytes, yet any interpretation will be completely dependent on a guiding theory - note, a theory - when we have none such. It will be, they say, like trying to learn what a laptop is and does by taking electrical recordings, when we have no theory of, or knowledge of, the existence of something called ""software.""

This is to say, we really have no clue what type of ""device"" the brain actually is. This is exacerbated by the fact that the reason we have no understanding of how experience is stored in the brain (or if), is that we have no theory of what experience is, i.e., we cannot explain the origin of the image of the external world - the coffee cup, in front of us, on the table. This problem of the origin of the image is the more precise statement of Chalmers' famous ""hard problem"" of consciousness - a word (consciousness), so far as I can discern, never seen once in Bostrom's book. The whole book proceeds as though this is an unimportant problem. Yet this very subject forms part of that missing notion of ""software."" Just to give a quick idea of how important this could be in terms of the ""device"" the brain actually is and for the origin of the image of the external world, Bergson (Matter and Memory, 1896), presciently anticipating the essence of holography in 1896, viewed the brain as creating a reconstructive wave passing through the external, universal holographic field, where this ""wave"" is now specific to, or specifying, a portion of the vast information in the field, now by this process, an image - the coffee cup on the table. This requires achieving a very concrete dynamics, it would make the brain a very different form of ""device"" and perception, memory and cognition employing a far different form of ""computation,"" and it begs the question of whether such a device - being simultaneously a very concrete wave - can be embodied in silicon, wire and transistors (or even ""memristors"") at all, but rather, to support such a reconstructive wave, all this biological stuff comprising the brain, with its quantum dynamics rampant, is absolutely required. In other words, it is not a question of speculating, as Bostrom does further on, whether we will achieve human equivalence in 2075, or 2100 or 3100, it is a question of what the ultimate ""device"" we ultimately create (brain/body - AI version) will look like, an answer that will completely determine whether controlling such a device, or imparting values, or significantly increasing its intelligence, is going to be any problem or reality at all. But this can only be glimpsed by engaging with and gaining answers - unto a comprehensive theory - within a number of subjects: perception, ecological psychology, memory, explicit memory (conscious knowing an event is in one's past), cognitive development, the origin and nature of consciousness, the role of consciousness in cognition, and more - but all here ignored completely.

But the book sails serenely on from this subject of brain emulation, confident without a qualm that we will have created the brain as a silicon and wires device - it seems, confusedly, a neural net-like device that still (somehow) uses software - and now beginning long considerations on approaches by which, since it is certain that we will have electronics, we can speed up the transmission velocities, etc., say by 10,000x (and as well, modify what may well be its non-existent ""software"") thus allowing the device to quickly develop, creating and moving to a super intelligence and thus inducing the ensuing problems the rest of the book deals with. At this juncture, though I read the rest (a couple hundred pages), I lost interest; the book has utterly failed to motivate the reality, the nature, or the essence - near or far future - of anything it is discussing from this point.

Consider, finally, in this ""un-motivated"" context, the ""values-loading problem,"" coined as a term I believe by Bostrom and treated at some length, wherein we must load human values into our super intelligence to prevent it from destroying the human race. How would the super AI know NOT to get my mother out of a burning building by simply throwing her out of the tenth floor? More simply how would the super intelligence know not to stir the coffee with a Toyota or a chair? In reality, this is simply a version of the ""frame problem,"" a problem discussed heavily by AI for 30 years, then ""faded."" It sits on top of one of those hills, for it is actually the old problem of commonsense knowledge. How does the robot, stirring his cup of coffee, recognize that giant bubbles and geysers arising from the liquid, or that a feeling like stirring molasses, are anomalous - features not ""expected"" in this event? In the ""frame"" formulation, the robot has to check (constantly, with great computational expense) his list of frame axioms, axioms which specify what should be unchanged in the world as he stirs. In reality, we recognize such an anomaly because it violates one of many invariance laws structuring the event: a radial flow field defining the coffee's swirl, an adiabatic invariance (a ratio of energy of oscillation to frequency of oscillation) carried over the periodic motion of the spoon and carried over haptic flows in the hand-arm, an inertial tensor defining the angular resistance as we wield the spoon, and much more. None of this - the concrete structure, forces and dynamics of this experience - can be handled by current AI, nor are the findings of the relevant science - ecological psychology - even considered. It is on the basis of this knowledge that we recognize the ""value"" of a spoon, or of the flat of a knife, or even of an orange peel, to create the forces required for stirring coffee. This structured experience with its laws is the basis for even higher order, yes, analogy-based value statements, ""Its not nice to stir up people."" But it is worse, for values impartation, while based in this very concrete knowledge and its invariance laws, is actually embedded over our cognitive development, in our interaction with the concrete world and its beings, and this development, it is now being understood, is itself a dynamic trajectory through which our brain is travelling as a self-organizing dynamic system.

This trajectory, in Piaget's model, unfolds over two years, enabling the child to achieve the basic concepts of causality, object, space and time, the capability of explicit memory (conscious localization of past events in time), and even the ability to symbolize - yes, even the ability to symbolize - the events of the world. It requires to the age of seven to achieve concrete operations which include further grasp of space, time and number, and to the age of 12 for formal operations which include forms of logic and thought we take for granted. In other words, the brain is not only an organized structure, but a structure changing its organization along a complex trajectory purposed to achieve these conceptual and logical capabilities. Not only then must we understand the structure of these billions of neurons and their 1000 types, but also the dynamic principles embedded deep within (via DNA?) by which the structure organizes towards the ""intelligence"" we are familiar with. It again goes without saying that we have no clue whether the actual biological organization of the brain, and the natural course of its interaction with the concrete world at our normal scale of time (also specified by this dynamics) and the reorganizations involved, can be achieved in any other way than by the concrete method nature designed. (Spare me the minor evolutionary mistakes nature has supposedly made.) Further, for all the ""operations"" above, it can be shown that consciousness is required. None of these subject areas make it anywhere into Bostrom. We are asked to worry about values-imparting and the supposed dangers of a silicon-based super intelligence entirely predicated upon an ignoring of all these issues and more, all of which beg or even scream questions not only on what intelligence actually is, but whether any of these proposed concerns have the slightest reality. It is just a bit difficult for me then to attend to a large structure of concerns which float in reality upon a puff of very inadequate analysis.",15
Looking For Good Science Fiction,1.0 out of 5 stars,"Superintelligence: Paths, Dangers, Strategies",I had high expectations for this book and am very disappointed with my experience in trying to get through it,"I tried to finish this book but couldn't. I got about half way through before I threw in the towel. Maybe the topic is just over my head in complexity, but I thought this book was going to be about approaches to building superintelligent machines and the benefit these machines would be to humanity. Instead the author spends an inordinate amount of space on the sociology of what would happen to humans if a superintelligent machine were invented. The text in the paragraphs are very difficult to follow so much so that I found myself thinking more than once ""What the heck is the author's point"". I had high expectations for this book and am very disappointed with my experience in trying to get through it. It is very intelligent (super or otherwise) not to waste your money on this book.",15
M. D. HEALY,4.0 out of 5 stars,"The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Second Edition (Springer Series in Statistics)",Excellent but assumes considerable background,"This should certainly not be the first statistics book you read, or even the second or third book, but when you are ready for it then you should absolutely read it. But be prepared to read it very slowly and digest each page. Its greatest strength is that it shows how much of modern statistics comes down to a few fundamental issues: bias, variance, model complexity, and the curse of dimensionality. There is no free lunch in statistics, methods that claim to avoid these tradeoffs only do so by adding more assumptions about the structure of your data. If your data match the assumptions of such methods, you gain statistical power, but if your data don't match the assumptions then you lose.

By looking closely at the assumptions, the book shows how many contemporary methods that look different are fundamentally similar under the hood.

And in my own work I have adopted their use of open circles for the points in scatterplots. These circles are easier to see than tiny solid dots, but overlapping symbols don't cover each other the way large filled symbols do.",15
Dr. Houston H. Stokes,4.0 out of 5 stars,An Introduction to Statistical Learning: with Applications in R (Springer Texts in Statistics),Review of strengths and weakness in this important book.,Clear book. Problem is no bibliography of research in the book. Book must be read with Friedman Hastie and Tibshirani for a list of the key book and papers to help a Reader.,15
Vance Christiaanse,3.0 out of 5 stars,Design Patterns: Elements of Reusable Object-Oriented Software,Studying Design Patterns vs. Improving Software Development,"It's hard to imagine how a software developer in 2005 could function without ready access to this 1995 classic. Without this book how could anyone
* Explain why the Factory Method pattern (page 107) is a special case of the Template Method (page 325) or why it isn't.
* Prove that Java's DriverManager.getConnection(...) method illustrates the Abstract Factory Method design pattern (page 87) rather than the Factory design pattern.
* Think of any practical example of the Visitor pattern (page 331).
* Agree on whether or not a given piece of software actually illustrates a specific one of the 23 patterns identified in this book.

Like the Guinness Book of World Records settles arguments between drinkers this book is the final authoritative arbiter when software developers argue about design patterns. This book is also useful for learning how to use design patterns to design and write better code.

It is a testament to the importance of this book that in the ten years since it was published the design patterns community has not really agreed on any additional patterns beyond the 23 defined here--although many more have certainly been proposed. Even more significantly, few have had the courage to suggest that some of the 23 patterns defined here might be of little practical value. Most design pattern book authors since treat these exact same patterns. I suspect their publishers insist on it because that's what the buying public seems to want. As a result it is certainly fair to say that once you buy this book you don't really need to buy any more books on the subject.

In fact, one might argue that this book is one of the few design patterns book you can buy that is 100% focused on helping developers write better code. Other books that dare to introduce valuable new ideas on design patterns typically include an explicit acknowledgement that the ideas that can't be traced back to the Gang of Four. Any time spent defining yourself in terms of the Gang of Four is time that is not being spent advancing the field itself or helping developers.

Another indication of the importance of this book is that fact that other design pattern authors often quote it directly, particularly the short definitions of the design patterns. This might suggest that other authors find it difficult to understand some of the 23 patterns well enough to be able to clearly and confidently explain them in their own words. Whatever the actual reason, it certainly indicates that if you want to buy a book on design patterns, this is the book to buy.

I wish the authors of this book would publish an official statement giving their disciples explicit permission to move forward with design patterns, improving and adapting them, adding new ones and letting those that haven't stood the test of time gracefully fade away. As it is, the study of design patterns is in danger of becoming a study of this book rather than a study of how to actually write better code using patterns.

I'll close with a significant and apparently overlooked line from the preface of this book:

""We don't consider this collection of design patterns complete and static; it's more a recording of our current thoughts on design.""",15
Roger,1.0 out of 5 stars,Design Patterns: Elements of Reusable Object-Oriented Software,The best computer book on your shelf you will never read,"In 1993 this book was groundbreaking. Patterns in C++? Java was just an idea at that point. By now there are many, easier to read and apply, books on Design Patterns. Often they can be language or domain specific. Enterprise Patterns, Ruby Patterns, etc.

If you have a tech bookshelf at work this book has to be on it, but you will never need to open it.",15
Erik Meijer,1.0 out of 5 stars,Machine Learning: A Probabilistic Perspective (Adaptive Computation and Machine Learning series),"Just a PDF, unreadable on kindle/iPad","So I paid how many dollars for a PDF document that is not flowing and resizing on the kindle reader on the iPad.
Come on, that sucks. I feel cheated. Specially given there is hardly any difference with the paper version.",15
AU_NLPer,3.0 out of 5 stars,Machine Learning: A Probabilistic Perspective (Adaptive Computation and Machine Learning series),Partial review about some details,"After I read this thread [...], I decide to buy this MLAPP. I am not working closely on machine learning, but I use machine learning techniques frequently in my research. The review is partial, because I only carefully read some independent parts.

When decide to buy this book. I care about and expect to obtain information on 1) the appropriateness of when I choose a machine learning method for a task; 2) the big picture of whole machine learning techniques; 3) the intuition of important techniques explained without jargons, and 4) how are these techniques connected;
Additionally, as an English as a second language (ESL) user, I expect the text is well organised and is written without ambiguity.

From my partial reading (mainly section 16.6 and some random stuff), I would say the book indeed covers many popular techniques (topic models, deep learnings). The author also did a very good job in describing terminologies and giving succinct descriptions about the key part and the application of each method. These are the two features I like most.

However, the downsides are 1) it is too abstract for some method descriptions that I need to leverage external materials (e.g. the original paper) to understand the method. Even though the description in the book covers the most important part, it is not sufficient and I would like to see more details. One example is in equation 16.105, why P_b(X) is not explained?
2) The text is like an oral presentation in a very long tutorial intended to cover an index of techniques. Overall, its readability (text in Section 16.6) dispoints me. I know English is not my native language. But I would still argue for this issue. Previous I read some chapters in Bishop's PRML and the lecture notes of machine learning in coursera, they do better jobs.",15
Stefan Popov,3.0 out of 5 stars,The Singularity Is Near: When Humans Transcend Biology,Faith in Technology,"Ray Kurzweil has done a lot of good work. But being right on some things does not mean he is right about everything.

With his last couple of doublings on the exponential curve of human progress, he reaches deep into faith more so than science. There are some major biases and contradictions in his theories, along with getting one of his main premises completely wrong.

He thinks we can create AI when the computing power of a machine reaches the 125 trillion synapses you have in your average brain. From that point on, we never look back and rule the universe as human-machine hybrid gods.

There a couple of really big problems with that assumption.

One, he assumed each synapse in our brains is a logical switch, which at the time he wrote the book was considered a known fact. Fair mistake. But the very progress of technology proved him wrong. The latest in neuroscience has shown that the brain is vastly more complicated than that and each synapse is much closer to a very sophisticated micro-processor with thousands of gates than to a simple logical switch. So, to put that in perspective--a single developed human brain has 125 trillion (or thereabouts) processors working seamlessly in parallel, taking input from 200 billion nerve cells, with extremely low energy requirements and low heat output.

For comparison, the entire human race currently operates several billion micro-processors. I have no doubt that number will increase several-fold in the next couple of decades. The second most powerful supercomputer in the world, the Cray Titan, has 37 thousand. The next generation will have less nodes, albeit faster ones. Yes, they will get smaller, faster, more efficient. However, to think that we'll replicate in machine form the true networked complexity of the human brain in the next 10 or 20 years is just nuts, given that it takes 3-5 years to actually build the next generation of supercomputers and even more years before people actually figure out what to do with them. So, on the ??hardware?? requirements for AI, under his original assumption, I think he was completely off and by orders of magnitude.

The even bigger issue is on the software side??his premise is that we only need to simulate the output of a super-complex system like the brain, not necessarily know how exactly the black box works. Hence, once we understand how the human brain works, we don??t need to rebuild it in machine form, we only need to build something which given the same inputs provides the same output. Then you??ll have true AI because we??ll have a machine that can self-learn, write unconstrained code, etc.

The problem here is that he has a very fundamental chicken and egg problem. The issue is that AI and digitalizing the brain is the very cornerstone of everything else in his writing??including nanobots (which even he admits will have their software written by a higher form of intelligence, not human) which truly kicks off the next stages of human-machine evolution. Right now we cannot even map what the brain really does on a molecular level, let alone accurately replicate it.

Furthermore, I know some very bright people who code for a living and even the best and brightest struggle with limited parallel programming and it gets exponentially more difficult with each level of parallelism you introduce. I am yet to meet a coder, no matter how self-confident, who will, with a straight face, claim that they can write software that can replicate or even approximate 125 trillion processors working in parallel. Kurzweil says that an AI unconstrained by physics or biology can write such code. So, while Kurzweil assumes that with increased computing power we??ll just figure such a true AI out, I??m not so sure it is that simple.

So, how do we get AI to begin with, if it truly takes a higher order of intelligence to write such an AI?

Overall, just like many futurists, there are hits and misses. I believe that when it comes to machines becoming pervasively widespread in everything we do, he is right on and has been for two decades. The next part, where humans become machine gods borders on religious (technology being the god here) fanaticism more so than on sound science.

Anyhow, time will tell, but I think he is at the very least off (if not completely wrong) on his timing??and by a lot.",15
Arthur P. Smith,4.0 out of 5 stars,The Singularity Is Near: When Humans Transcend Biology,Is this Reality? And is it good for us?,"Among technological optimists in the world, the ""singularitarians"", led by Ray Kurzweil, are perhaps the most extravagant, extrapolating from the growth in information technologies of the past century. This book provides a good review of the ideas behind this optimism, and its likely consequences over the next century or so. It also raises and partly addresses a few central questions: do these extrapolations faithfully represent reality? Do they really extend beyond information technology to our control of the material world around us? And how can Kurzweil be so sure the predicted doubly exponential progress will be good for us?

Kurzweil's fundamental basis for optimism is his ""Law of Accelerating Returns"" for information technology, which claims that the components of our information systems naturally grow in capability at an exponential rate, and that as each reaches limits, it is superceded by new technology with ever-faster exponential growth rates. Not only is the growth exponential, but the rate of growth is itself growing exponentially. Kurzweil even justifies this ""law"" with a mathematical appendix that suggests the exponent should grow roughly at the same rate as world GDP; he does not mention that the actual rate he finds is a little under half that (1.2% vs 2.8% annually for the 20th century). As I argue elsewhere, if one discounts the putative computation rates per thousand dollars of the early years of the twentieth century (before 1920), the numbers seem to just as easily fit a non-growing exponential rate (0% instead of 1.2%), so it seems hard to saw Kurzweil's ""law"" is at all proven. The next decade or so will be the real test, as integrated circuits are replaced by whatever the next technological leap coming along is.

The idea that this acceleration applies beyond information technologies has also been criticized by people like physicist Jonathan Huebner, who argues that we are, far from entering an era of exponentially greater growth in capabilities, actually approaching a new dark age. Huebner claims the rate of technological innovation per person per year reached a peak a century ago, and the decline now, despite high R&D and education funding, is because developing new technology beyond what's already been done has become more and more difficult. Kurzweil has his own list of innovations to refute this, but he does not manage to make a convincing case that his ""law of accelerating returns"" is in any way a necessary consequence of the way the world works. In comparing linear and exponential behavior in the first chapter, Kurzweil notes that ""people tend to overestimate what can be achieved in the short term (because we leave out necessary details)"". There are many details Kurzweil has necessarily skipped over, but no indication that he thinks he might himself be overestimating.

So we may have accelerating returns, continued exponential growth, or much slower growth or even decline, depending on your view of the world. At least with either of the growing curves, Kurzweil's other projections still apply, but under plain exponential growth would be simply delayed a bit. Kurzweil estimates a ""human-level"" computer would require between 10^16 and 10^19 cycles per second. With accelerating returns, that computer would be under $1000 at some point between 2020 and 2030. If the growth continues only on a simple exponential, we have to wait until after 2050 for human-scale personal computing. Kurzweil fully intends to be alive when his brain can be scanned and uploaded to a simulation of immortality, a motive that perhaps overly encourages him to argue for the earlier date.

Kurzweil sets 2045 as the date for the Singularity itself, the point when all this computer power really transforms our capabilities. If the plain exponential law is true instead, the date for comparable computational capabilities is pushed back to the first decade of the 22nd century. Continued doubly exponential growth in computational power would reach the ultimate computational capacity of our solar system, between 10^70 and 10^80 calculations per second, before 2120, within the natural life-span of some alive today. Growth along the ordinary exponential would not reach such astronomical scales until the 25th century. Depending on whether such vastly enhanced intelligence can find a way around the speed-of-light restriction or not, Kurzweil sees a universe filled with computation possible less than 200 years from today.

This vast growth in computational power is the central element on which much of the remaining speculation of the book rests; it's an awe-inspiring story, and even if slower growth pushes back some of the these dates a century or three, it is still worth understanding where augmenting human intelligence with machines may take us. Kurzweil's arguments for the development of real artificial intelligence in the relatively near future, given computational capabilities, seem sound enough. His commentary on the issue of subjectivity (if I get uploaded, which one is ""me""?) is one of the most lucid I have ever seen. But he wastes far too much time on Searle's Chinese Room argument against AI; just a simple statement that the scale of complexity invalidates the comparison should have been enough.

Kurzweil identifes three related revolutions underway: in genetics, nanotechnology, and robotics (strong AI). These enable the information technology revolution to be extended to the living, material and mental worlds; many wonders are to be expected. In particular, his outline for ""brain uploading"" depends on nanomachines capable of penetrating the brain and recording patterns there, a rather invasive (but believable) approach.

At times, Kurzweil's book veers into millenial apocalypsism, at one point describing ""Singularitarianism"" as an almost religious belief in the ability to be uploaded and live forever, and listing several articles of faith. Kurzweil acknowledges the religious element but asserts that this is different: traditional religion is primarily a rationalization of death, while the Singularity makes death a thing of the past. How will existing religions respond to such notions?

One very serious question is the possibility of threats from these new technologies - every individual will have vast power, beyond anything even nations have today. There is the ""gray goo"" threat from nanotechnology, as Bill Joy has articulated. Kurzweil acknowledges, yes there are dangers, in fact he agrees with Joy in many respects. Unfortunately we will have to keep several steps ahead, with ""immune systems"" deployed against the threats, before they wreak havoc. The most worrisome threat is from Strong AI itself - once they supercede human intelligence, what will prevent them from overcoming any bounds we may have set against harming us? Kurzweil's main response to this threat is that ""they"" will be ""us"", uploaded and greatly enhanced, so it doesn't much matter what happens to the old biological world. This is, to say the least, a little unsettling...

In addition to the copious graphical illustrations, Kurzweil adds to the text some imaginary conversations with historical, present, and future persons, including Eric Drexler, Bill Gates, Darwin, and Freud. He seems to have obtained permission from the living for this; sometimes these conversations enlighten, but they seem oddly contrived.

Kurzweil does have a fascinating view of our potential future. Whether near or far, this book is a useful guide to how the world will change at that point where humans transcend biology.",15
Allen B. Hundley,4.0 out of 5 stars,The Singularity Is Near: When Humans Transcend Biology,"Which Will Come First, the Singularity or the Discontinuity","Ray Kurzweil is without question one of the greatest technologists of our era and his ideas should command respect. That does not necessarily mean that all of them are correct.

Kurzweil's latest book is a brilliant exposition of one possible future for the human species. As an intellectual adventure it is in the same league with Brian Green's books on string theory and Steven Wolfram's ""A New Kind of Science"". If you enjoy reading Scientific American you can handle Kurzweil. If Discovery magazine is closer to your speed, a more accessible book is ""Radical Evolution"" by Joel Garreau.

People who read books like these basically fall into two groups, those primarily interested in current trends in science and those primarily interested in the future of humanity. Kurzweil attempts to explain both the explosive development of genetics, robotics, and nanotechnology (GRN) and the profound implications these have for the future of our species. The book is worth buying just for its stunning exposition of current trends in GRN.(Actually Garreau's GRIN, for Genetics, Robotics, Information, and Nanotechnology, is a more accurate and therefore better acronym).

Unfortunately, but perhaps not surprisingly, Kurzweil does not adequately take into account events external to the world of technology that could and probably will completely derail his predictions about both GRN and humanity's future. In that sense Kurzweil falls victim to the very same `linear thinking' that he decries in others who forecast the future.

The term `singularity' as used by Kurzweil means the transformation of Homo Sapiens from a slowly evolving biological species to a race of super intelligent beings no longer constrained by the limitations of biology. This transformation will be the result of the confluence of genetics, nanotechnology, and robotics and will occur sometime around 2045.

Descendants of Homo Sapiens live forever because the aging process has been halted. All of the world's economic and social problems disappear because all the baggage of biological evolution (species competition for limited resources, sex, aggression, territorial defense, etc.) vanishes. There is little need to work because intelligent machines do it all, even repairing and replacing themselves when they fail or wear out. The new super beings spend most of their time exploring ever deeper mysteries of the universe.

Kurzweil backs up his extraordinary claims with a wealth of convincing data, in itself a significant contribution, but more important and the reason this book is worth reading, is his exposition of how this confluence could take place. Kurzweil believes firmly it will take place and this is where his linear thinking intrudes.

By linear thinking I mean the idea that tomorrow's technological advancement will follow along the same smoothly upward flowing line that it followed today and yesterday and the day before. If the progress Kurzweil projects for the next four decades were to be compressed into the next five or at most ten years then his forecast could very well turn out to be correct. But in this reviewer's opinion far more powerful and immediate societal forces are at work that will result in a major discontinuity, either natural or manmade.

By discontinuity I mean a collapse of the world economy most likely brought about by terrorist related political and military strife followed by widespread anarchy, certainly lasting many decades and possibly much longer. The GRN technologies are not for backyard inventors working in their garages. They are extremely complex, requiring vast financial, physical, organizational, and intellectual resources. Kurzweil's path to the future depends on a smoothly flowing, surprise free world for the next forty years. Can any thoughtful person reading a newspaper today possibly believe this?

Let N equal the number of Muslims in the world today, roughly one billion. Let N divided by 1,000 (i.e., one tenth of one percent) equal the number of fundamentalist Muslims committed to die for Allah to destroy western civilization. Do the math and that works out to 1,000,000 suicide bombers coming at us daily for the next forty years. Nineteen high school graduates crashed some planes into a couple of buildings in New York and one in Washington, killed three thousand people, and caused a Trillion dollars in damage to the American economy.

Someday the attack will biological or nuclear. It will kill 30,000 or 300,000 or even 3,000,000. No one will know for sure if another is not soon to follow, and another. Uncontrollable mass panic will reign. This civilization risks collapse not because of the buildings destroyed or the numbers killed but because of its extreme fragility due to excessive system interdependence. The collapse could possibly be avoided but the changes required would be profound. It would require too radical a paradigm shift for global elites who cling to the system as it is now.

Kurzweil himself acknowledges that terrorism is the most likely scenario that would prevent the Singularity yet he admits that he has no solution for it. I would recommend that he read ""The Collapse of Complex Societies"" by Joseph Tainter, ""Collapse: How Societies Choose to Fail or Succeed"" by Jared Diamond, and ""The Long Emergency"" by James Howard Kunstler. While these also have some problems in their arguments they point us in the right direction. It would be interesting to see how one of the world's truly great visionaries incorporates the ideas contained in those books into a revised edition of ""The Singularity"".

Civilizations rise and fall. There is no reason to believe that ours is somehow immune to this cycle. One may completely reject the apocalyptic beliefs of fundamentalist Christians, the earth changes of New Agers, and the psychic prognostications of the supermarket tabloids, and still recognize the warning signs that the current civilization cycle may well be nearing an end.

This should not be a cause for despair but rather for hope. At some point a new cycle will begin. Kurzweil's singularity is a cautionary vision of where that next cycle may take us.

We do not know with certainty but the evidence is mounting that probably there are many intelligent species in the universe. Some of them must have progressed beyond our level of development with all its dangers. All we have to do is figure out how they did it.",15
farrell lines,1.0 out of 5 stars,How to Create a Mind: The Secret of Human Thought Revealed,Nothing new here,"I like Ray. A lot. He's a compelling thinker and an important presence in moving us forward towards some version of artificial minds. But this book isn't worth anyone's time. C'mon Ray, you can do better than this.",15
gcgutier,5.0 out of 5 stars,Introduction to Machine Learning with Python: A Guide for Data Scientists,Exactly what I was looking for,"Fantastic introduction to machine learning in Python. The examples are well written, and do a very nice job of introducing both the implementation and the concept for each model. I'm halfway thru the book, and am really enjoying it.

I have a background in math and wrote software professionally for a number of years, but haven't spent much time doing either for the past 5-10 years. This book is technical enough to keep me interested, and accessible enough to allow me to ramp up on the language and the scikit framework.

An added bonus - the instructions actually allowed me to set up my development environment, and the code in the book actually runs!

100% recommend for someone looking to get started in ML with Python.",15
Vladislav Skvortsov,2.0 out of 5 stars,Programming Collective Intelligence: Building Smart Web 2.0 Applications,Not worth the money,"In short: this book isn't worth its price.

The major part of the volume of the book is code and corresponding explanations. If the reader is a decent programmer, he can actually figure it all out by himself given algorithms. Otherwise it makes more sense to get a book on data structures, or Python, or general algorithm construction and learn the basics there.

The algorithms/methods presented in this book are not really specific to ""collaborative intelligence"" (with a couple of exceptions). The author gives a brief overview of the techniques and then dives into great details on how to implement it. In reality unless you are working on a toy site, you don't really need that code, since it wouldn't scale or fit the production environment. You'll need the math model / algorithm to come up with reasonable implementation. However, it's exactly what the book is missing. Well, it gives *some* info on that, but you'll need to read a more comprehensive source if you intend to really implement it.

I was quite disappointed with the book. I guess it might be ok for a junior developer to get a feel of what that all is about. If you've ever come up with an algorithm by looking at a mathematical description of the approach, you don't need this book at all; you can write a similar one yourself.",15
Ivan Bohannon,3.0 out of 5 stars,Programming Game AI By Example (Wordware Game Developers Library),"Great book, bad kindle translation","I purchased this book after reading the other reviews, and I was not disappointed.

It has GREAT content. Now the annoying part.

Obviously a robot without a spell checker OCR'd the book and make a kindle version, and then the author or amazon never proofed it. Every single page has words with numbers in place of letters and/or funky random spaces in the middle of words, words are even broken across line breaks.

Also NO browsable table of contents, chapters, or organization of any kind, so you would probably be better of with the paper edition if you are going to be referring back to the book.",15
Kimberly F.,5.0 out of 5 stars,Amazon Echo: 2017 Edition - User Guide and Manual - Learn It Live It Love It,The guide that you need,"This fine book covers the set-up, usage and troubleshooting involved with owning an Amazon Echo. It is a view into the future - a view into voice commanded devices that control other devices that you own. Along with this it answers questions, plays music and controls a variety of devices that will expand over time. The book is a primer about this device, set-up options, and especially helpful is the trouble shooting section of the book.",15
Joseph Oliver,5.0 out of 5 stars,Accelerated Spanish: Learn fluent Spanish with a proven accelerated learning system,"Even if you are not a beginner, start here!","I had started learning Spanish before I found this system. It was a bit painful to force myself to stop studying my other resources and go back to the very basic fundamentals, but once I did, I found my comprehension increased virtually overnight. This method is a lottery ticket in understanding for those who follow it the way it was meant to be followed.",15
Nathan Taylor,5.0 out of 5 stars,"The Age of Em: Work, Love, and Life when Robots Rule the Earth","Best book on the future I've ever read, though jargon heavy at times","Robin Hanson has written the best book I've ever read on what the future may hold. Rather than explore many alternative possibilities, he deliberately picks a single future scenario to explore in great depth. Then leaves to others to work out alternates, building from his baseline. Hanson's chosen scenario is one where humans upload their minds to computers to create human emulations or ems. He uses standard social and physical science to grind out the details of what this world might look like. As ems are zero marginal cost to copy, this means ems live megacities which look like giant server farms gone mad, where billions, possibly trillions of copies of ems work. While some have robot bodies, most live in virtual reality in pleasant but malthusian conditions. Since these ems can run 1000x faster than regular humans, the economy doubles in months(!). While this phase might last hundreds of years in em subjective time, in calendar time it'll only be a few years. During those few years, humans can retire. Sticking to his guns, Hanson keeps his deep focus only on his core scenario, and doesn't spend time on what regular humans think or do. Or on what comes next. Though he does suggest the em era is followed by one dominated by new types of artificial general intelligence invented by the ems themselves.

That said, while Hanson writes in solid straightforward prose, he tends towards a jargon heavy, highly footnoted style. The book has no strong narrative. As I saw elsewhere, think The Silmarillion, not Lord of the Rings. Since I'm a long time reader of Robin Hanson's overcomingbias.com blog I'm familiar enough with his oeuvre to avoid getting bogged down with terms like ems, near/far mode, farmers/forager lifestyles, status signaling, coalition politics, etc. Or with Hanson analyzing ems based on his own particular take on human psychology. The book will definitely work for new readers interested in these topics, but will be a bit of a slog at times.

Hanson often notes that x is not about y, it's really about z. For example charity is not about helping, it's about signaling to others your helpfulness. In that sense, I suspect for many people Futurism is not about the future. That is, some (not all!) people who say they are interested in the future are really more interested in wish fulfillment about the present, or a utopian desire to fix things with technology, or enhancing a group's status, or just hearing an exciting adventure story. A real analysis of the future tends towards a dry, somewhat jargony, heavily footnoted tome. And that's what Hanson has written. It's a history book, though one about the future. Of course, some historians also write with great narrative power as well, and a few of those are also great historians to boot. But if I had to choose, I would take a well written, solid academic work full of quirky and often brilliant original ideas over narrative any day. So I highly recommend this book, greatly enjoyed it, and feel like I now have a slightly better view of what the future may hold. With caveats as noted.",15
gtdsox,2.0 out of 5 stars,Pattern Classification (Pt.1),Terrible Problems,"I am not sure how this book gets consistently high marks. I am using this text for a graduate level course. While it does a decent job covering most of the topics, it has some glaring flaws.

For one the Homework Problems it provides are not really representative of what you're learning in the text. Almost all of the problems revolve around proofs, as opposed to using the concepts in practice. You can seemingly have a good grasp on the material, yet spend hours trying to solve each of the problems they provide for that particular section. My entire class has complained, and even my professor has admitted that even he isn't sure sometimes how they expect you to solve some of the problems.

Secondly, there are very few example problems demonstrated in the text, so the reader doesn't really get to see the concepts in action so to speak.

Also, there is a typo or error on almost every other page, sometimes even on important formulas.

Overall, I'd have to think there are better books out there. If this truly is ""the best there is"" as some reviewers claim, God help the field of Pattern Recognition.",15
William Schreiber,5.0 out of 5 stars,Learning Robotics using Python,"Misleading title, but excellent robotics book","The title of this book is misleading. Yes, there is python in the book and the examples are written in python, but the book is really about how to take existing technology and build an advanced robot at a price most hobbyists could probably afford. Most of us build a line follower, a light avoider, a robot that bounces off walls and then randomly turns etc, but moving to that next step of building a robot that knows where it is and can find its way back (SLAM algorithm) is something else most builders never get to since it is a hard nut to crack. He gives a blue print for an advanced robot which can be built for well under a $1000 and uses ROS (robot operating system), PCL, a Kinect, IMU, ultrasonic sensor ARM processor etc.

He takes all the pieces that are out there and shows you how to integrate them all into an advanced robot. It wasn't what I expected from the book but I was pleasantly surprised since it was exactly what I need to get myself to that advanced robot I really want to build.

Warning, that the directions may be out of date (it is predicated on an older version of ROS) and you will need to use the internet and/or other resources to do all of the things he documents. It is still worth every penny",15
Mark on Amazon,5.0 out of 5 stars,Essentials Of Discrete Mathematics,Best book on discrete math I've yet found,"This book is written and illustrated in a manner that is clear and precise, while using plain English. Terminology is explained. Intermediate steps are explained. Dependencies between chapters and sections are clearly marked. Exercises and examples are relevant and progress from simple to complex. A good breadth of subject matter is covered. For the reader who is not particularly mathematically-inclined, but who needs to master the fundamentals of discrete mathematics, (such as for computer science), this is an outstanding book, head and shoulders above any other I've used (and, to get a grip on discrete math, algorithms, and optimization, I've been reading A LOT of them lately).",15
T. Wiedman,4.0 out of 5 stars,Neural Networks for Pattern Recognition (Advanced Texts in Econometrics),Only for an expert,"Mr Bishop's book is very well written and contains a lot of useful information on neural networks. It is outlined well and progresses in a logical form. If, however, you are looking for a book that gives discussions with concrete examples of neural networks applications or set ups, you will be sorely disappointed. The mathematical treatment is universally generalized with very few specific concrete examples shown. Even the exercises will not serve you well. The term 'graded' is used; however, that simply referes to the description of difficulty. There are no answers to these exercises, so unless you have a teacher or are already firmly familiar with the material, you will not know if you have completed them correctly or not. Even worse, the exercises are in general not written to reinforce concepts in the chapter, but in most cases extend the chapter material into new regions.

In summary, this book should only be purchased by someone already familiar with neural networks and their mathematical basis. Anyone else will be wasting their money.",15
Paul M Sweazey,5.0 out of 5 stars,The End of Error: Unum Computing (Chapman & Hall/CRC Computational Science),"Amazing! A brilliant technical work and a ""page turner"" in the same book","Sure there will be naysayers, but 10 years from now we will look back to floating point as if it represented the dark ages. Structural engineering, Cosmology, and even high school calculus will be distinctly improved, startups will be born, and future generations will find that science and math are less baffling and more honest than today.

I bought this book because of my slight hope that it would show me an improved floating point variant. Instead I discovered a fundamental breakthrough. Gordon Bell says that the next step is implementation and testing that would lead to wide-scale adoption. I say, not would, but will. This book is easy to read, entertaining, and filled with surprises and revelations that keep you turning the pages.

I spent a career steering toward hardware architectures that could solve their problems using only integer data types, and away from problems without closed form solutions. This book helped me to understand what I feared and why. And now how do I feel? No project could be more satisfying than to build a unum processor. Congratulations to Mr. Gustavson for unums, which show how the real number line deserves the title ""real"".",15
galaxy_express_899,3.0 out of 5 stars,Feynman Lectures On Computation,Dissapointing,"I find this book dissapointing. It doesn't compare with the insight, clarity, and beauty found in the famous ""Feynman lectures in physics"". Basically what Feynman does in this book is simplify and coaches one though complex Computer Science/ Information Theory Concepts. The book may have the small size of a novel, but I find it to be more like a textbook; because it has many equations (even exercises in the first chapter), and also one has to be quite attentive while reading. I'm not saying this is a bad book, only that, if you liked the ""Feynman lectures in physics"" it doesn't automatically mean you'll like this book. This book is different, obviously in the sense that it doesn't deal much with physics, and secondly in the fact that it is not passionatly written, I think. Why is this book so expensive anyways?
Now that you got my warning. I can definitely recomend this book for people intereseted in things like:
-theoretical limits of computers (enthropy, energy)
-physical realizations of logic gates (transistors)
-quantum computers",15
Ddub,5.0 out of 5 stars,Machine Learning in Python: Essential Techniques for Predictive Analysis,Great book on both the fundamentals and getting started!,"I'm somewhat new to the field, working on a new venture involving predictive analytics. Of the resources I'm using, I keep coming back to this book - the background, problem setup, explanation of tradeoffs, and code examples have been really good. I'm no Python developer, but I was able to narrow down to an algorithm and get it running with Anaconda and Scikit-Learn without much trouble. Compared to a lot of other resources I've seen, this is a great book for a complete view of the recent algorithms along with a how-to on getting started.",15
Mark on Amazon,5.0 out of 5 stars,Essentials Of Discrete Mathematics (The Jones & Bartlett Learning Inernational Series in Mathematics),Best book on discrete math I've yet found,"This book is written and illustrated in a manner that is clear and precise, while using plain English. Terminology is explained. Intermediate steps are explained. Dependencies between chapters and sections are clearly marked. Exercises and examples are relevant and progress from simple to complex. A good breadth of subject matter is covered. For the reader who is not particularly mathematically-inclined, but who needs to master the fundamentals of discrete mathematics, (such as for computer science), this is an outstanding book, head and shoulders above any other I've used (and, to get a grip on discrete math, algorithms, and optimization, I've been reading A LOT of them lately).",15
C. Andersen,5.0 out of 5 stars,Bootstrap Methods and their Application (Cambridge Series in Statistical and Probabilistic Mathematics),A Clear Introduction to the Bootstrap & Applications,"This is a well-written book, and I had the basic bootstrap notion figured-out and implemented within a few days, though it will be some time before I develop any serious depth of mastery of the material. For those unfamiliar with the bootstrap method, by a system of resampling from an existing sample of data it provides a means of establishing the standard error for pretty-near any statistical measure (like the standard error of the mean in traditional statistics), as well as the determination of general confidence intervals for those measures, even when the distribution of the data is non-gaussian or unknown. I do find the author's symbolic notation a bit confusing - perhaps TOO compact, and many of the symbolic expressions would really benefit from an associated clearly written paraphrasing (difficult for me to remember all the conventions after putting the book down for a few days). Still, to go from being barely aware of the technique to applying it to the data analysis in a current research project over a period of several weeks suggests that this text does a heck of a good job at conveying the intended introduction.",15
Lucas N. Santos,3.0 out of 5 stars,"Web Data Mining: Exploring Hyperlinks, Contents, and Usage Data (Data-Centric Systems and Applications)",Good overview on current topics,"What I liked most about the book was the scratch I got when facing all the possibilities regarding data that is free available on the Internet. My interest area is crawling, and there is an exclusive chapter about it on the book. But as with all others chapters, it's only a bird's-eye view on the topic, so specifically the crawler part of the book wasn't of much use. In spite of it, my expectations were reached with the rest of the work, since I just wanted to be aware of what is happening today concerning Web data mining. I must note that, although chapters on relevant topics are small (more or less 30 and so pages) and surely don't cover all the nuances, the book comes with plenty of references for anyone who wants to dig further.",15
John Harpur,5.0 out of 5 stars,The Computational Brain (Computational Neuroscience),A source of stimulation and frustration,"There is an argument that this is a book of its time. It is nearly fifteen years since it was put together and a great deal of neural water has flowed under the bridge. The thematic enthusiasm for computationalism that dominates the book has not been convincingly proved in the meantime. If anything, the computational properties of models have been shown to entertain many unpleasant complexity results. Moreover, the localisation of brain functions grounded in naive interpretations of lesion effects has come under greater scrutiny due to detailed MRI results. Given twhat was known at the time, it is unsurprising that the book focuses on the visual system - a focus also found in Christof Koch's recent book. Acknowleding all that and more, it would be hard to find a better condensation of science, computationalism, and philosophical speculation than in this book.

Leaving aside downsides arising from recent discoveries that the authors could not have anticipated, the book can be frustrating to read at times. In particular, there is a tendency to introduce technical concepts and descriptors into accounts without prior definition. For example, very early on in a brief account of monkey vision there is mention of V4, MT, etc. The terms are neither defined nor explained. Strangely, in the introduction to networks, the inner product of two vectors is explained while the outer product is not. Small points but the oversight recurs.

The philosophical content in the book is light, but the assumptions driving the work are among the most contentious. There is no point reaming off a list but the book does not shirk supporing the brain-as-a-computer hypothesis.

All in all a stimulating work, if in need of updating.",15
D. Archer,5.0 out of 5 stars,Robot Building for Beginners,Amazing Find for Teaching Kids Electronics and Robotics,"I have bought other robot building books in the past for my teenage son, yet I quickly got lost in each of them. Not sure how much he retained. Then I found this book. It's wonderful!

A little background: I have a college degree in science- health science. My electronics education is pretty much limited to the Physical Science I took in 9th grade- and I remember my Dad helping me struggle through that! However, I have two sons who are interested in learning robotics. There were no classes or organizations nearby, so we decided to start our own group so the boys could learn with a group of friends. Needless to say, I had to teach it! Over the past year, I've tried several different books/curriculum- including Lego Mindstorms material. I quickly got bogged down in each of these due to my limited background on the subject. I bought this book on a whim as a Christmas present for my oldest son, and was amazed the moment I opened it. After reading each chapter, I truly understand the concepts Mr. Cook is presenting. Our Robotics group decided to use this for our Spring ""semester"", and we are working through this a few chapters each week. The kids are really learning, and I even have a couple of kids as young as 10y/o who are reading the chapters and enjoying it! We decided to buy the kits that go with the books from Solarbotics to simplify things somewhat due to our group size, but we are loving it! I already have the next book- Intermediate Robot Building- ordered for my son to start when we finish this one.",15
John C. Wilkinson Jr.,5.0 out of 5 stars,Robot Building for Beginners,Robot Building for Beginners and the follow on book open new doors,"To me robot kits leave me feeling disappointed and turned off. I mean u buy a kit, assemble it, learn next to nothing, and then the robot just does one thing and u quickly tire of it. These 2 books (especially the 2nd one) turn robotics into an open-ended hobby and a continuous source of education and experimentation. With kits, they do nothing until you are done and then only do one thing. But the way David Cook presents it, you learn all the time, you test little pieces and watch and learn how the parts work and how to make changes in the design. These 2 books are the best robotics books I have ever bought!",15
John Hofmann,3.0 out of 5 stars,Intelligent Data Analysis,Good book for academic work,"I'm sure this book is very helpful for academics who are doing work or research into sophisticated ways of extracting knowledge from data, but if this is something you are looking to do for a practical or professional reason, this book probably isn't for you. It's very detailed with in-depth mathematical explanations for everything, although they are not helpful in actually implementing any of these types of algorithms. The book is also basically an index into publications and other works, so it's not really self-contained and I don't think it should be considered a standalone work.

It's got very interesting, well-researched material from very knowledgeable academics, and it seems like that's also the target audience. That's not bad, but it wasn't clear when I bought this book. If you're like me, and you're looking for practical explanations of these concepts, you may want to consider looking elsewhere.

I assume it's very useful for pure researchers, although I'm not one of those people so I have no insight into their needs. I hope this review helps give an idea of the contents.",15
Dr. Lee D. Carlson,3.0 out of 5 stars,What Is Thought? (MIT Press),Some interesting ideas here...but speculative at many places,"Rapid progress is now being made in the field of neuroscience, and this progress is not merely in theory, but also in laboratory measurements, thanks to the advances in magnetic resonance imaging. Also, advanced and practical applications in artificial intelligence are now a reality. Indeed, applications of artificial intelligence in the business environment are skyrocketing, and there is every indication that this will continue. Still though, the nature of human thought remains somewhat of a mystery, which is a kind of irony, given that intelligence is imputed to humans even without understanding fully what is really going on in the human mind when it is engaged in problem solving, reasoning, planning, or myriads of other activities. We do have non-human intelligent machines, but they are not considered to be by most, with the sole reason being that we can understand the nature of their problem-solving abilities. Will we then continue to view the human mind as exhibiting intelligence once we have deciphered its workings?
This book gives many different insights into the problem of human thinking and just what are its origins. Although written for the ""popular"" audience, much can be gained from reading it regardless of the reader's background. It does indulge in speculation frequently and reasoning by analogy, and it skirts at the ill-defined boundaries of philosophy, but it is worth taking the time to read in detail.
The author has a very specific view of intelligence as is readily apparent when he remarks that human intelligence has the ability to ""understand"" in many domains. Machines in his view though do not have this ability, but are ""brittle"", and cannot tackle different problems on the fly the way humans can. But does ""understanding"", as we frequently impute it to humans, have to accompany successful problem solving? Why is it that we are prejudiced in the requirement of ""understanding"" when we characterize an entity as intelligent? And is the ability to answer questions from many domains or contexts, however vaguely they are presented, really indicative of intelligence or understanding? The author wants to clarify the notion of ""understanding"", this to be one of the goals in the book. He asks whether there is some ""quantity called understanding"" that will serve to distinguish mechanical computation from thought. The author is expressing great insight in bringing this question to light, as it has long been a prejudice that machines are merely engaging in syntactical manipulation, and unable to deal with the ""semantics"" or understanding of the ""meaning"" behind the symbols.
The thesis of the author is very straightforward, namely that Occam's razor, as he defines it, serves as the foundation for human reasoning and the mind. The criterion of simplicity is formulated using Kolmogorov complexity, which is currently the most popular one, at least in the computer science community. Most interesting though is the author's view on compression, in that the human mind functions by using essentially compressed programs. Compression to him is the key to understanding, in fact is equal to it. Compressed descriptions are the origin of understanding, and the human brain has, through evolution and reinforcement learning, acquired very adept programs for a myriad of tasks relevant for human survival.
The author's arguments are interesting, but he frequently uses arguments by analogy rather than backing them up with empirical research. More use must be made of the research in neuroscience and psychology before claims can be made on the functioning of the human brain. Too much philosophical discussion has invaded the author's arguments, and this weakens his case in many places in the book. It is the opinion of this reviewer that those engaged in research into artificial intelligence, neuroscience, and closely related fields should declare a moratorium on philosophical speculation and argumentation. The conceptual spaces generated by philosophical speculation are too large to be practical, as they contain too much information, which is constantly expanding with time because of the lack of side constraints, or ""inductive bias.""
Since the efficacy of the human brain is the result of evolutionary pressures, one would naturally ask what role the genetic code would play. The author answers this question in very simple terms, namely that the generation of mind was due to the training of a compact program. This compact program was encoded as DNA, and evolution was a training process for this program. It took four billion years of this training to be compactified into an expression residing in the DNA. This viewpoint is an interesting one, and it sounds very plausible, but again, it still needs to be supported with empirical evidence.
Much use in the book is made of results from computational learning theory because of the author's belief that inductive bias is the crucial to learning in complex environments. `Inductive bias', as he views it, and how it is viewed by researchers in computational learning theory, is a certain preference in learning one concept rather than another. Certainly it is true, and it has been shown by research in computational learning theory, that inductive bias is useful in pruning the search space and can assist in omitting useless information that is not pertinent to the problem at hand. However, the author's view is much stronger regarding the role of inductive bias: he is claiming that it is absolutely essential for learning in complex environments and therefore that other approaches to learning in such environments will not be as efficacious. His views are thus at odds with certain results in computational learning theory regarding the absence of a ""free lunch"" in randomized algorithms (as reinforcement learning is). The author is claiming, perhaps without meaning to, that learning algorithms that incorporate inductive bias will give essentially a free lunch. The only way out of this difficulty might be to acknowledge that the learning processes used by the brain are still being subjected to evolutionary pressure and hence that the learning processes now being used are not optimized, and are undergoing modification (however slowly).",15
Brian James,1.0 out of 5 stars,"The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Second Edition (Springer Series in Statistics)",,"I am a physician who is interested in data science as a way to analyze health outcomes. I am new to this field, but in undergrad I took three semesters of calculus, differential equations and graduate-level statistics courses (and I made A's in all of them except the differential equations course). This book is definitely not geared towards beginners or anyone who does not hold an advanced degree in mathematics or statistics. I also have about four years of programming experience, notwithstanding that I am rusty.

That said, I am having an extremely difficult time parsing the information in this book, as it consists mainly of mathematical jargon with little explanation of anything. I would definitely not recommend this book as a didactic textbook for beginners or even intermediate level learners in this field.

I am sure the authors are very knowledgeable in this field, but this book is not a good textbook to learn from. To quote the authors ""We expect that the reader will have had at least one elementary course in statistics, covering basic topics including linear regression."" I have to call BS on this, as I never had any trouble in my classes (or learning directly from textbooks without instruction) and this book is just killing me.",14
Kayode Leonard,2.0 out of 5 stars,Design Patterns: Elements of Reusable Object-Oriented Software,Great if you live in the 90's,"This book reminds me why I hated school so much, despite my innate love for programming. It is bland, boring and outdated. If it had pictures in it, I would have drawn mustaches on all the people. There is nothing about the way this book is written that engages the reader and makes them want to read more. The examples are outdated, and don't directly apply to developers using modern languages like C#/Java. I mean using sub-classing for method callbacks is one such example, gimme a break. With that said, this book I'm sure was groundbreaking when it was written when a lot of this stuff was not well known. However, being a programmer of the modern age, most of these patterns are intrinsic and intuitive. Most of these patterns I've used throughout my career, I just didn't know what they were formally called. So, if you want a book that puts a name with the common patterns you normally use day to day, by boring you to death in the process, then this is the book for you. If you are a teacher and want to fail your whole class and discourage them from pursuing CS as a major, then this is definitely the book for you.",14
Calvin,5.0 out of 5 stars,Artificial Intelligence: A Modern Approach (3rd Edition),"Finally, a text book that you can read","Text books are usually cryptic and boring, but this one's actually quite fun to read. It's so easy and fun that I'm actually excited when the professor assigns a new reading. In fact, I liked it so much that I looked up the author to find more of his books, and guess what? The author works at Google. Someone in Google making a user-friendly textbook? I'm in!",14
Paul McConnell,1.0 out of 5 stars,Amazon Echo: Master Your Amazon Echo; User Guide and Manual,Don't waste your money on this drivel,"This 34 page paperback set me back almost ten bucks. The type is large enough to be read from a distance, is double-spaced, and enough blank pages are furnished to permit copious use of your crayon supply. I learned very little more than what is available from the limited guide that came with the Echo is the first place. Don't waste your money on this drivel!",14
ChristineS,1.0 out of 5 stars,Amazon Echo: Master Your Amazon Echo; User Guide and Manual,Nicely written but...,"Although it gives you info about the Echo, it is nothing that I have not already read in reviews from CNET or others that have reviewed the Echo. Definitely not worth the purchase. I thought I was actually going to learn something new. I will continue to read info on the web.",14
Bruce Chambers,1.0 out of 5 stars,Amazon Echo: Master Your Amazon Echo; User Guide and Manual,24 pages of basic generic information,"I can't believe I paid $8.75 for a large pamphlet that contains no useful information at all. If you exclude the introduction and conclusion (which contain nothing useful), you have 24 pages--with large print--of some of the most basic information you could imagine. I can't imagine anyone that would need a book to give them the information in this book--almost all of which came with the Echo.
Save your money.",14
Lou Gutnicki,4.0 out of 5 stars,Data Smart: Using Data Science to Transform Information into Insight,"Great Book, Lousy References","I would go as far as to say that the book is brilliant.
First, a drop about me from the standpoint of this book. I have been an IT professional for many years specializing in programming, database, and MS Office add-ons. Part of my job entails self enrichment, that is, expand my working knowledge in areas potentially important for my job. I chose Foreman's book to help with this task for a number of reasons: a) Data Science is a hot area and my company does have a Data Science group, b) I have lots of data experience under my belt - I felt that it would be nice for once to get some useful information from the data, and c) I have a really good Excel background - so I figured that Foreman's approach would be perfect for me - little did I know that I would seriously add to my Excel bag of tricks.
The author makes the assumptions that: a) the reader is somewhat technical, b) he knows nothing about Data Science, and c) he is relatively comfortable working in Excel.
Reading the book is a joy because Foreman has a cozy, chummy style. He definitely doesn't throw all the technical stuff at the reader rat-tat-tat machine gun style like many other authors. Instead, Foreman gently introduces his topics and then ramps up technical details carefully. This most definitely helps the learning process.
Speaking of learning, by the end of the you will have learned important concepts in ""machine learning"" and I believe that you will be ready for the next step. I sure was. I found the topics interesting and I wanted to learn more. This is where the book's only problem area comes into play - the next step. Foreman has 3 references - one good, but minor, one terrible, and the other is inappropriate. Let me explain.
Foreman recommends a free resource as a follow-on to his Forecasting Chapter. This is a good reference, but I believe that Forecasting is a minor topic in Data Science, unless, of course, Forecasting becomes your thing.
Foreman's main reference is: ""Data Mining with R"" by Luis Torgo. Foreman recommends this as the next step after his book.I tried to read this several times, but couldn't. It certainly wasn't my next step.
The other reference, ""The Elements of Statistical Learning"" by Trevor Hastie, et. al, is totally inappropriate for Data Science newbies. You can checkout the Amazon reviews for this book and you'll see that you need a pretty serious background in statistics to get anything out of that reference. In fact, the author Hastie says as much in his next book ""An Introduction to Statistical Learning- with Applications in R"". This is the appropriate next step, but I'll get to that in a moment.
Here are my recommendations:
A. Read Foreman's book and follow along with him in working through the Excel spreadsheets. This is a first step in getting comfortable with Machine Learning.
B. Take the Coursera courses: 1) Machine Learning Foundations: A Case Study Approach, and 2) Machine Learning: Regression. The courses are free unless you want completion certificates, in which case there is nominal cost.
C. Now you are ready for: An Introduction to Statistical Learning: with Applications in R (Springer Texts in Statistics) This book is also available for free by the authors - check online.",14
Michael Matthews,5.0 out of 5 stars,Data Smart: Using Data Science to Transform Information into Insight,The Perfect Book for Meaningful Data Analysis,"This is an excellent book and incredibly powerful if you're in any sort of field that requires data analysis. I've read many books on the subject of statistical analysis and most seem to fall in the category of:

1.) A very technical ""how-to"" on using Excel/R/whatever to run certain functions but there is a huge assumption that you understand what the data output means. These are more like user manuals for their respective programs.

2.) A more high-level view of stats that is similar to stuff you learned in Statistics 101 but with far less examples and it can be difficult to see how this will apply in your position.

Foreman's book was recommended to me by Chandoo of Excel Guru fame and it is the book I've been searching for to step up my game. He does a great job of breaking down core concepts and introducing new tools(all in Excel!) that I can actually apply to my current position. That being said, there are a couple of caveats...

1.) I would recommend at least 6 months of solid Excel usage under your belt. The author goes over the formulas and you can download the files online, however there is plenty of OFFSET and Array formulas that can be intimidating to more casual users. I highly recommend downloading the files and doing everything from scratch, and then using the author's version as reference when you get stuck.

2.) This is not really a book you can breeze through(and I mean this as a compliment). The core concepts are broken down well but you will need to reread chapters to truly understand how the formulas and underlying concepts fit. I personally read Chapter 2 around 5-6 times so I can grasp k-means clustering and how I can apply it to my current project. I've only been in the data analysis world for a couple of years, so perhaps this is just my noviceness showing.

This is a fantastic book and one I cannot recommend enough. I hope that Foreman continues to expand on this series as I really enjoy his writing style and his ability to confer what's truly important in data science.",14
James,5.0 out of 5 stars,Make Your Own Neural Network,One of the best books on Machine Learning,"One of the best books on Machine Learning. I really enjoyed the style of the author, truly demystifies complex topics. I have many books on Machine Learning and Neural Networks but I always get lost and hit a wall. I purchased ""Python Machine Learning"" which starts describing similar topics at the beginning but then the book just moved too fast for me. I didn't know the why and how.

But Tariq's book was amazing, the author really takes his time to explain things mixing text with illustrations to make a point. Usually my attention span with these kind of books is few pages here and there a day, but with this book I couldn't stop. I was on a rhythm , and I felt I could retain the knowledge. When I attempted to read the other books, they all start perfectly on the first chapter, then all of sudden you see code and the authors move too quickly assuming the reader is following along or has some background knowledge. With this book I felt I could indulge in a meaningful dialogue with anyone on the topic, and I could explain things better. After reading few chapters from Tariq??s book, I picked up ""Python Machine Learning"" and what was amazing is that I was able to follow along and all the gibberish stuff started to make sense. So, I would urge anyone to start reading this book first because it covers all the fundamentals including basic Linear Algebra (Matrices).

I haven??t finished the book yet but I can??t wait to complete it, and then move to more advanced topics/books.",14
Martin van Creveld,1.0 out of 5 stars,Our Final Invention: Artificial Intelligence and the End of the Human Era,Both superficial and repetitive.,"The author has one, and only one, message: artificial intelligence may one day become very dangerous to humans. This message he repeats time after time after time, sometimes in his own words and sometimes in those of experts whom he has inteviewed. After twenty pages or so I got the idea and stopped reading.",14
J. Myers,3.0 out of 5 stars,Humans Need Not Apply: A Guide to Wealth and Work in the Age of Artificial Intelligence,Critically important topic marred by unlikeable presentation,"This is an unbelievably vital topic, and Dr. Kaplan does a service by exploring the problems, and contributing his opinion of some solutions.

Dr. Kaplan implicitly identifies and feels out an inventory control problem in vocational education: Universities are producing mis-educated students faster than the workforce can consume them, with obvious resulting inventory buildup (showing up in not stacks of widgets, but stacks of unemployed workers). [See Goldratt's ""The Goal"".] At the same time, new-technology jobs are projected to go begging, unfilled, due to the mis-allocation of inventory (students who could have learned X but are stuck at A instead). Dr. Kaplan's proposed solution to this structural economic problem is a type of Kanban: Employers should post requirements for future jobs, in the form of vocational training loan sponsorships. Only that many students should be allowed to take those vocational trainings, in a one-to-one relationship. Then demand will be supplied efficiently, and there will be less wastage (of lives, i.e. unemployment).

This is an interesting idea, headed in the right direction, which should be explored further. Its surface challenges (employers want to hire today, but it takes 1-4 years to train a skilled student; there is no meritocracy in choosing which single students get selected for sponsorship; employers have difficulty projecting future needs beyond the next few quarters) can be polished out in version 2.

Dr. Kaplan unfortunately ties this Kanban system in with an ill-fated scheme to create new ways for students to take out credit by explicitly mortgaging their future earnings. Ignoring the fact that this is exactly what the status quo does, which has resulted in an industry bubble (student debt) that threatens the nation and will take decades to unwind, such a scheme has three problems: (1) it effectively indentures the worker to the company even more than now. This scheme is already being done with East Asian sex-trade workers for organized crime in Japan; to a lesser extent, it can be seen in American employers sponsoring foreign workers. The worker gets paid 2/3ds what they're worth, and cannot ever dare to say No to anything. Not pretty. (2) It makes the student pay for what is a mutual benefit to the student, the employer, and society. (3) It creates a new credit vehicle, which in six months will be bundled, sliced & diced, packaged, and resold on Wall St., contributing further to excess credit derivative bubbles. Also: (4) it provides yet another insidious way in which American workers mortgage their souls and lifetimes to The Man. Better to work on making education free, as Khan and Coursera do; or getting the government or the employers to sponsor the trainings; or incent millionaires and foundations to compete in quality/quantity of sponsorships; or teach people to save and be self-reliant, so that they don't have to take out credit to learn a trade.

So concentrate on Kanban, but lose the new credit vehicle. What would this look like?

The book is set in 10-point sans-serif font, and is physically painful to read. Margins are 5/8"" at the top, and 1.5"" at the bottom of pages. The book title, and all chapter titles, are typeset vertically. A future version would profit by using 12-point serif type, same pagecount, and chewing up the space at the bottom.

For a respected founder of Teknowledge, Dr. Kaplan sadly serves best by pointing out what he is ignorant of. He makes a ""joke"" that he lives in a 10,000 sq-ft, three-storey, 7-bedroom custom-landscaped home with a 2,500 sq-ft 2BR guest house, 5 refrigerators, that can accommodate 150 guests and 200 guests for parties respectively, but ha ha he's not one of those rich jerks like the ""top 1%"". They should give their money away to help create jobs and help people become less poor, the greedy bastards. Then he actually says he contributes his charity money to help his kids' ""private school capital campaign, instead of a local homeless shelter"".

Well, actually the top 1% homes start at 6,400 sq'. But more important is the ethics question that Dr. Kaplan brings up. Should people have free will over the possessions and capital they own and control? Or should what they earn be taken away from them by force, and redistributed to the poor?

'Cause we ALREADY have a social institution to take care of the latter, it's called The Government. I personally would like to see both taxes and charitable contributions be made voluntary, backed by strong marketing. If people feel called to donate to a cause, they should donate. But one of the reasons why The Rich do not spontaneously give all their money to poor people is because The Rich are each individuals just like you, me, and Dr. Kaplan--they feel like they've got legitimate expenses, concerns, and risks, and they do not feel called to donate. Dr. Kaplan may not be in the top 1%, but for certain he is in the top 2%. If even Dr. Kaplan, with his modest 350-guest capacity and his sub-$300K income, does not feel called to help the homeless, then why should anyone else?

It is therefore hypocritical to rag on billionaires because they do not spontaneously form more charities than they already do.

Dr. Kaplan then displays his ignorance of the difference between wealth on paper and cash flow, by insisting that billionaires like Jeff Bezos and Bill Gates are not helping people's lives, but could and should rather take their billions and give them to help people for real. Like give them jobs, or something. Why, Bezos is worth $32B; the greedy bastard could EASILY use that to fund a $26B shortfall in California's budget.

Strange as it may seem, Bezos does not have $32B in cash lying around his home. Although Dr. Kaplan talks about Gucci bags, most of Mr. Bezos's wealth is tied up in stock certificates. That he got as receipts. From contributing more than $32B to the economy. By creating steady jobs for 150,000 people.

Oh.

You mean, good entrepreneurs actually CREATE wealth? And (the successful ones) create steady jobs for people? And the rich ones have ALREADY DONE SO, so you might think about being grateful to them, instead of calling them stingy greedy bastards who should not be able to sleep at night?

(Yes, Hillary, entrepreneurs actually create wealth, not the Fed. Not Modern Money. But that's another topic for another day.)

Reality Check: If Mr. Bezos actually DID sell even 10% of his stock to buy hospitals, say $4B, what would actually happen? This would send a strong market signal that JEFF BEZOS does not think Amazon is All That anymore, and has better things to do with his time and money than manage and own the jobs of 150,000 people. Amazon's stock price would plummet like a flying sheep down 20%, and Jeff would actually walk away with only $3.2B in cash. But: Amazon's market cap is $300B, much of that owned by institutional investors. At the cost of a $3.2B hospital, Dr. Kaplan's proposal would instantly wipe out 20% or $60B worth of value owned indirectly by retirees counting on that to fund their groceries.

Ooo. Didn't see that one coming.

Dr. Kaplan then rags on Mr. Bezos for creating even more jobs with Blue Origin (instead of, say, California schools). He rags on the top 5% for having the gall to support the economy strongly with around one-third of the total spending. And he rags on the ancient pharaohs for providing guaranteed socialized employment for 25,000 workers over 20 years building pyramids & getting to eat meat, and causing a ""stable political and economic system for several thousand years"".
This might even make sense if his theme were the inefficiency of poorly-allocated endeavors. He could then comment on the ""Bridge To Nowhere"" problem of handing allocation of resources to someone else, like the Government, or a self-righteous entity that thinks it knows how to spend Other People's Money, which almost always ends in tears. For systemic (moral hazard) reasons. But no, his theme is the problems caused by insufficient viable jobs being around, as a result of technological expansion. So his examples undermine his thesis.

My problem with most people who go on about income inequality is that they seem totally unfamiliar with Zipf's law, or even the Pareto Principal. They seem to think it surprising that a few people make billions of dollars more than most people. They also seem to think this natural outcome is a problem. This is only a problem when people concentrate on perceived unfairness of relative inequality, and do not look at absolute poverty levels.

Say, for instance, you have a country, perhaps like Japan, where just about everybody makes $50,000/yr. In absolute poverty terms, everyone is well fed and quite happy. Now, say, you add a handful of 1% billionaires to the mix; people who create hundreds of thousands of more jobs, spend millions of dollars more money in the economy, keep a few more billions collectively in the bank so that banks are more solvent and can loan more, and pay millions in additional taxes.

According to the inequality metric, all the previous people have been made terribly unhappy indeed. The 1% are way so much richer than they are, that they are knawing their insides out in envy and agony.

According to any reasonable objective metric, though, not only are all the $50K people at least as well off as before, they are even better, because the money velocity of the overall economy has increased. Much better to measure absolute poverty rather than rail at Pareto inequality.

All this hogwash is a smoke-screen to the actual immanent problem, which needs a serious answer.

Dr. Kaplan amazingly conflates robot minds, which he calls ""synthetic intellects"", with robot bodies, which he calls ""forged laborers"". Excluding military robots, the first revolution hits hard in 2017-2018, while the second doesn't start to make a serious dent until 2022-2028. These require separate discussions and solutions.

All in all, a provocative first effort for a deadly serious topic; but the presentation gets in the way too much, and I feel the book raises more questions than it answers.",14
J. Palmisano,4.0 out of 5 stars,Dark Pools: The Rise of the Machine Traders and the Rigging of the U.S. Stock Market,must read,"My background...I have been heavily trading the stock markets for the last two years. I'm also an AI expert.

This book is a 'must read'. Not only does it give a great summary on how the stock market became computerized (as other reviewers mention), but it really helped me understand how the modern market came to be.

My goal in reading the book was to up my trading game, and while the book gives few trading ideas, it does a great job explaining how 'big money' and the HFTs game (cheat? trade?) the market. Understanding this alone really helps me understand price action at a whole new level.

I did have to remove one star though for the authors lack of understanding of computer algorithms and how they work. He uses ""AI"" as a catch-all phrase for any computer algorithm, even if it was a crude program that simply trades a stock spread.",14
Amazon Customer,5.0 out of 5 stars,Accelerated Spanish: Learn fluent Spanish with a proven accelerated learning system,You'll be amazed your ability to form sentences and use correct structure in a short amount of time!,"This book and the Accelerated Spanish full coaching program is by far the best way to learn Spanish. You'll use a memory palace to learn groups of words and conjugations of verbs with easy recall. Eventually the recall becomes natural and you begin speaking ""in your Spanish voice"" rather than thinking in English first then trying to translate. I honestly think that the coaching element to this program is key because your must practice with native speakers to become fluent. However, this book will blow your mind compared to other methods of study. I highly recommend you check it out!!!",14
R. J. Deneaux,2.0 out of 5 stars,The Age of Spiritual Machines: When Computers Exceed Human Intelligence,A half-baked masturbatatory science fiction sourcebook,"I had this book recomended to me (repeatedly) over the course of my reading of Radical Evolution. I was underimpressed by Ray's endless wanking at the idea of replacing human interaction with computer interaction, and the substition of the mortal coil with the superiortity of the T-800. If you are non-proficient with the subtlety of human mechinations, then the promise of escape via virtual reality, nano-orgasm machines, and techno-immortality can seem like the stuff of dreams. As a list of ""bold predictions"" this sketchbook of sci-fi cliches lacks the hard science to suggest the wildly optomistic timelines the author suggests.

As an artifact from the heady, euphoric days before the dot com burst, one can see how this book was published, and subsequently purchased by a great many people. By the time the author was defending previousely made statements about the actualization of his earlier predictions, I saw a pattern of half-truths that paints a techno-eutopia which here, in 2006, hardly exists in the labs of MIT, let alone for purchase as Best Buy, as the author so desperately hopes for.

This book summarizes a decade's worth of Popular Science articles (that decade being the 1990's) and the most enticing fantasies of the transhumanists, but is not actually fun to read. The dialogues with ""Molly,"" the author's internal dialouge about the future of the toys he wishes will save him, borders on embarrassing.

There are a dozen books about exactly these subjects, which should be read first.",14
william c christopfel,5.0 out of 5 stars,Nine Algorithms That Changed the Future: The Ingenious Ideas That Drive Today's Computers,Pedagogical Tour de Force,"A terrific book if you are interested in understanding how these algorithms work. The author is superb at explaining the core ideas in clear, understandable terms. You don't need to be a computer geek to follow this book. All you need is a desire to understand. I wish I had had more teachers like this guy when I was in school. I am truly impressed with his ability to explain.",14
BellieBee,5.0 out of 5 stars,"Amazon Echo: Dot:The Ultimate User Guide to Learn Amazon Dot In No Time (Amazon Echo 2016,user manual,web services,by amazon,Free books,Free ... Prime, smart devices, internet) (Volume 5)",really helped em a lot,"i got an Amazon dot as a gift and wanted to learn the various features, usage and other instruction of this useful tool before i begin it. this book is really great for starters as its like a manual and a tool guide that explains so many features of Amazon dot in detail. this is a great guide for people who are not much into technology stuff to use and operate gadgets like this.",14
Apaxmec,1.0 out of 5 stars,Persuasive Technology: Using Computers to Change What We Think and Do (Interactive Technologies),Oy!,"This is the second book I have decided to review. I have decided to do so inorder that others may avoid my mistake. The book is banal. It goes on and on, creating category after category of needless taxonomies. Nothing even slightly new or interesting. Additionally it suffer the problem of all ""internet"" books. It was hoplessly outdated by the ime it hit thw shelves. Someone exceptionaly tiresome wrote a phd thesis, invented jargon and then decided to turn it into a book.",14
David Rolland,1.0 out of 5 stars,Boosting: Foundations and Algorithms (Adaptive Computation and Machine Learning series),Deceiving content,"I can't believe other reviewers actually read this book. I'm disappointed by the content of the book. More than 75% of the content is actually theorems, lemmas and formulas you actually don't care about and I doubt anyone will verify if they are even true. I'm a software engineer with an excellent comprehension of maths (I always had A+ in University) and I found all these formulas indigestible.
I read all the chapters of the book and the actual useful, practical information could hold in less than 20 pages. Everything you can read on Internet about boosting is clearer and more useful than this book.
I have nothing against the Kindle format of the book but I wish I had bought the hardcover version to be able to sell it back right now.",14
Miguel Morales,5.0 out of 5 stars,Artificial Intelligence: The Basics,"Agree, Great Place to Begin","Well, hard to say that this is the 'best' book to begin with since this was my first. But I can assure you the it is a GREAT place to begin since it feels like an ""Information Desk"" where you can find where more information about a particular topic is. So if you are into Robotics or into Machine Learning or into ANN or GA, Cyborgs, or you just like AI but not sure what/who/where to begin? then this book will point you in the right direction. The recommendation he makes are so broad and targeted for practical and theoretical folks.",14
oldsoup,5.0 out of 5 stars,"Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond (Adaptive Computation and Machine Learning)",best book of kernel methods,"It is the best book on kernel methods. It covers a wide range of subjects.
The best thing is that after finishing one or two basic chapters, you can read the rest of the book in any order; most chapters are almost independent to each other. At the beginning of a chapter, the authors list the prerequistites, so a reader knows whether he will be able to understand the chapter.
For now the book still reflects the state of art. But it is a fast changing field. I hope the authors will update the book in the future.",14
JoLo,5.0 out of 5 stars,Lessons from the Masters: Current Concepts in Astronomical Image Processing (The Patrick Moore Practical Astronomy Series),Current Concepts In AIP A Must Have,"For anyone wishing to improve their astrophotography skills this book is excellent. I do not recommend it for those just starting out in astrophotography - there are other getting started books and guides out there - but for those who have invested the time and effort in AP and are moving up the learning curve, this book is an excellent resource.

The book is divided into chapters written by some of the top names in astrophotography - Tony Hallas, Robert Gendler, Ken Crawford, Jay GaBany, Babek Tafreshi and many others. The chapters concentrate on a single process or workflow, many of which inlcude step-by-step instructions for incorporating these techniques into your workflow. There are three chapters that outline an overall deepsky workflow that I found very helpful. Hallas' short chapter on noise reduction and his technique used to remove green pixels from the background was by itself worth the price of the book. Ken Crawford on HDR and PS mask refinement, Tafreshi's chapter on incorporating earth and sky, sections on wide field processing, color enhancement, the list goes on...

If there was one disappointment with the book, i would say it was Damian Peach on planetary / lunar photography. I was really looking forward to the chapter to improve my processing skills on these challenging objects, using my video camera and Registax. I found the chapter to be useless and very basic. It did not contain any tips or step by step techniques like the other chapters that i found to be so useful - it really didn't tell me anything I didn't already glean from the web and the astronomy forums.

But this is one minor complaint in an otherwise impressive guide for the midlevel astrophotographer. You will not be disappointed!",14
Julie,2.0 out of 5 stars,Data Analysis and Graphics Using R: An Example-Based Approach (Cambridge Series in Statistical and Probabilistic Mathematics),"Should have bought ""The R Book"" Instead....","I got this book over Crawley's (The R Book) since the Amazon reviews said that this one was more organized than Crawley's.. however, even if that is true (maybe.. but Crawley's organization does not bother me), this book does not have half of what ""The R Book"" has, and their GLM chapter is a poor explanation of the function.

I highly recommend purchasing Crawley's book over this one. This one is not horrible, but was not sufficient for me. Lucky for me I have online access to Crawley's book for free, which has saved me in some spots, along w/ the online R-help websites and list serves.

This book definitely doesn't hurt to have though, but if you are looking to only buy one book, I would not rely solely on this one.",14
N/A,5.0 out of 5 stars,Digital Arithmetic (The Morgan Kaufmann Series in Computer Architecture and Design),A good book by a good Professor,"I had taken the course ""Digital Arithmetic"" under Prof. Ercegovac in UCLA and had used the draft version of this book. Professor Ercegovac is extremely knowledgable and well-known in his area and I was amazed at how quickly he was able to answer all our doubts.
Now about the book. I have not read any other book on this subject except this one. So, keep that in mind while considering my review. This book is about efficient algorithms for arithmetic operations like addition, multiplication, etc and the ciruits for realizing these algorithms. The book deals with circuits at a high black-box level, so you don't have to be an expert in low-level circuits (in fact, it hardly needs any electrical enginering knowledge). I found the book to be pretty good. First the organization. The book starts with a brief review of various number systems, etc. I was pleasantly surpised to know that apart from the decimal, binary, n-ary number systems, we have what are called redundant number systems, etc. It was also fascinating to know how different number systems had different tradeoffs which made one number system better for certain operations (for eg. redundant number system is good for multiplication) but maybe not for other operations. Then the book discusses two-operand addition techniques. By the first few pages of the this chapter, you would have covered simple schemes like ripple carry adder, carry-save adder, etc which are normally covered in undergraduate computer architecture courses. Then the chapter discusses various other schemes for two operator addition. The next chapter deals with multioperand addition, which as the name implies, discusses different techniques for adding more than two operands. It is very amazing to see the authors use very clever tricks to reduce the complexity of the circuits needed to realize the operations. The later chapters discuss the more complicated operations of multiplication, division, square roots, etc. There is also a chapter on serial arithmetic. These later chapter may be a bit difficult to understand if you are planning to study them on your own and if you don't have much background in this area.
Overall, I found the book to be excellent. It has plenty of figures to explain the concepts and a number of exercises to test your understanding. The only minus point I found was that some sentences in the text were confusingly framed. This might be expected because the authors are not native English speakers. But, then I had used the draft version and I have been told that the print version is much better having gone through the editing phase. To conclude, after taking the course (with this textbook), I came out totally amazed by the fact that there is so much more to know than we can imagine about the ""everyday operations"" of addition, multiplication, etc.",14
Evelyn Uyemura,4.0 out of 5 stars,Alan Turing: The Enigma,"Still an Enigma, but thought-provoking","This is a re-release of a book that was first published in 1983 (and largely researched during the 10 years prior to that), so it first came out in a very different time than today--a time when World WarII secrets were still being somewhat protected, and when the details of a homosexual man's life were still not easy to explain to the average audience without giving offense. Also, it was written and published in Great Britain. As a result, there are many allusions and off-hand references that are opaque to an American living in 2015.

Although the author is a gay rights activist himself, as well as a mathematician, and wrote this book in part to try to see Alan Turing's life from a sympathetic point of view, some of his narration comes across as coy to the point of obscurity--he mentions Turing's trip to Sweden, but it is not till much later that it finally becomes clear that he went there to pick up young men. It is never completely clear which of his friends were also lovers and which were just colleagues. And perhaps that was necessary when those men were still alive, or were only recently deceased, but if the book is going to be re-issued, it needed to be re-edited as well. The intro, which details places where changes should or could be made, was not an adequate substitute for a revised edition.

The explanations of code breaking is detailed, but perhaps necessarily obscure as well. I still have no idea of how Turing's insights were different than what the Polish codebreakers had already accomplished. One point that was a big issue in the movie, about how the Allies should use the information that they from their ability to read the Enigma code was never mentioned in the book, yet it is a crucial question--the movie has the military allowing a ship carrying one of the codebreakers's brothers go to its death, because otherwise the Germans would know that the Brits were able to read their messages, and would then change it. This is not in the book (fine, maybe it was fiction), but it's a key aspect of game theory--how do you use your hard-won information without tipping your hand? And if you can't use it, what's the point of having it?

It is a bit ironic that a book whose title implies that Alan Turing himself is the biggest enigma manages to leave him still an enigma in many ways, but that is the case.

I think the aspect of the book that I most grasped and that was the most thought-provoking was Turing's ideas about machine intelligence. Turing was not actually most interested in making machines that were intelligent; he was most interested in exploring intelligence in machine form in order to understand what human intelligence actually is. He posited an extreme statement: machines can (and will some day) do everything that human brains do. But his point was to show that there was no ""ghost in the machine,"" no special non-material ""spirit"" or ""will"" or ""intuition"" or ""insight"" necessary to explain human intelligence.

Like most people, I resist this idea to some extent. Could machines (computers, that is) ever make judgments? At first, my answer is no. But then they made computers that play chess at a Grand Master level (in the 1980s!). Ok, but that seems like a sort of a stunt. Recently IBM's Watson beat Ken Jennings and Brad Rutter at Jeopardy. Still, it seems more like looking things up on Wikipedia really fast, rather than actually thinking. But then I read that Watson is actually being used to diagnose illnesses, and that computers are more accurate than physicians, less liable to be led astray by forgetting or overlooking or dismissing crucial details. Hmmm, In advance, I would have said that the ability to diagnose a disease was an example par excellence of the sort of human judgment that computers would never have. And if they can drive our cars, and avoid accidents better than human drivers? Who would have thought it? Apparently the answer is, Alan Turing would have!

One off-hand remark in the afterword is that the author wonders if some day, a computer will be able to write a book such as his. Unimaginable, I think. But my daughter reminds me that computers already compose news items (rather badly, but still.) And we discuss the possibility that a basic undergraduate research paper could be composed by a computer today, and I think the answer is Yes. I can imagine that one could teach a computer to write a paper that discusses Domestic Violence, pulling together statistics on its frequency, demographics,causes, effects on children, possible solutions, and so forth.

I am left still puzzled by Alan Turing, finding it hard to picture him as a man, but deeply impressed by his mind, by his foresight and his insight, and I think that perhaps in some ways, he is in fact as significant a figure as Darwin and Einstein. What a tragedy that he died so prematurely, whether his death was in fact suicide, or possibly murder, or even more unlikely, a weird accident. How fitting and how odd that he died by (apparently) eating a poisoned apple. If it were fiction, it would just be too neat.",14
desertguy,1.0 out of 5 stars,Alan Turing: The Enigma,Don't be fooled,"Don't be fooled. This book may allude to the movie but it is not anywhere close. It is an overly detailed, mathematically and statistically dull biography. I wish I could get credit for my purchase. I could not get past the first ten pages.",14
CK,5.0 out of 5 stars,Error Control Coding: Fundamentals and Applications (Prentice-Hall Computer Applications in Electrical Engineerin),Foremost book in the field,"I had the previous version of this book as my text at USC. This version is a huge improvement over the last one. This one covers all the new advances and adds emphasis on the use of coding to communications channels. A complaint I had of the last version was that it under-emphasized coding gains and Eb/N0 vs. BER performance figures. This book has overcome many of those difficulties. It is still a bit ponderous in places but then it is the only book that covers the material in this much detail, truly a Bible of the field. It is a great graduate level text and a must-have book for any comm engineer. Charan Langton complextoreal.com",14
Paul Bundick,1.0 out of 5 stars,"Superintelligence: Paths, Dangers, Strategies",What ??,"So, I'm halfway through the book and so far it has been literally unreadable. I'm a Network Engineer but don't have a clue of what he's talking about or the terminology. Not sure if I will waste anymore time reading the rest. Very disappointing. Guess I'll need the dummies guide to Superintelligence! Paul",13
Michael E,5.0 out of 5 stars,Python Machine Learning,I decided on this book because of all the other good reviews. I have since picked up a few ...,"I'm a senior undergraduate student in electrical and computer engineering, and decided to make use of machine learning for my senior design project. Having had some experience in python (but not much with matplotlib or scipy), I decided on this book because of all the other good reviews. I have since picked up a few other books related to machine learning, but none can even compare to this. It's stellar! In three weeks I have managed to give myself a comprehensive crash course in classification algorithms using Python which is enough to give me a rolling start on my design project. I am about half way through the book, and apart from very few minor errors (to be expected in a first edition book), I cannot find any faults in it. It's a great resource for someone who wants to learn about machine learning but doesn't know where to start. I'm going to keep an eye out for further books by Mr. Raschka, because his ability to clearly and concisely explain things is superb. Additionally, I enjoy the fact that the book attempts to give a solid foundation on the mathematics behind various machine learning algorithms, since that is enjoyable for someone like me, who always likes to understand what is happening beneath the surface.

Update: Having finished the book now, I can definitely reaffirm my original position. This is one of the best technical books I have ever read. The last few chapters especially, image recognition with MLP networks and parallelizing networks with Theano and Keras are extremely interesting. I have taken these ideas and applied them in several of my own projects now. Also, as I'm planning on going to graduate school in the very near future, I'm thinking that machine learning and ANNs will likely be at the top of my list of areas to specialize in. The research that is going on in this field is huge, and this book manages to touch at the very base of neural networks, but enough to get your feet wet and show you where to go from there.",13
R. Williams,5.0 out of 5 stars,Design Patterns: Elements of Reusable Object-Oriented Software,CD Edition is Awesome!!,"What you've heard is true: this is the most important book on programming of the last __ years (at least 10, for me maybe of all time).
I wanted to just put a few thoughts in that I didn't see in the other reviews:
1. I read an article one time where John Vlissides (one of the authors) was saying he spoke somewhere and asked how many people had read the book and almost everyone raised their hands, then he asked, who would like to come up and explain how to implement the Composite pattern and suddenly only a couple hands were raised. Though this book is a fount of great ideas, it really will be most useful to you if you become CONVERSATIONAL with EACH of the patterns. That's the whole idea from Alexander anyway so consider it a mandate from on high.
2. One easy way I've used to explain to people what patterns are about is that mere object oriented training leaves people with an idea of how to model things as objects, but so many times I've done reviews of programmers code and they got that far and then as soon as work needed to be done that required more than one class, one of two things happens: they start passing data all over the place (back to the structured world we go), or they start binding their objects into deadly embraces. This book teaches you how to have some 'tricks' in your bag for modeling just such situations. Now, that said, there is some work you will have to do to map it into the newer programming world we're living in, for instance distributed Java makes some services available (like EJBs/container services/messaging) that changes some of the implementation ideas considerably.
3. If you are using Java, you can start to learn patterns and their application to your chosen platform by looking at a vast wealth of work that's already been done. The JDK uses the Observer pattern for its event model. Some of the more advanced frameworks, like BEA's Theory Center, are loaded w/Design Patterns (Chain of Responsibility and Strategy). And many products (Together/J) use patterns in their APIs (Visitor).
Finally, whenever I'm interviewing programmers now I ask them if they know what patterns are, then if they get past that, if they can give me an example of a recent use of a pattern and how it worked. I had a guy a couple of weeks ago looking for 6 figures who told me he'd heard of the book but hadn't gotten around to opening it. Der, that's like a doctor saying 'I've heard milk might not be good for ulcers, but take it because I haven't had time to review the research yet.'
More writers need to put out CD editions that are this good, dang it!!",13
Richard Cowand,4.0 out of 5 stars,Amazon Echo: Master Your Amazon Echo; User Guide and Manual,Great reference to learn more about Echo,"I'm interested in the Echo and was delighted to be able to read this guide. It is a bit heavy on the ""spin"", and sometimes feels like an extended sales pitch, but it does explain many technical aspects that I was wondering about. (No it does not have an ""audio out"" jack to connect to my stereo). Once you get past the ""rah rah"", you can actually learn quite a bit. I will reference this heavily after I make my purchase. For the price (free), this is a great reference book and an excellent starting point for someone that is trying to learn more about the Echo before buying one.",13
Amazon Customer,1.0 out of 5 stars,Amazon Echo: Master Your Amazon Echo; User Guide and Manual,Do not buy,"Terrible writing. And its purpose is to sell you on Alexa before you've purchased, not teach you anything you don't already know by the time you've owned it for 3 hours. To ""master"" something is supposed to mean learning extra information that everyone else doesn't already know.

Added 7/12/2015: I wish I could give it negative three stars. Finally finished it last night with huge sigh of relief. Indeed it did not teach me a single thing other than what an awful writer the author is. It did say things that were quite false. For example it said that when you say something to Alexa, the voice data is sent to your smartphone and all the processing is done on your smartphone. How absurd.",13
Mrs. C.,1.0 out of 5 stars,Amazon Echo: Master Your Amazon Echo; User Guide and Manual,No new info.,No new info at all. There's no info on using it to control other devices like lighting. Also I thought I clicked on a free download and it charged me,13
ZZ,3.0 out of 5 stars,Probabilistic Graphical Models: Principles and Techniques (Adaptive Computation and Machine Learning series),"A useful, comprehensive reference book; awkward to read","This popular book makes a noble attempt at unifying the many different types of probabilistic models used in artificial intelligence. It seems like a good reference manual for people who are already familiar with the fundamental concepts of commonly used probabilistic graphical models. However, it contains a lot of rambling and jumping between concepts that will quickly confuse a reader who is not already familiar with the subject. While the book appears to be systematic in introducing the subject with mathematical rigor (definitions and theorems), it actually skips a lot of fundamental concepts and leaves a lot of important proofs as exercises. I would recommend that a beginner in the subject start with another book like that by Jordan and Bishop, while keeping this book around as a reference manual or bank of practice problems for further study. The Coursera class on this subject is much easier to follow than this book is.",13
Nathan,5.0 out of 5 stars,Make Your Own Neural Network,"The author explains neural networks, a topic that is often made more confusing than it should be, in very simple terms.","This is a very nice introduction into Neural Networks. I have been recommending this to my friends and family. Even if you are afraid of the mathematics involved, the appendix in the book covers what you need to know in order to make sense of the math (most of it is simple algebra) with just a bit of derivatives that involve the chain rule. This is one of the few books that not only goes over the theory but also the step by step implementation (training your network to recognize handwritten numbers in Python) as well as testing the code and making minor tweaks to show how that will affect the overall accuracy of the network. For an added bonus, the author includes a chapter describing how you can train the network to recognize your own handwriting and things you can do to further increase the accuracy.

Even though I highly recommend this book, there are a few grammatical errors as well as labels being incorrect in a few of the diagrams. You can still get through the book without the errors taking away from the content. I'm sure in future revisions, most of these errors will be corrected. Aside from that, I am pleased with my purchase of this book. Money well spent and I will continue referring back to this book.",13
martin pszczola,2.0 out of 5 stars,Introduction to Machine Learning with Python: A Guide for Data Scientists,Not worth the money,"First of all, O'Reilly textbooks are way overpriced.

As for this text, if you want to spend the money and gain a better understanding of Machine Learning algorithms, then you should buy Max Kuhn's 'Applied Predictive Modeling' and read the FREE documentation for SKLearn to understand how to apply those algorithms in your analyses. Don't waste your money on this book.",13
Aaron Mcbride,3.0 out of 5 stars,Natural Language Processing with Python: Analyzing Text with the Natural Language Toolkit,A good overview,"I've only made it through the first half of the book, but here's what I think so far. It's a good book with a lot of overview information on the types of thinks that can be done with NLP today. I've certainly learned a lot. What I was disappointed by was the lack of description of the inner workings of many of the algorithms. They just give you a library and expect you to treat it as a black box. If you don't want to use their library, you have a long ways to go for real understanding.",13
Zac,3.0 out of 5 stars,Reinforcement Learning: An Introduction (Adaptive Computation and Machine Learning),Good introduction but not well structured,"This book provides an easy to read introduction in reinforcement learning. It covers several approaches (dynamic programming, monte carlo, temproal differnce) and gives a lot of examples.

However, in my opinion it is neither well structured nor written. The book has no clear separation between theory and examples given to demonstrate the applications of the theory. Due to this, the theoretical ideas are blured instead of clearified. After going through the examples it is always possible to find out how it work, but this should not be necessary.

After reading this book you will definetely know the basics (even more) about reinforcement learning. However, I somehow expected more because of the names of the authors. Perhaps this is not only a problem of this book but of the field of reinforcement learning itself.",13
Margaret Magnus,5.0 out of 5 stars,"Speech and Language Processing, 2nd Edition",Jurafsky and Martin,"I give J&M five stars and they deserve it, and here??s why. If you want learn to write natural language software, no other single book is as good ?? at least I??ve not found it. In fact, I bet they invented the genre. Pulling this together is not easy, and they do a creditable job. I know a lot more than I did before I read this book, and I??ve been writing linguistic software for over 30 years. As a linguist writing software (as opposed to the other way around), one can feel just a tad under siege these days. Google advertises that they don??t have a single linguist on staff, and MS is ubiquitously quoted for saying that the quality of their software decreases for every linguist they hire?? J&M, I??m happy to say, are above the fray. (What is ??supervised?? machine learning? Oh yeah, that??s where your input was created by a linguist. Supervised or not, you??re just playing number games on the foundation of a theoretical framework invented by linguists.) They provide a balanced account with historical perspective. I like them. They??re cool.

So on to picking nits... which is way more fun. What I really wanted is to read this book and then be able to sit down and write my own Python implementation of the forward/backward algorithm to train an HMM. I bobbed along through the book, perhaps experiencing a little bit of fuzziness around those probabilities, and came full stop at ??not quite ksi?? right smack in the middle of my HMM forward/backward section. I??d done a practice run by training a neural net in Andrew Ng??s machine learning course with Coursera. But I stared pretty hard for 3-4 hours at pages 189 and 190. And I mean I get it basically?? Alpha and beta represent the accumulated wisdom coming from the front and from the back?? And then you take a kind of average to go from not quite ksi to ksi. But there are too many assumptions hidden in P(X,Y|Z)/P(Y|Z). And this is an iterative algorithm, so how do you seed the counts? And I??m very annoyed by the phrase ??note the different conditioning of O??. Okay, I can see the O is on the wrong side of the line. What does that mean? When I came to the next impasse, I didn??t try as hard. It??s already clear I??ll have to go elsewhere for the silver bullet. (The next impasse, btw was the cepstrum ?? what do you mean you leave the graph the same and just replace the x-axis with something totally unrelated? I??m no Stanford professor, but what kind of math is that? I??m sure it means something to somebody, but not to me.)

And drop the pseudo-code. If you??re deadly serious about teaching me the HMM, then write out a working implementation in full in a real language like C or Python with the variables all initialized so I can copy and paste the code into my debugger and watch what happens to the numbers as I step through. I suspect J&M of compromising the pedagogical value of the book by deliberately withholding information from those brilliant Stanford students of theirs so they have something to quiz them on at the end of the chapter. But this is a mistake. Give us the answers. Give us all the answers. Give us the actual code for the HMM and then explain it. I will read the explanation. I??ll have to read the explanation, because my neck is on the line if my code blows up. There will still be plenty of questions left over for those students.",13
Tom in Florida,2.0 out of 5 stars,"Data Mining: Concepts and Techniques, Third Edition (The Morgan Kaufmann Series in Data Management Systems)",Get the hardback version instead.,"Viewing this in the Kindle reader was difficult. Many inset sections of text, including algorithms, appear as images in the text. These don't enlarge when I enlarge the font size and there seems to be no way to make them big enough to read. Even if they were bigger, the pixel size is large enough that they appear a little bit pixellated already. Enlarging them probably would exacerbate it.

Get the hardback version instead.",13
Denny,3.0 out of 5 stars,Programming Collective Intelligence: Building Smart Web 2.0 Applications,Good - If you know what you're getting,"Let me start with pointing out what this book does well:

- The book gives a good survey of common Machine Learning algorithms. It explains what kind of problems these algorithms are good for. That's perfect for someone who wants to get a quick overview and has no background in Machine Learning.
- The book is very easy to understand. The writing style is very casual. Even people without formal training in Computer Science should have no problem. The only thing that's required is basic programming knowledge, preferably in Python.
- Among all of the theoretical ML books out there it's refreshing to find a book that applies the algorithms to real-world problems.

Now the negative points. The following are not necessarily negatives for everyone, as it really depends on what you were looking for in this book. However, I was expecting a bit more, and was disappointed about the following:

- Half of the books is code. I just don't see the point in printing full listing of Python code. Why not give shorter pseudocode and make the Python code available on the website? The long code listings only obfuscate the ideas instead of demonstrating how to apply them. If you take away the code listings there are maybe 150 pages of ""real"" content left.
- The very casual and easy-to-understand style comes at a price. The book does not go into the mathematical details of any of the algorithms. I understand that this wasn't the books intention to begin with, but I would argue that some mathematical background is necessary in order to efficiently apply complex algorithms. If you want to apply the algorithms presented in the book to slightly different or more complex problems, or wish to understand the advantages/disadvantages of each of the algorithms you'll have to know the basic math behind them.
- The algorithms are very poorly implemented. Looking at some of the code makes me cringe. While the code in the book may work for ""Building a search engine"" for a few thousand pages, or optimizing problems with a handful of variables, it certainly won't work for more interesting problems that involve real-world data, which is orders of magnitude larger. And the real-world scale is where these algorithms actually become interesting. The code in this book will only work for small examples where efficiency play no role. I understand the author wanted to keep the code as simple as possible, but in my opinion a few notes about how algorithms can be made more efficient would have been necessary. I can see many people trying to apply these algorithms to their real-world data, and getting stuck because of the poor implementation.",13
Yegor,5.0 out of 5 stars,Decision Making Under Uncertainty: Theory and Application (MIT Lincoln Laboratory Series),a unique book,"I am a student at Stanford, and I had the pleasure of taking a CS course that used this book.

This is hands down the best introductory text I have come across on quantitative and computational methods for decision making and autonomous planning, with applications ranging from autonomous vehicle control to business decision making.

One reason this book is great is that it covers an incredible breadth of topics - everything from the foundations (decision making formalism, probabilistic modeling, sequential decision making basics) to rather advanced theory (POMDPs, newest advances in reinforcement learning) - without sacrificing the rigor and the depth of coverage. At the same time, the material is presented in a very logical order, which ensures that the new knowledge gradually builds on top of the theoretical foundation. The language of the book is plain, precise, concise and very easy to understand - even to people without advanced math background.

The quality of the math notation is in itself fascinating - the author has gone to great length to ensure all the math is very easy to read and comprehend. Finally, each chapter of the book provides an extensive literature review with up-to-date sources.
My impression is that this book could work well both as an introduction to the decision making methods, and as a review of a particular subfield. I strongly recommend this text.",13
Acesion,5.0 out of 5 stars,Essentials Of Discrete Mathematics,Simple and clear.,I used this book for two logic courses. The book is laid out in a straightforward logical(I would expect as much from such a book) fashion. You should be able to go from the first to the last chapter without a need to jump around to connect concepts as they simply build upon one another. Each chapter is also self contained meaning that if you only wanted to learn about graph theory you could skip to that section and read it and be able to understand it without needing to consult other chapters which is nice when you take a semester break between logic courses. The best part are the problem sections which the book provides detailed answers for. Unlike most math books which only detail a few steps or simply give you an answer to reference this book will actually lead you through the process of solving the problems which is immensely helpful.,13
Ashutosh S. Jogalekar,5.0 out of 5 stars,Molecular Modelling: Principles and Applications (2nd Edition),Comprehensive and self-contained,"In this book, Andrew Leach has done a great job in describing almost every important concept, sundry as well as significant, from the field of computational chemistry and molecular modeling. From basic but very useful topics like atom types, Z matrices, and force field parametrization, to advanced ones like Ewald Sums and Low Mode Monte Carlo conformational searching, Leach gives due importance to everything. The discussions on quantum mechanics in the first few chapters are moderate on the mathematics without shying away from it, and provide just the right amount of detail. Later chapters cover the whole gamut of computational techniques, from molecular dynamics and molecular mechanics, to molecular similarity and QSAR. Examples that are relevant in chemistry and biology are scattered throughout the book and illustrate every key idea. There are many good books for computational chemistry and molecular modeling, and some are good for a few topics, others for other ones. However, if one wants to get a grip on all important topics in the area, I think this is the most comprehensive reference that one can look up.",13
Raphael D. Mazor,5.0 out of 5 stars,The Grammar of Graphics (Statistics and Computing),This book changes the way you think about statistical graphics,"I boought this book because I am getting increasingly interested in data visualization. I've played around with ggplot2, and went to Edward Tufte's seminars, and eventually found my way to this book.

As the other reviewers mention, this is NOT a how-to book. It's a much deeper, fundamnetal treatment of how data and graphics connect, and how we represent them. So, it's not as much a ""useful"" book, except insofar as it changes the way you put together your next graph.

This book crystalized a lot of concepts I already understood, though only vaguely and intuitively. Like, a legend and an an axis are really the same thing, and that a stacked bar and a pie chart are identical except for the coordinate system used.

It's quite a dense slog to read this book, so I recommend you pick it up and read a few pages here and there, and follow through on the issues that catch your interest.

It's not for everyone, but I suspect it could make anyone communicate better through graphs.",13
Wyatt,5.0 out of 5 stars,Differential Equations and Boundary Value Problems: Computing and Modeling (4th Edition),if you wanna save a few bucks...,"I've compared this side by side with the previous edition, and all of the questions are the same. You could absolutely make it by with the previous book for much cheaper.

Regarding this book, it's a great book. Very informative and to the point. Small for a textbook, not a pain to carry around.",13
Wyatt,5.0 out of 5 stars,Differential Equations Computing and Modeling (4th Edition),if you wanna save a few bucks...,"I've compared this side by side with the previous edition, and all of the questions are the same. You could absolutely make it by with the previous book for much cheaper.

Regarding this book, it's a great book. Very informative and to the point. Small for a textbook, not a pain to carry around.",13
N/A,1.0 out of 5 stars,Discrete Mathematics (5th Edition),terrible book,"I keep thinking as I'm forced to use this book for a college course, that Discrete Math would not be so confusing to me if not for this textbook. With a good textbook, I believe the concepts would not be very difficult, but this book makes them so. True, they have many examples - very few of which cover the complex things you are then asked to do in the Exercises. If I could give it negative stars, I would, since it doesn't teach us but confuses us.",13
Demo Monkey,1.0 out of 5 stars,Principles of Data Mining (Adaptive Computation and Machine Learning),"Very, Bad Book !","I was very disappointed in this book. There are so many other books in the field of Data Mining that are so much better. This one has very little to offer.

It does a poor job explaining the theory.
It does a poor job giving practical ""hands on"" advice.

SAVE YOUR MONEY, AVOID THIS BOOK !!!",13
Acesion,5.0 out of 5 stars,Essentials Of Discrete Mathematics (The Jones & Bartlett Learning Inernational Series in Mathematics),Simple and clear.,I used this book for two logic courses. The book is laid out in a straightforward logical(I would expect as much from such a book) fashion. You should be able to go from the first to the last chapter without a need to jump around to connect concepts as they simply build upon one another. Each chapter is also self contained meaning that if you only wanted to learn about graph theory you could skip to that section and read it and be able to understand it without needing to consult other chapters which is nice when you take a semester break between logic courses. The best part are the problem sections which the book provides detailed answers for. Unlike most math books which only detail a few steps or simply give you an answer to reference this book will actually lead you through the process of solving the problems which is immensely helpful.,13
Ricardo C. Martini,5.0 out of 5 stars,"Matrix Algebra: Theory, Computations, and Applications in Statistics (Springer Texts in Statistics)",Beautiful book,"I think it's one of the best books on the subject, all theorems with demonstration, a lot of examples and problems solved (I like specially the chapter about Generalized Inverse matrix)... ...written in Latex so it looks very ""beautiful""...ALL what you wanted to know about matrix theory is in this book ... very rigourous, with modern notation for matrices and vectors, besides it covers almost all subjects related with the application of matrix theory (...for a statistician who works in multivariate analysis or linear models this book should be THE BIBLE...).Besides it is much modern than many of the good books in the subject (Gantmacher for example). I love this book",13
SDB Mike,3.0 out of 5 stars,"Introduction to Neural Networks for C#, 2nd Edition","Necessary practical review of methods for NNs, needs polishing","The author provides a needed introductory level book for NNs. I have several theoretical books on my shelf that hit me like a brick wall. Sifting through code with accompanying explanatory information is a luxury for non-theoretical folks like myself. Sadly, physically crunching the numbers (okay, letting code do it) while monitoring code execution is what some of us need to get a mathematical idea to sink in. This book provides that.

That being said, the author writes very mechanically, bordering on robotic. Just a little more writing finesse would greatly improve the readability. The text is still quite readable, though, and the references are available to dig deeper (Neural Smithing, for instance). In addition, for folks interested in the code architecture, this book is sadly lacking. Theoretical and mathematical information is first presented, followed by most of the code, and then code walkthrough. The code walkthrough is somewhat helpful and necessary, but discussion of the how and why of the code implementation is not adequately addressed. A few choice UML diagrams would greatly improve the reader's understanding of the code flow. This is especially important for the feedback sections.

Now, I bring this up because I think it is vital to an avid reader: I have only read the first 7 chapters. What? Really? And yet I am willing to rate it? Yes. It is the critique above that has kept the book sitting on my shelf the past several weeks. This is very interesting and directly applicable material and I should be willing and ready to devour it... and yet, I'm not. I will garner the will power to continue to the end because the Bot section was the content that queued me to by the book. Making learning agents, coupled with Buckland's approach in Programming Game AI by Example, is quite valuable to me. I think a 3rd edition could become a coder's gem.",13
s.,1.0 out of 5 stars,Here,Do NOT buy the Kindle Edition,"What idiot set up the kindle edition? The Polish and English texts are mixed together, a few stanzas in one followed by a few stanzas in the other. It's hard to read and impossible to appreciate properly. I can deal with weird editing of the free and cheapo books that Amazon offers, but this one cost real money. What gives?

And reading raves about how great the facing page setup works in the dead-tree edition just makes it worse!

--s.",13
Wyatt,5.0 out of 5 stars,Differential Equations: Computing and Modeling (2nd Edition),if you wanna save a few bucks...,"I've compared this side by side with the previous edition, and all of the questions are the same. You could absolutely make it by with the previous book for much cheaper.

Regarding this book, it's a great book. Very informative and to the point. Small for a textbook, not a pain to carry around.",13
J. A. Griffin,3.0 out of 5 stars,Mind Children: The Future of Robot and Human Intelligence,"Thought-provoking, but un-even","In this nearly twenty year old book, the author contends that advancing technology and the force of economic competition will lead inevitably (and in a span of mere decades) to a world in which machine intelligence vastly exceeds human intelligence. In chapters 3 through 6 the author gives a fascinating look at some of the possible features of that transhuman, post-biological world. Those chapters are as interesting and thought-provoking as any that have appeared in more contemporary treatments. Where the book does show it age, however, is in the first three chapters. There the author reviews the history of computer technology, and then succumbs to the shop-worn refrain of many classical AI researchers - ""If only we had a computer that is 100 (or 1000 or 10000) times as powerful as today's machine, then we could program a human-equivalent intelligence"". He even predicts on page 23 that ""a general-purpose robot usable in the home"" will be available within ten years. Well, today we have the computer power he was hoping for and still no general-purpose robot. Bottom line: if you want a fascinating look at what a world with superintelligent machines might be like, then buy this book and start reading at chapter 4. If you are interested in how we might actually achieve such a world then consider buying a copy of ""On Intelligence"" by Jeff Hawkins.",13
Leslie Frankel,1.0 out of 5 stars,Alan Turing: The Enigma,Practically unreadable,"I tried to read this book. Really I did. But unless you study advanced math, engineering, or are a physicist, I don't think you will understand most of this book. I loved the movie, but I could not follow long passages, sometimes whole chapters of the book. To make it worse, oftentimes the sentences seem to make no grammatical sense either. The writer's a mathematician so I guess he's writing for other mathematicians. Good luck reading this book!",13
Gshell,1.0 out of 5 stars,Alan Turing: The Enigma,Dry as a popcorn fart!,"So you loved the Imitation Game and want to know more about the saga of Bletchley Park and how Enigma shortened the war? Then this is NOT your book. This book will bury you in minutiae and bore you to tears. Yes, the work is thoroughly researched--but it is as dry as a popcorn fart. The author is so pedantic that it is unreadable to all but die-hard Alan Turing fans. Keep looking.",13
Sharat Chikkerur,2.0 out of 5 stars,OpenCV 2 Computer Vision Application Programming Cookbook,I would stick with the website documentation,"OpenCV has had several drastic refactoring making ""learning opencv"" obsolete. I picked up this book hoping it would be a better guide for the new version. However, I find it very sparse on actual openCV details and more focussed on software engineering. I appreciate the advice of using controllers and strategy patterns. I would find the fact that including opencv.hpp instead of cv.h in the new version even more useful. I think in this particular instance following the documentation on the website more useful because it is more information and keeps pace with the frequent changes being made to opencv.",13
A. Oliver,4.0 out of 5 stars,Mastering OpenCV with Practical Computer Vision Projects,Good book if you are familiar with the basics of OpenCV,"I'm one of the authors of the book Practical Computer Vision with SimpleCV. The original reason we wrote the book was we felt OpenCV was lacking a lot of 'real world' type of examples that the average programmer could pick up without having to have a complex in-depth knowledge of Computer Vision. I feel this book does a very good job at that as well. Each chapter is basically it's own example with various computer vision techniques applied. I also appreciate the authors have posted all the code online for download and testing it the code compiled without any issues (Ubuntu 12.04). I definitely recommend this book if you are new to OpenCV or even interested in learning some of the basics of programming computer vision, although you should probably also have a bit of programming experience as well to actually understand what the code is doing.",13
XY,4.0 out of 5 stars,Artificial Intelligence: Foundations of Computational Agents,interesting,"This book presents an ingenious nine dimensional taxonomy of the design space for a computational agent, which I'll call the PM (Poole-Mackworth) taxonomy. Unfortunately, after presenting this taxonomy in chapter 1, it is not directly referenced again until chapter 15, the final chapter. My preference would be that the PM taxonomy be referenced constantly throughout the book, for example by reference to appropriate nine-dimensional spider diagrams. Relationships between topics would be represented as relationships between points on the PM spider diagram, and transitions between topics would be described accordingly. Any proposed AI taxonomy will only be generally accepted if it is shown to be useful, and this book does not try very hard to demonstrate the utility of the PM taxonomy. The need for a useful taxonomy for AI is demonstrated by one of this book's main competitors, the encyclopedic Russell-Norvig book. The 'everything but the kitchen sink' approach employed in the Russell-Norvig book is intellectually unsatisfying; a future edition of Poole-Mackworth's book has the potential to bring some much-needed order to the field of AI.",13
Bradford W. Miller,5.0 out of 5 stars,Automated Planning: Theory & Practice (The Morgan Kaufmann Series in Artificial Intelligence),Excellent presentation that fills a void,"Until this book, possibly the only comprehensive treatment of planning has been a paper collection: Readings in Planning (Morgan Kaufmann Series in Representation and Reasoning). What these authors have done is phenominal - they've marshalled a bibliography of 565 publications into a comprehensive treatment from a common point of view. That makes it much easier to analyze different approaches to planning, as well as to see how various application domains have applied these approaches to solve real problems.

The first 448 pages of the book discusses various planning approaches, from classical state-space planning including recent improvements in the STRIPS model (GraphPlan), to dealing with temporal operations and resource scheduling. They then use the readers understanding of these deterministic approaches to bridge to planning under uncertainty, which is where planning meets the ""real world"" of imperfect knowledge, observability or even actions having unintended effects. The next roughly 100 pages goes into application domains discussing how space applications, robotics, manufacturing, emergency evacuation and even the game of bridge has used these planning methods to give the reader better intuitions on their own domain.

Finally some minority approaches such as case-based planning and plan related areas such as plan recognition are introduced briefly, leading to tutorial appendices on search (and complexity), first order logic, and model checking.

I have been working on the periphery of planning research for over 25 years, including (currently) directing advanced research in adversarial planning (a topic not addressed by this book, but that's hardly surprising given the novelty of the approach ;-). This is the best overview and reference I've seen to date for this very important area.",13
Ayon Sinha,5.0 out of 5 stars,Mahout in Action,"""In Action"" Absolutely. Machine Learning text converted to usable code","I have a large scale production code background and have been slowly getting deeper and deeper into recommenders, classification & clustering due to the nature of our business. The Data Mining textbooks have a very different objective, which is to cover every technique so that the person taking the class knows ins and outs of these.
Mahout in Action is written and explained so well with simple real life explanations and definitely executable code that you can gather all the techniques you've heard/read about come right near your grasp. Just extend your arms and reach for that recommender or clusterer.

A big thanks to every Mahout contributor and double thanks to the authors.

Oh by the way! Order the book. At whatever price, this will save you hundreds of hours of reading and coding.",13
Steven B.,5.0 out of 5 stars,Genetic Programming: An Introduction (The Morgan Kaufmann Series in Artificial Intelligence),"Excellent, comprehensive and easy to read.","We all know that kind of books where the author likes to show how much he knows making things intentionally complex....well...this is the opposite side of the spectrum.
The book is very complete and detailed yet easy to read, even after a day of work.
The first part of the book contains introductory information on background areas like probability, biology and computer science as a general discipline.
Getting into the topic, it clarifies some of the differences between evolutionary systems and genetic algorithms and shows how all this contributes to the theory of genetic programming and the evolution of computer programs.
It explains how things are done with different types of individuals (tree, linear, graph, etc) and gives valuable insight about the implementation process.
Although you may need other sources for formal treatment of some topics, this book is a very good acquisition.",13
Steven B.,5.0 out of 5 stars,Genetic Programming: An Introduction (The Morgan Kaufmann Series in Artificial Intelligence),"Excellent, comprehensive and easy to read.","We all know that kind of books where the author likes to show how much he knows making things intentionally complex....well...this is the opposite side of the spectrum.
The book is very complete and detailed yet easy to read, even after a day of work.
The first part of the book contains introductory information on background areas like probability, biology and computer science as a general discipline.
Getting into the topic, it clarifies some of the differences between evolutionary systems and genetic algorithms and shows how all this contributes to the theory of genetic programming and the evolution of computer programs.
It explains how things are done with different types of individuals (tree, linear, graph, etc) and gives valuable insight about the implementation process.
Although you may need other sources for formal treatment of some topics, this book is a very good acquisition.",13
Hadayat Seddiqi,3.0 out of 5 stars,Machine Learning: An Algorithmic Perspective (Chapman & Hall/Crc Machine Learning & Pattern Recognition),"Decent intro to machine learning, nice Python+Numpy code, but many errors","I am somewhat disappointed by this book. Today I'm feeling generous, but it was tough to bump this up from 2-stars because to me it at times created more confusion than anything else.

First off, this is an introduction certainly, probably at the sophomore college level. The math is there but not used especially well, and I believe the intention of the book is to sort of cater to those whose math backgrounds aren't very good. There is certainly a need for a book like this, but it shouldn't be used for more than supplementary material.

There are many errors in this book, sometimes typographical but other times a little more serious. The writing style puts a bit of stress on the reader and I find myself jumping around the paragraph sometimes trying to figure out what is being said. The tone is meant to be casual and simple, but coupled with the numerous errors in the book it really felt like this edition was rushed. This was the most disappointing aspect.

This book was useful to me for clarifying some things, but only because it was a different explanation that wasn't bogged down in mathematical rigor. I think it is a very good idea to have several books on the same subject for which you are studying seriously (I have three or four books on quantum mechanics, and even then it took many reads through them to really understand it). This book served its purpose in that sense. I also bought it because I was eagerly awaiting deep learning topics to find their way into ML texts. Sadly, this book didn't help me as I had been reading papers at this point, but I think it was a good introduction to deep learning and the types of neural networks typically used to build them and I applaud this initial effort by the author to include the material. I did find a few mistakes in the earlier chapters on Hopfield networks specifically, but I don't remember them being serious.

I'm a Python programmer who uses Numpy a lot, and this was the best feature of this book. Most of the time I could quickly glance at the code and see what was really happening, and looking over the included code clarified some things for me as well. For textbooks in computational areas nowadays there's no excuse for not providing code, and I'm very glad to have had that to look at.

Overall, this book could have been a lot better and has the potential to be a really great introduction to ML as its own textbook (at the underclass level, i.e. freshman and sophomore). The author simply didn't put in enough time to revising, or perhaps it was the editor's fault, not sure. The heavy usage of actual code was a big plus for me, and it covered some topics that aren't typically covered (deep neural networks) which was done well. For someone who is somewhat familiar with ML, this is a decent book to sprint through just to review and glean some bits and pieces. For the beginner, it can be a good introduction especially if you aren't as good at math as you'd like to be, but I'd recommend using it as a supplement to something at a higher level (perhaps Bishop's or Alpaydin's book, or even David Barber's book).",13
Henrik I. Christensen,1.0 out of 5 stars,Machine Learning: An Algorithmic Perspective (Chapman & Hall/Crc Machine Learning & Pattern Recognition),Be aware the digital version has issues,"I had this as a print version and bought the kindle edition. Unfortunately the kindle edition cannot be read on a kindle or a kindle reader for ipad. It can only be read on kindle readers for mac and pc. First encounter for me that certain Kindle Books cannot be read on digital readers such as the ipad. Clearly you should be aware of this. To me it is *very* unfortunate that Amazon is starting to distribute kindle files that may not be readable on my mobile devices.

I called Amazon customer service and they confirmed that I cannot read this book on my ipad. Have we started to see a new policy from Amazon that eventually could lead to less kindle contents being available for the ipad? Just wondering",13
PDS,3.0 out of 5 stars,"Superintelligence: Paths, Dangers, Strategies",I got thru it,"Very difficult read. Writer does not use everyday language. Textbook style that needs a ton of explanation and footnotes. I plowed thru it and got the gist of it (I think) but didn't really enjoy the trip. Be sure to have a dictionary handy. Much prefer ""Our Final Invention"" by James Barrat",12
Nelson Bridwell,1.0 out of 5 stars,"Superintelligence: Paths, Dangers, Strategies",Flawed Nonsense,"Hilariously flawed diatribe against AI. Several arguments make no sense at all.
For instance, Bostrom thinks that superintelligent computers will want to do ultrastupid things like saturate the world with paper clips.
Or, he claims that an ultrasmart AI that is asked to protect us will not be bright enough to realize that locking us up in a prison is not exactly what we had in mind.
I suppose some might find this amusing, but to me it is a waste of time, dollars, and wood pulp.",12
Tyler Renelle,5.0 out of 5 stars,Python Machine Learning,Be sure you already know know ML & Python data tools.,"Great book! I would recommend buying this as PDF directly from packtpub. There's a lot of code, and it can get hairy in Kindle format. The author does have an iPython notebook repo, which makes following the code much nicer; but for reading in bed, not needing to switch back-n-forth, go PDF.

Make sure you already know (a) Machine Learning; (b) Python, NumPy, Pandas, iPython, Matplotlib. The author primers these a tad, but not enough for the uninitiated. If you're new, I'd recommend first taking Andrew Ng's Coursera Machine Learning course; then find a book on Numpy + Pandas + Matplotlib (1 book will cover all 3). Then read this book.",12
Jim R,3.0 out of 5 stars,Python Machine Learning,Greatly degraded in Kindle format,"I would not recommend the Kindle edition because of the formatting of the book. All the equations, inline and standalone, are too small to read. The graphs are too small to read. You have to double click on each one to zoom in. Then you click to go back to page. This horrible formatting makes reading the book tiring and frustrating. The book gets a 1 star for the page layout making it difficult.

I don't understand how the publisher let this go. I will check samples carefully in the future to be sure not to get stuck with one of these duds again. I would advise anyone to try the epub format straight from the publisher. I can't say that is better, but can't imagine it could be worse.

The content was okay, but only left me looking for another book on the subject.

The examples are excellent working code case studies.

The balance of theory vs practice in the book wasn't right for me. I want to use Machine Learning. I do not intend to advance the field. While the math is interesting, it doesn't help a user decide what to do nor how to apply a method to a problem. Too much of the advice in the field seems to reduce to ""try it, vary the parameters, maybe it will do something for your problem"" or ""if that one doesn't work, here are others to try"". I realize that this may be state of the art, that people don't really know _why_ the various machine models work or don't work. But to move machine learning from a science experiment to a methodology with predictable outcomes, we need more books focused on practical advice.",12
dgood,3.0 out of 5 stars,Design Patterns: Elements of Reusable Object-Oriented Software,Design Patterns CD - Needs updating,"The CD version is not 100% compatible with current browsers. Internet Explorer v6 reports errors on every page and it's new security features disable some CD functionality.

The Java search engine does not function in both IE and Firefox.

The content is, of course, exceptional; but the reasons for buying the CD are lost in the new browsers. Stick with the book.",12
Ashwin Kapur,5.0 out of 5 stars,Artificial Intelligence: A Modern Approach (3rd Edition),Fantastic Book: Horrendous Kindle Conversion,"This is the best introductory review to Artificial Intelligence on the market. It's very well written and organized. There are other books that are better for focusing on one particular aspect of AI, but as a general book this is the best I've seen. If you are looking for a really good introductory textbook to AI that does not completely dumb things down, buy this book.

Most of the negative comments about this book come from people stating that it's not a big enough update from the prior edition. While it's true that the entire field of AI has not been completely updated since the last edition, it's also not the case that this book comes out with new editions with the frequency of some Calculus or Economics textbooks where new editions seem to come out purely to ensure students can't buy a used book for the course. The updates are substantial. Whether the new edition gives you enough extra to want to buy it if you own the old edition is a decision only you can make for yourself after spending some time at the website for the book aima.cs.uberkeley.edu.

The Kindle conversion of this book is absolutely horrendous. I prefer to buy electronic copies of books if possible so I don't have to carry a heavy hard copy around since I often read while commuting. I would not recommend that for this book, even though at a 1000+ textbook sized pages, it is a pretty substantial book. Fortunately a friend of mine had bought a Kindle copy of the book and I was able to see how bad it was and I bought the hard copy.

I recently got an email telling me Amazon was sending out an updated version of the Kindle version of Steve Job's biography because the conversion hadn't been done properly. They really need to do that for this book. Once done it may be a good idea to state on the website that the Kindle conversion has been fixed.",12
anonymous coward,1.0 out of 5 stars,Artificial Intelligence: A Modern Approach (3rd Edition),Kindle edition very poorly done,"I like this book, but the kindle edition is full of weird artifacts. This has rendered many in-line mathematical formulas largely unintelligible. For an example, every logical expression for ""x and y"", where the ""and"" should be a wedge, has instead been converted into a caret, which in every case is floating almost directly over the first variable. In another example, there is a reference to the ""one-element vector h0.6i."" It seems that the h and i were probably brackets originally, but it is impossible to tell.

In the real book there are words in the left margin that indicate where in the text a word has been first defined. In the kindle edition these are replaced with immense horizontal bands across the entire page with horizontal rules above and below, taking up three full rows of text, and they appear below the text that they refer to. Three of those in one paragraph, and you're lucky to even get the paragraph on the same screen with them, much less use them as a nice guide to where words are defined. All practical use they had in the real book is completely obliterated, and now they just take up a lot of room on the screen and make the book harder to read.

In the few places where they've kept the original formulas by means of images, the images look a little like they came from a malfunctioning copier. This is less of a problem than the other issues, but it is still annoying.

Overall a big thumb's down on the kindle edition!",12
kellycmaine,3.0 out of 5 stars,Amazon Echo: Master Your Amazon Echo; User Guide and Manual,A good place to start,"This guide is for the very new only, and perhaps those that haven't done much research about the product. I was hoping to find more tips on types of requests that are successful vs. might cause confusion. Lots and lots of typos, and redundant in many areas.",12
Marc W. Abel,5.0 out of 5 stars,Learning From Data,A great book if Eout(g) ~ Ein(g),"I can't pretend to have spent nearly as much time with this book as I've signed up to. It arrived this afternoon, and it got at least 20 minutes of my time looking ahead at what Professor Abu-Mostafa is going to say to the world tomorrow. But from page 15 to 27, here is what I can observe.

A minor point: I love the color examples within the book. When I was in school, we didn't get textbooks like this.

The tone of the text is very sympathetic in the direction of one who is interested in the subject. That is, if you need to learn from data, the text considers what you will need to know to succeed. The reader's need to understand is prioritized much higher than the reader's need to ""be educated"".

Although I've been out of college for two decades, I have no problem following what the text has to say, or the direction it's headed in. I don't abstract things magnificently, my calculus isn't that hot, and I slid through school without a probability class as such. I love math, but I'm not a powerhouse at it compared to the peers who once sat next to me. But I can follow this text, understand the exercises, and I conjecture that I can work the problems which are meant to be worked.

For a non-academic, I have considerable on-the-ground machine learning background. I've done a lot of backpropagation network training in my day in character recognition, acoustics, finance, and similar disciplines. This is where I find the text valuable: it can build on what I already know, and it starts in a place I'm already familiar with. So if this is your field or one of your fields, the book will make not just a good textbook but a useful reference.

So let's talk about what this book is not, and perhaps AMLbook will publish something else for us. Don't expect a course in neural networks here. They're not in the table of contents (""hmmm...""), but you'll find them in the index pointing you to the epilogue. Support vector machines get the same treatment. Now support vector machines are a little new for me; they came into their own after I finished college. Neural networks, however, got an earlier start.

What I can say is that this text is intentionally tool-neutral. I just read 13 pages that weren't about neural networks per se, but they covered vital groundwork that I learned via hands-on experience with real neural networks. My grasp of some of the ""why"" components of what I know is already improved.

I am not in love with whatever chemical processes went into the manufacture of this book. Perhaps it came off the press so recently that I'm noticing that, and the effects will fade. For right now, it's a definite don't-cuddle-with volume which drives me to the bathroom sink when I put it down. I can live with this; it's a small price to pay for the knowledge.

The amount I paid for this text was astonishingly low. No doubt the authors have thought this through carefully, but this text will hold its own against others that cost three to six times what I paid.

I apologize if this is not the best-informed review. I'm hitting send a little early, because at the present time, you don't have many alternatives to read.",12
Brian A. Garber,2.0 out of 5 stars,Learning From Data,"For researchers, not for regular users","This book is a lot more about theory than application. It also involves heavy math. I purchased this because I was generally interested in Machine Learning, and it was ranked highly. However, it was a disappointment because I want to be a _user_ of machine learning, not a researcher of the topic.",12
BruceK,2.0 out of 5 stars,How to Create a Mind: The Secret of Human Thought Revealed,"I might have called this ""Pulp Non-Fiction"" ...","The books has some interesting moments ... but in the parlance of my Jr. College class designations, this is like ""Intro to How To Create A Mind - 10"" not a real class that teaches you something. I would put the level of this somewhere around high-school or early college level and for those who do not really know anything about the subject.

At every step of the way Kurzweil goes off on historic or trivial anecdotes, wasting our time because he really has damn little to say but to re-phrase what others have said. If you read the quotes at the beginning of the chapters and you have read some neuroscience before, you might even have been able to write this book.

I appreciate Kurzweil's accomplishments, he is an accomplished individual ... but in writing a book that is merely an ad for his own celebrity, or pat on the back for his own job well done, I expected more. This is not ""How To Create A Mind"" ... the title is false advertising.

Kurzweil is very much like the Turing Test he likes to dwell on so much ... that is, if he can talk vaguely and skillfully around the subject the reader will never know he is not telling us really anything new, any more than a talking robot is proving it is human by fooling us in a teletype test.

It's very interesting to hear scratchpad calculations about what the level of computation is in the human brain, and the increasing level operations per second in the computer industry, and memory bandwidth, etc ... but the whole idea of software, the whole idea of debugging or creating a massively parallel biological system in a computer is covered by continual handwaving.

My thoughts on this are that it is very helpful to know the basic numbers Kurzweil spends time setting up for this arguments ... but from there it peters out to nothing. Kurzweil spends quite a while attacking Roger Penrose for what Kurzweil characterizes as comparing quantum computation and consciousness as both being mysterious and so must be connected somehow ... well, hello, to me it sounds like Kurzweil does the same thing when he says that when the two levels of computations and basic understanding of computers and the human brain get close that we will somehow be able to program something like a brain, or have it program itself.

I don't buy it. It's interesting, and I don't complain that he is trying, what I am complaining about in this book is the lack of real value to any thinking person who read anything about this subject, and particularly if they are familiar with Kurzweil's writing itself.

I cannot give this book a 1, that would be unfair as it would be very good for a novice in the subject, nor can I give it a 3 or higher, because that would mean that it achieved what the title said ... in either a excellent way or mediocre way. So I give it a 2 because it is a rehash of stuff that I think it close to an insult to Kurzweil's fans and followers and to those who pay good money to hear new ideas, not the same rehashed stories and points made in many many other books.

""On Intelligence"" has been mentioned in some of these reviews. That is not quite a good book to compare this two, because it is over 10 years old now I think, and also most of the important points I recall from ""On Intelligence"" are covered more simply and better in ""How To Create A Mind"". The description of the nervous system and the brain and some of the parts of the brain are well done.

Even had the book contained more meat, and less filler, still I would have issues with Kurzweil because in his zeal he seems to completely bypass the ""qualia"" points because he has no way to deal with them - so they are nothing. He gets into a little of these thought experiments and ideas, but then dismisses them. All naturally evolved brains developed to solve the problem of survival .. that is writ large into our whole species back forever. How does that fit into the software of our brains? What about the search for pleasure or happiness, or what about the same foibles that our brains are heir to ... that is, prejudice, pride, making mistakes, correcting and reporgramming ourselves. We are not good at even using our intelligence and our social organization is a disgrace. It is hard to even imagine that we are intelligent or that the intelligent parts of us has anything to do with other than the ablity to pass ideas, experiences and doubts back and forth to each other on things that are not really important to us, because we act secretively and selfishly on anything that is, and we whip up fictions about what is important and fight for them from the time we are infants.

I have the feeling that life has been put through its tests ... that all the little lessons of being whatever it is that a given species, brain, DNA is, is moving along in time from a given beginning diverging constantly, in a brilliant design of nature ... and that when we try to understand nature we get little chunks of it, and our history has been to use those chunks to make money or weapons or gain the approval of those we need to gain the approval of ... but how would a machine do this? There are probably critical ideas and ""software"" that are not perceivable just as humans do not understand the weather patterns of the world, or all the ramification of DNA and genetic engineering. There is a lot more to software than just a basic program, there is what is judgement.

I think it will be much easier to create tools for humans to use than it will be to create a mind, and those tools may not be so great as there is so much ambiguity inside our brain than we can express or experience in words.

As I read this book there were a few times when I flashed on the old Star Trek episode ""What Are Little Girls Made Of"" where a man is transformed into a machine, and in the end of the show has lost what makes him essentially human. That episode aired something like 47 years ago ... these concepts are not hard and do not bear filling a whole book full of them when the title promises the reader something about ""How to Create a Mind"" and ""The Secret of Human Thought Revealed"" ... I have to say it's disappointing.",12
S. L.,5.0 out of 5 stars,Probabilistic Graphical Models: Principles and Techniques (Adaptive Computation and Machine Learning series),Awesome book of Graphical models,"I have learned basics of graphical models from a professor who is quite prominent in the field.
He taught it from unpublished book by Michael Jordan + few chapters by Chris Bishop.
I have not read most of the books but have read enough to write positive things about it. I especially like the part of the book that shows dependencies (bad pun alert). dependencies of chapters that is. :D
the only complaint i have is not towards the authors but towards the publishers. the quality of paper is the worst i've ever seen and i own more than 400 textbooks. there are dusts all over the pages. you can feel your hands getting dry due to these paper particles and after a while you can't breathe because of these particles. some books have this but this book is the worst when it comes to that paper dust. you will know when you have this yourself.
they could have slapped on $200 and worse paper quality, I would still buy it without thinking twice about it.",12
Saikat,5.0 out of 5 stars,Probabilistic Graphical Models: Principles and Techniques (Adaptive Computation and Machine Learning series),Great book for grahical models,"I am a PhD student in machine learning. This book is a great reference for graphical models. There are some typos, but it will probably be fixed in next edition.",12
Vincent Stanford,2.0 out of 5 stars,Machine Learning with R - Second Edition,The book is shallow to the point of being cursory in its treatments of the topics it addresses.,"This book may be useful if you are very new to the topics it addresses, but it is not a good resource for developing sophisticated ML algorithms. It has very little code, and not much on how to read and structure the data. There are overviews that you could easily get from introductory paragraphs of Wikipedia articles.

If you are starting from ground zero in R and ML it might be useful.",12
Ian K.,2.0 out of 5 stars,Machine Learning with R - Second Edition,Machine Learning with R for High School students,"For $20.44 I expected a book that was useful. Indeed, if I were a High School student, I might have found this book useful. The book does provide a shallow overview of Machine Learning, with some R code. The book carefully explains things like standard deviation (if you need this background I recommend A Cartoon Guide to Statistics (seriously)). But there is no depth at all and the introduction to R is cursory. This is not a book in the Springer Use R! series.

If you're not a High School student and you know basic statistics and basic college level math, this book will not be much use to you. Since there is so little in the way of background information, the book will be of no use in actually implementing Machine Learning algorithms. Machine Learning is a deep topic and this book has the depth of a rain puddle.",12
CherylY1,1.0 out of 5 stars,Machine Learning For Dummies,Waste of money,"This book requires that you are (or become) familiar with both R and Python languages. The book is poorly organized and many results are stated rather than shown. If you are interested in an introduction to machine learning, take the FREE course given by Andrew Ng from Stanford (one of the world's experts) on Coursera. By the third week, you will be far ahead of the content in this book.",12
Damita,5.0 out of 5 stars,Amazon Echo: 2017 Edition - User Guide and Manual - Learn It Live It Love It,"Amazon echo,,, really wonderful.",Amazon echo is really is helpful to all amazon users. It comes with lots of good things that will help us in our daily lives. This guide book is very clear on how to use the amazon echo and to set it up. It lists several ways on how to use the echo such as as a bedtime timer for kids and also can be used in offices and business enterprises. It has many advantages and I really love the book. Thanks to the author.,12
Amber,5.0 out of 5 stars,Accelerated Spanish: Learn fluent Spanish with a proven accelerated learning system,Great Learning Book,"This book is really good if you want to learn Spanish fluently and quickly. Timothy teaches in a way where you would be able to speak to an actual Spanish-speaking person. It's not like they teach you in high school where it's based on an intro conversation you may or may not have. He also is really good at explaining the difference between verbs that might seem very similar to us like ser and estar.
If you're serious about learning Spanish and I would definitely recommend getting this book.",12
Dr. Lee D. Carlson,3.0 out of 5 stars,On Intelligence,A bit too philosophical,"In the field of artificial intelligence it seems there are as many definitions of intelligence as there are stars in the heavens. Each of these definitions seems plausible, and interestingly, they seem to get more difficult to satisfy with time. Thus progress in artificial intelligence seems to be non-existent, since the criteria used to designate a machine as being intelligent ten years ago are no longer used today. Researchers in AI used to believe for example that if a machine could beat a human in chess then it should definitely be deemed intelligent. That belief is hardly held by anyone in the AI community at the present time.

The author of this book proposes yet another definition of intelligence, and it is one that is inspired by his understanding of how the human brain functions. His justifications are interesting, but they are highly speculative, and border on mere philosophical musings. It would have been a better book if the author refrained from the random walks in conceptual space that are characteristic of philosophy, and justified his conception of intelligence with what is really currently known in neuroscience. He does quote the research of neuroscientists that have produced a detailed map of the monkey cortex, which revealed many different regions connected together in a complex hierarchy. The author then makes the assumption that the human cortex hierarchy has a similar hierarchy. This is not really an unreasonable assumption if viewed from the standpoint of neuroanatomy, but from the standpoint of the cognitive abilities of humans versus those of monkeys, it might indeed be an assumption that deserves intense scrutiny.

The author definitely wants to view intelligence as being one that can function over many different domains, i.e. an intelligent machine will be able to not only play chess for example, but could also analyze stock market data or perform some other function typically thought of as requiring careful thought. He expresses this by saying that the human cortex is ""universal"" in that it can be applied to any type of sensory or motor system, and that the ""algorithm of the cortex"" can be expressed independently of any particular function or sense. Certainly humans can think in many different domains, but one cannot conclude from this that humans possess the general intelligence that the author believes they do. There is in fact a large body of research that indicates that the human brain has a modular structure (the author discusses this research very briefly), with each module being responsible for functioning in a particular domain. If one of these modules ceases to function, this has no effect on the functioning of the others. This is a view of the brain as having a domain-specific structure. A domain-general notion of intelligence would mean that the brain can deal with several different domains, but that the same reasoning patterns or processes are used to think in these different domains. If one of these reasoning patterns or processes becomes non-functional, the rest of them will suffer. One could still view the brain as consisting of modules expert in different domains, but that these modules are ""entangled"" with each other in the sense just specified, i.e. damage in one module will affect the others.

In fairness to the author, there is also research in neuroscience that lends support to his notion of general intelligence and a single algorithm that can deal with all of the data presented to the human brain. He gives a few references that discuss this research, and he definitely emphasizes the need for feedback and the related notion of `auto-associative' memories. The brain in his view is a ""pattern machine"" and if one is to construct truly intelligent machines one must make use of this pattern manipulating capability of the human cortex. Thus intelligent machines will be a result of this ""neocortical inspired"" computing, and the author spends a lot of time explaining why these machines will mimic the ability of the brain to solve a problem using memory, and not by computing a solution. The cortex, in his view, creates ""invariant representations"" which can handle the intricate variability of the world it is confronted with. He summarizes this viewpoint by saying that the neocortex stores sequences of patterns, recalls patterns auto-associatively, stores invariant patterns, and stores patterns in a hierarchy. His explanations of how it does this are interesting, but again are very speculative, and in the absence of a prototype for a machine that possesses this kind of intelligence, it is difficult to assess the validity of his assertions.

This reviewer strongly disagrees with the assertion from the author that there are no machines today that express true intelligence. A strong case can be made for the existence of myriads of intelligent machines in the world today, but this case would again be dependent on a particular definition of intelligence. Machines that have intelligence as the author defines it are nowhere in sight, and this is no doubt due to the lack of commercial value in the domain-general intelligence that the author advocates. The intelligent machines of today can learn, adapt, and manage, and do many other different things, but they only do these things in specific domains. There is absolutely no need for these machines to have expertise in more than one domain, both for the sake of efficiency and also because of economics. In managing a network for example, there is no need for a machine to have expertise in some other area, such as chess playing or backgammon. Business demands thus dictate the kind of domain-specific intelligence that is so prevalent in hundreds of intelligent machines performing many useful functions in business and industry.",12
William M. Harvill,3.0 out of 5 stars,The Perfect Bet: How Science and Math Are Taking the Luck Out of Gambling,If you are interested in the development and future of robotics you'll enjoy this book,Thoughtful discussion of the intersection of science and gambling. Much of the content is a rehash of Fortune's Formula and Richard Munchkin's book Gambling Wizards. If you are interested in the development and future of robotics you'll enjoy this book. If you're looking for detailed gambling stories there are better places.,12
J. Bosch,3.0 out of 5 stars,Artificial Intelligence: A Modern Approach (2nd Edition),"Could have been great, but ...","As some reviewers have said, this is probably the most comprehensive AI textbook on the market. The ""pros"" of the book have been covered pretty well by other reviewers, so I'll limit my review to some of the things that bug me about the book.

1. No answer key for any problems. This feature has been standard in textbooks for decades as a way for students to self-check their understanding of the material.

2. Examples are scant and sometimes stop in the middle. For example, in Chapter 13, the example of applying Bayes' Rule gives one approach and indicates that it will discuss an alternative approach, but then the text just goes off on another path and never completes the example.

3. Inconsistent and (sometimes) convoluted pseudocode for the algorithms. Pseudocode should be a fairly-close-to-English approximation of the algorithm, but this book seems to mix RTL, English, and any other notation. Though the appendix includes an attempt at explaining their rationale behind their own brand of pseudocode, it's incomplete at best. Also, the function names don't follow any convention I've ever seen (I have 30+ years experience in software), and aren't even consistent within the book.

4. Condescending language. This should never occur in a textbook. In far too many places, the authors tell us that ""the sharp-eyed reader will have noticed"" or similar phrases, which basically implies, ""if you didn't get our explanation and find the hidden subtext, you are not sharp-eyed"". All such language should have been edited out.

The authors came so close to writing a classic, but sadly missed the mark. I think that any professors who claim that their students ""universally love this book"" are deluding themselves. Still, if your professor is good at explicating the material, it's worth going through it once, then switching to other materials, maybe primary source materials in the subfield(s) that grab your interest.",12
Karen S.,1.0 out of 5 stars,Couscous and Other Good Food from Morocco,Not a cookbook........,"This is a lot of things, but it is not a cookbook. The recipes are listed by local names and have little or any organization. I felt like I spent more time looking up what the words meant so often that I felt the book was written in Moroccan. There were a very few line drawings and no pictures of finished dishes. This book is not about couscous, it is about just about every other dish served in Morocco.

My daughter loves couscous and I bought this book hoping to find some good dishes that she would enjoy. Nothing could be further from the truth.

If you are looking of a compendium of Moroccan food and have time to sit and read this book from cover to cover, then this is your book. If you want something helpful in the kitchen, save you money.

This book was a total disappointment to me and I am amazed that it is even given cookbook status.",12
Robert Carlberg,4.0 out of 5 stars,"Out of Control: The New Biology of Machines, Social Systems, & the Economic World",Giddy Plagiarism,"I agree with the ""Chicago reader"" who said this book could've used an editor, but it's one of the best poorly-written books I've read too.
Kelly's cheerleading for the decentralized, ""hive-mind"" mentality smacks of the giddy 1940's Tomorrowland propaganda -- oblivious to market realities, people's resistance to change and the fact that simple technologies always win head-to-head competitions with more complex technologies. Yet he makes a valiant attempt to pull a Douglas Hofstadter, and write a ""Godel Escher Bach"" of future technologies. None of his examples or conclusions are original, but that doesn't diminish the cumulative power of his argument.",12
Philip H. Smyth,5.0 out of 5 stars,Practical Common Lisp,"""Practical"" is the key.","There have been any number of excellent books written on Lisp and its sister, Scheme. ""The Little Lisper"" and ""Structure and Interpretation of Computer Programs"" are two that come to mind. What most of them have in common is an emphasis on applying the powerful semantic features of Lisp to fundamental questions in computer science.

This book does show that side of Lisp. However, its most important feature is in showing an underexposed side of common Lisp - that of a potent and underutilized tool for real world programming applications.

File operations, XML and HTML output and web services are all covered. Constructs like the loop macro and package system are given extensive treatment. These were essential tools in the days when Lisp Machines roamed the earth. The unique power of the ""defmacro"" user defined macro facility is shown to good advantage.

I am giving the author five stars for a comprehensive *practical* treatment. This book demonstrates that Lisp is as capable as the current breed of ""dynamic"" languages for application programming - while possessing unique functional powers that have yet to be equaled.",12
Amazon Customer,2.0 out of 5 stars,Probably Approximately Correct: Nature's Algorithms for Learning and Prospering in a Complex World,First half is OK,"First half is OK. It is clear and intuitive presentation of learning algorithms and discussion of the limitations of these algorithms. Very well positioned in the overall context of computability and complexity.

Second part is boring. I stopped reading. All sorts of speculative divagations about evolution as learning algorithms, and such.

Maybe some day, when I retire, I will finish reading. But today, I am mostly interested in learning algorithms and technicalities. Second half of this book is not for me. First half is very interesting",12
Fitness Dude,5.0 out of 5 stars,GIMP for Absolute Beginners,"Nicely written, and the author assumes ZERO Gimp knowledge, so it truly IS for beginners :)","Love this book!

The Author (Jan Smith) is to be commended for an extremely well written book, that will have you up and running on the free alternative to Photoshop in no time :)",12
Vincent Stanford,2.0 out of 5 stars,Machine Learning with R,The book is shallow to the point of being cursory in its treatments of the topics it addresses.,"This book may be useful if you are very new to the topics it addresses, but it is not a good resource for developing sophisticated ML algorithms. It has very little code, and not much on how to read and structure the data. There are overviews that you could easily get from introductory paragraphs of Wikipedia articles.

If you are starting from ground zero in R and ML it might be useful.",12
